%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/


%% Created for Chandler May at 2014-06-02 13:53:45 -0400 


%% Saved with string encoding Unicode (UTF-8) 



@inproceedings{teh2008,
	Author = {Yee Whye Teh and Kenichi Kurihara and Max Welling},
	Booktitle = {Advances in Neural Information Processing Systems 22 (NIPS)},
	Date-Added = {2014-06-02 17:49:56 +0000},
	Date-Modified = {2014-06-02 17:53:43 +0000},
	Title = {Collapsed Variational Inference for HDP.},
	Year = {2008},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QFi4uL1BhcGVycy90ZWgvMjAwOC5wZGbSFwsYGVdOUy5kYXRhTxEBgAAAAAABgAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAAY6HkCDIwMDgucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAB4JQDPmdxQAAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAAN0ZWgAABAACAAAzuyrrAAAABEACAAAz5oUkAAAAAEAFABjoeQAFDHEAAUznwAFM54AAMBHAAIAO01hY2ludG9zaCBIRDpVc2VyczoAY2ptYXk6AERvY3VtZW50czoAUGFwZXJzOgB0ZWg6ADIwMDgucGRmAAAOABIACAAyADAAMAA4AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgApVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy90ZWgvMjAwOC5wZGYAABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4ApwCsALQCOAI6Aj8CSgJTAmECZQJsAnUCegKHAooCnAKfAqQAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACpg==}}

@phdthesis{beal2003,
	Author = {Matthew J. Beal},
	Date-Added = {2014-06-02 17:12:53 +0000},
	Date-Modified = {2014-06-02 17:13:57 +0000},
	School = {Gatsby Computational Neuroscience Unit, University College London},
	Title = {Variational Algorithms for Approximate Bayesian Inference},
	Year = {2003},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QFy4uL1BhcGVycy9iZWFsLzIwMDMucGRm0hcLGBlXTlMuZGF0YU8RAYAAAAAAAYAAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM7sZVxIKwAAAIGFTggyMDAzLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgXa+z7IT6wAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAEYmVhbAAQAAgAAM7sq6wAAAARAAgAAM+yTCsAAAABABQAgYVOABQxxAAFM58ABTOeAADARwACADxNYWNpbnRvc2ggSEQ6VXNlcnM6AGNqbWF5OgBEb2N1bWVudHM6AFBhcGVyczoAYmVhbDoAMjAwMy5wZGYADgASAAgAMgAwADAAMwAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAKlVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvYmVhbC8yMDAzLnBkZgATAAEvAAAVAAIADP//AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAKgArQC1AjkCOwJAAksCVAJiAmYCbQJ2AnsCiAKLAp0CoAKlAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAqc=}}

@article{duchi2011,
	Author = {John Duchi and Elad Hazan and Yoram Singer},
	Date-Added = {2014-05-25 16:59:44 +0000},
	Date-Modified = {2014-05-25 17:01:01 +0000},
	Journal = {Journal of Machine Learning Research},
	Pages = {2121--2159},
	Title = {Adaptive Subgradient Methods for Online Learning and Stochastic Optimization},
	Volume = {12},
	Year = {2011},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGC4uL1BhcGVycy9kdWNoaS8yMDExLnBkZtIXCxgZV05TLmRhdGFPEQGGAAAAAAGGAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADO7GVcSCsAAAA1n2kIMjAxMS5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAH7VSM+nmbkAAAAAAAAAAAABAAMAAAkgAAAAAAAAAAAAAAAAAAAABWR1Y2hpAAAQAAgAAM7sq6wAAAARAAgAAM+n0fkAAAABABQANZ9pABQxxAAFM58ABTOeAADARwACAD1NYWNpbnRvc2ggSEQ6VXNlcnM6AGNqbWF5OgBEb2N1bWVudHM6AFBhcGVyczoAZHVjaGk6ADIwMTEucGRmAAAOABIACAAyADAAMQAxAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgArVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9kdWNoaS8yMDExLnBkZgAAEwABLwAAFQACAAz//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgCpAK4AtgJAAkICRwJSAlsCaQJtAnQCfQKCAo8CkgKkAqcCrAAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAKu}}

@inproceedings{ranganath2013,
	Author = {Rajesh Ranganath and Chong Wang and David M. Blei and Eric P. Xing},
	Booktitle = {Proceedings of the 30th International Conference on Machine Learning (ICML)},
	Comments = {Ranganath et al. (2013) propose a learning rate for stochastic variational inference that is defined in terms of the estimated distance from the stochastic global variational parameter update to the batch update, rather than in terms of tunable algorithm parameters. The proposed learning rate is designed to minimizes the two-norm of the error between the stochastic and batch global variational parameter updates, and the natural gradient that arises in that formulation is estimated by moving averages initialized with Monte Carlo. Ranganath et al. thus arrive at a learning rate that is estimated purely from the data in a manner amenable to computation, and does not have any parameters to be tuned. While learning rates that satisfy the Robbins-Monro conditions come with convergence guarantees, the empirical learning rate proposed by Ranganath et al. does not. The authors are, however, able to prove convergence of a heavily idealized version of their learning rate. Additionally, their learning rate yields faster convergence to better predictive log-likelihoods in topic modeling experiments (using online LDA) on three large text corpora than the best Robbins-Monro learning rate and constant learning rate. When the underlying distribution of the data is augmented to shift at fixed intervals during learning, the proposed learning rate spikes immediately after the shifts and decreases in between them, as would be desired, even though the algorithm has no explicit knowledge of the distribution shift. Again, the likelihood obtained by the adaptive learning rate at the end of the run is better than the likelihoods obtained by the best Robbins-Monro learning rate and constant learning rate. (In all experiments, the ultimate improvements in log-likelihood offered by the proposed adaptive learning rate are not large.)},
	Date-Added = {2014-05-22 18:09:42 +0000},
	Date-Modified = {2014-05-22 18:10:34 +0000},
	Title = {An Adaptive Learning Rate for Stochastic Variational Inference},
	Year = {2013},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QHC4uL1BhcGVycy9yYW5nYW5hdGgvMjAxMy5wZGbSFwsYGVdOUy5kYXRhTxEBkgAAAAABkgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAAe6HCCDIwMTMucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAB8rG7Po7HUAAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAAlyYW5nYW5hdGgAABAACAAAzuyrrAAAABEACAAAz6PqFAAAAAEAFAB7ocIAFDHEAAUznwAFM54AAMBHAAIAQU1hY2ludG9zaCBIRDpVc2VyczoAY2ptYXk6AERvY3VtZW50czoAUGFwZXJzOgByYW5nYW5hdGg6ADIwMTMucGRmAAAOABIACAAyADAAMQAzAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgAvVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9yYW5nYW5hdGgvMjAxMy5wZGYAABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4ArQCyALoCUAJSAlcCYgJrAnkCfQKEAo0CkgKfAqICtAK3ArwAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACvg==}}

@inproceedings{ranganath2014,
	Author = {Rajesh Ranganath and Sean Gerrish and David M. Blei},
	Booktitle = {Proceedings of the 17th International Conference on Artificial Intelligence and Statistics (AISTATS)},
	Comments = {Ranganath, Gerrish, and Blei (2014) propose a framework that reduces the overall cost of developing a coordinate ascent variational inference algorithm for complex models. Specifically, they use Monte Carlo samples to approximate the expectation of the objective gradient, thereby replacing the expensive need for a human to analytically compute that gradient with a comparatively cheap requirement of computer resources. A basic form of this framework was independently proposed by Wingate and Weber (2013). One drawback of the Monte Carlo approximation is the introduction of variance in the coordinate ascent steps. Ranganath, Gerrish, and Blei detail two extensions to their basic framework to reduce this variance without introducing bias: Rao-Blackwellization of gradient components beyond the active component's Markov blanket and augmentation of the gradient with a control variate. These two modifications make the sampler statistically efficient; the authors also implement an adaptive learning rate (AdaGrad) and the stochastic gradient in order to improve the overall rate of convergence of the inference algorithm. Ranganath, Gerrish, and Blei evaluate their algorithm on a longitudinal medical study. Specifically, they learn a dimension reduction in a time series (Gamma-Normal-TS---a nonconjugate model without closed-form coordinate ascent updates) on a dataset consisting of the lab results (over time) of 976 patients with chronic kidney disease. The model is evaluated via predictive likelihood of lab results on a held-out set. The authors found that their ``Black Box Variational Inference'' algorithm converged faster and to a better solution than a purely sampling-based approach, ``Metropolis-Hastings within Gibbs.'' They also performed a small ablation study on the variance reduction extensions to their algorithm: Rao-Blackwellization reduces variance by several orders of magnitude over the basic sampler and the control variates reduce variance by an additional order of magnitude. Lastly, as a concrete proof of the practical utility of the framework, black box variational inference was applied to three additional graphical models using different assumptions and distributions than Gamma-Normal-TS. The authors claim variational inference for each of these models would have justified three separate papers (respectively), whereas black box variational inference was readily applied once the likelihood under each model was specified.},
	Date-Added = {2014-05-20 16:41:52 +0000},
	Date-Modified = {2014-05-20 16:43:38 +0000},
	Title = {Black Box Variational Inference},
	Year = {2014},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QHC4uL1BhcGVycy9yYW5nYW5hdGgvMjAxNC5wZGbSFwsYGVdOUy5kYXRhTxEBkgAAAAABkgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAAe6HCCDIwMTQucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAB4N+LPmkwRAAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAAlyYW5nYW5hdGgAABAACAAAzuyrrAAAABEACAAAz5qEUQAAAAEAFAB7ocIAFDHEAAUznwAFM54AAMBHAAIAQU1hY2ludG9zaCBIRDpVc2VyczoAY2ptYXk6AERvY3VtZW50czoAUGFwZXJzOgByYW5nYW5hdGg6ADIwMTQucGRmAAAOABIACAAyADAAMQA0AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgAvVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9yYW5nYW5hdGgvMjAxNC5wZGYAABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4ArQCyALoCUAJSAlcCYgJrAnkCfQKEAo0CkgKfAqICtAK3ArwAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACvg==}}

@inproceedings{gershman2012a,
	Author = {Samuel J. Gershman and Matthew D. Hoffman and David M. Blei},
	Booktitle = {Proceedings of the 29th International Conference on Machine Learning (ICML)},
	Date-Added = {2014-05-20 16:40:16 +0000},
	Date-Modified = {2014-05-20 16:41:00 +0000},
	Title = {Nonparametric Variational Inference},
	Year = {2012},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QHC4uL1BhcGVycy9nZXJzaG1hbi8yMDEyYS5wZGbSFwsYGVdOUy5kYXRhTxEBkgAAAAABkgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAAFDJFCTIwMTJhLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABjFAvPdMwMAAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAAhnZXJzaG1hbgAQAAgAAM7sq6wAAAARAAgAAM91BEwAAAABABQAFDJFABQxxAAFM58ABTOeAADARwACAEFNYWNpbnRvc2ggSEQ6VXNlcnM6AGNqbWF5OgBEb2N1bWVudHM6AFBhcGVyczoAZ2Vyc2htYW46ADIwMTJhLnBkZgAADgAUAAkAMgAwADEAMgBhAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgAvVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9nZXJzaG1hbi8yMDEyYS5wZGYAABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4ArQCyALoCUAJSAlcCYgJrAnkCfQKEAo0CkgKfAqICtAK3ArwAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACvg==}}

@inproceedings{eisenstein2010,
	Author = {Jacob Eisenstein and Brendan O'Connor and Noah A. Smith and Eric P. Xing},
	Booktitle = {Proceedings of the Conference on Empirical Methods in Natural Language Processing},
	Date-Added = {2014-05-20 16:38:14 +0000},
	Date-Modified = {2014-05-20 16:39:43 +0000},
	Title = {A Latent Variable Model for Geographic Lexical Variation},
	Year = {2010},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QHS4uL1BhcGVycy9laXNlbnN0ZWluLzIwMTAucGRm0hcLGBlXTlMuZGF0YU8RAZIAAAAAAZIAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM7sZVxIKwAAABQyQQgyMDEwLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAXHHmz217oAAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAKZWlzZW5zdGVpbgAQAAgAAM7sq6wAAAARAAgAAM9ts+AAAAABABQAFDJBABQxxAAFM58ABTOeAADARwACAEJNYWNpbnRvc2ggSEQ6VXNlcnM6AGNqbWF5OgBEb2N1bWVudHM6AFBhcGVyczoAZWlzZW5zdGVpbjoAMjAxMC5wZGYADgASAAgAMgAwADEAMAAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAMFVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvZWlzZW5zdGVpbi8yMDEwLnBkZgATAAEvAAAVAAIADP//AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAK4AswC7AlECUwJYAmMCbAJ6An4ChQKOApMCoAKjArUCuAK9AAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAr8=}}

@inproceedings{wang2009a,
	Author = {Chong Wang and David M. Blei},
	Booktitle = {Advances in Neural Information Processing Systems 23 (NIPS)},
	Comments = {Wang and Blei develop an efficient mean-field variational inference algorithm for the nested Chinese restaurant process (nCRP). They model the nCRP by a recursive stick-breaking construction on a single (shared) ``stick,'' define the variational distribution in terms of nodes within a (finite) truncated tree and nodes outside of the truncated tree, and propose several heuristics for adapting the structure of the truncated tree during inference. Wang and Blei argue that the nCRP mixture model ``is too large even to effectively truncate,'' thus justifying their heuristic truncation adaptations which allow the (truncated) hypothesis space to be explored non-exhaustively. The heuristics include ``grow'' and ``prune,'' the implementations of which are inspired by Gibbs sampling steps, and ``merge,'' which is performed when the cosine distance between the variational probability measures of two paths in the tree breaches a prespecified threshold. A fourth operation, ``split,'' is defined for continuous observations and implemented as in a previous study. This variational inference algorithm is empirically evaluated on two tasks, topic modeling (discrete data) and handwritten digit reconstruction (continuous data). In the topic modeling task, variational inference achieves worse held-out likelihood on three journal abstract corpora than Gibbs sampling. This ordering holds for two approaches to initialization for the variational model, both based on Gibbs sampling, and the authors note the results are consistent with those of previous work on the hierarchical Dirichlet process (HDP). In the handwritten digit reconstruction task, the hierarchical components analysis (HCA) model based on nCRP, learned using the variational inference algorithm, achieves lower reconstruction error than principal components analysis (PCA) for all four truncation levels tested.},
	Date-Added = {2014-05-07 23:26:57 +0000},
	Date-Modified = {2014-05-07 23:28:08 +0000},
	Title = {Variational Inference for the Nested Chinese Restaurant Process},
	Year = {2009},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGC4uL1BhcGVycy93YW5nLzIwMDlhLnBkZtIXCxgZV05TLmRhdGFPEQGGAAAAAAGGAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADO7GVcSCsAAAAUMqwJMjAwOWEucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAHKuhM+QOXwAAAAAAAAAAAABAAMAAAkgAAAAAAAAAAAAAAAAAAAABHdhbmcAEAAIAADO7KusAAAAEQAIAADPkHG8AAAAAQAUABQyrAAUMcQABTOfAAUzngAAwEcAAgA9TWFjaW50b3NoIEhEOlVzZXJzOgBjam1heToARG9jdW1lbnRzOgBQYXBlcnM6AHdhbmc6ADIwMDlhLnBkZgAADgAUAAkAMgAwADAAOQBhAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgArVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy93YW5nLzIwMDlhLnBkZgAAEwABLwAAFQACAAz//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgCpAK4AtgJAAkICRwJSAlsCaQJtAnQCfQKCAo8CkgKkAqcCrAAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAKu}}

@inbook{bottou1998,
	Author = {L\'{e}on Bottou},
	Date-Added = {2014-05-05 21:21:53 +0000},
	Date-Modified = {2014-05-05 21:24:45 +0000},
	Publisher = {Cambridge University Press},
	Title = {Online Learning and Stochastic Approximations},
	Year = {1998},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGS4uL1BhcGVycy9ib3R0b3UvMTk5OC5wZGbSFwsYGVdOUy5kYXRhTxEBhgAAAAABhgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAAcY9iCDE5OTgucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABxhwDPjXhwAAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAAZib3R0b3UAEAAIAADO7KusAAAAEQAIAADPjbCwAAAAAQAUAHGPYgAUMcQABTOfAAUzngAAwEcAAgA+TWFjaW50b3NoIEhEOlVzZXJzOgBjam1heToARG9jdW1lbnRzOgBQYXBlcnM6AGJvdHRvdToAMTk5OC5wZGYADgASAAgAMQA5ADkAOAAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIALFVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvYm90dG91LzE5OTgucGRmABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AqgCvALcCQQJDAkgCUwJcAmoCbgJ1An4CgwKQApMCpQKoAq0AAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACrw==}}

@inbook{vidal2014f,
	Author = {Rene Vidal and Yi Ma and S. Sastry},
	Chapter = {6},
	Date-Added = {2014-05-03 15:59:27 +0000},
	Date-Modified = {2014-05-03 15:59:47 +0000},
	Publisher = {Springer-Verlag},
	Title = {Statistical Methods},
	Year = {2014},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGS4uL1BhcGVycy92aWRhbC8yMDE0Zi5wZGbSFwsYGVdOUy5kYXRhTxEBiAAAAAABiAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAAFDKkCTIwMTRmLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABvEy7PiUuYAAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAAV2aWRhbAAAEAAIAADO7KusAAAAEQAIAADPiYPYAAAAAQAUABQypAAUMcQABTOfAAUzngAAwEcAAgA+TWFjaW50b3NoIEhEOlVzZXJzOgBjam1heToARG9jdW1lbnRzOgBQYXBlcnM6AHZpZGFsOgAyMDE0Zi5wZGYADgAUAAkAMgAwADEANABmAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgAsVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy92aWRhbC8yMDE0Zi5wZGYAEwABLwAAFQACAAz//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgCqAK8AtwJDAkUCSgJVAl4CbAJwAncCgAKFApIClQKnAqoCrwAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAKx}}

@inbook{vidal2014e,
	Author = {Rene Vidal and Yi Ma and S. Sastry},
	Chapter = {5},
	Date-Added = {2014-05-03 15:58:57 +0000},
	Date-Modified = {2014-05-03 15:59:24 +0000},
	Publisher = {Springer-Verlag},
	Title = {Algebraic-Geometric Methods},
	Year = {2014},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGS4uL1BhcGVycy92aWRhbC8yMDE0ZS5wZGbSFwsYGVdOUy5kYXRhTxEBiAAAAAABiAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAAFDKkCTIwMTRlLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABvDY/PiUuMAAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAAV2aWRhbAAAEAAIAADO7KusAAAAEQAIAADPiYPMAAAAAQAUABQypAAUMcQABTOfAAUzngAAwEcAAgA+TWFjaW50b3NoIEhEOlVzZXJzOgBjam1heToARG9jdW1lbnRzOgBQYXBlcnM6AHZpZGFsOgAyMDE0ZS5wZGYADgAUAAkAMgAwADEANABlAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgAsVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy92aWRhbC8yMDE0ZS5wZGYAEwABLwAAFQACAAz//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgCqAK8AtwJDAkUCSgJVAl4CbAJwAncCgAKFApIClQKnAqoCrwAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAKx}}

@inbook{vidal2014d,
	Author = {Rene Vidal and Yi Ma and S. Sastry},
	Chapter = {4},
	Date-Added = {2014-05-03 15:58:21 +0000},
	Date-Modified = {2014-05-03 15:58:55 +0000},
	Publisher = {Springer-Verlag},
	Title = {Nonlinear Extensions to Principal Component Analysis},
	Year = {2014},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGS4uL1BhcGVycy92aWRhbC8yMDE0ZC5wZGbSFwsYGVdOUy5kYXRhTxEBiAAAAAABiAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAAFDKkCTIwMTRkLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABvDM7PiUuJAAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAAV2aWRhbAAAEAAIAADO7KusAAAAEQAIAADPiYPJAAAAAQAUABQypAAUMcQABTOfAAUzngAAwEcAAgA+TWFjaW50b3NoIEhEOlVzZXJzOgBjam1heToARG9jdW1lbnRzOgBQYXBlcnM6AHZpZGFsOgAyMDE0ZC5wZGYADgAUAAkAMgAwADEANABkAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgAsVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy92aWRhbC8yMDE0ZC5wZGYAEwABLwAAFQACAAz//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgCqAK8AtwJDAkUCSgJVAl4CbAJwAncCgAKFApIClQKnAqoCrwAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAKx}}

@inbook{vidal2014c,
	Author = {Rene Vidal and Yi Ma and S. Sastry},
	Chapter = {3},
	Date-Added = {2014-05-03 15:57:11 +0000},
	Date-Modified = {2014-05-03 15:58:00 +0000},
	Publisher = {Springer-Verlag},
	Title = {Robust Principal Component Analysis},
	Year = {2014},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGS4uL1BhcGVycy92aWRhbC8yMDE0Yy5wZGbSFwsYGVdOUy5kYXRhTxEBiAAAAAABiAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAAFDKkCTIwMTRjLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABvDFTPiUuHAAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAAV2aWRhbAAAEAAIAADO7KusAAAAEQAIAADPiYPHAAAAAQAUABQypAAUMcQABTOfAAUzngAAwEcAAgA+TWFjaW50b3NoIEhEOlVzZXJzOgBjam1heToARG9jdW1lbnRzOgBQYXBlcnM6AHZpZGFsOgAyMDE0Yy5wZGYADgAUAAkAMgAwADEANABjAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgAsVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy92aWRhbC8yMDE0Yy5wZGYAEwABLwAAFQACAAz//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgCqAK8AtwJDAkUCSgJVAl4CbAJwAncCgAKFApIClQKnAqoCrwAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAKx}}

@inproceedings{wang2011,
	Author = {Chong Wang and John Paisley and David M. Blei},
	Booktitle = {Proceedings of the 14th International Conference on Artificial Intelligence and Statistics (AISTATS)},
	Comments = {Wang et al. (2011) explain stochastic variational inference for the hierarchical Dirichlet process (HDP), a Bayesian nonparametric mixed membership model. Providing a symmetric Dirichlet distribution over a vocabulary as the base distribution, they apply the HDP as a topic model prior in which the atoms of the first-level DP are the topics and the second-level DPs are mixtures of those topics (i.e., documents). Sethuraman's stick-breaking construction yields a fully conjugate, explicit representation of the HDP, which results in closed-form coordinate ascent updates in a mean-field variational approximation. A stochastic natural gradient approximation is then applied, yielding an online inference algorithm. Wang et al. evaluate their algorithm for the HDP using predictive likelihood on two datasets, articles from Nature and from PNAS. For these experiments the first-level DP is truncated to 150 atoms (topics) while the second-level DP is truncated to 15 atoms (active topics per document). HDP is found to use about 110 of the 150 topics, whereas LDA uses almost all of the 150 topics and exhibits overfitting. Online inference for HDP converges much faster than batch inference for HDP, and achieves a final likelihood almost as good as that of batch inference. A parameter study is also performed for the learning rate and minibatch parameters, and HDP is shown to outperform LDA under most parameter configurations (and in particular, HDP achieves the best likelihood).},
	Date-Added = {2014-04-27 19:55:23 +0000},
	Date-Modified = {2014-04-27 19:56:04 +0000},
	Title = {Online Variational Inference for the Hierarchical {D}irichlet Process},
	Year = {2011},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QFy4uL1BhcGVycy93YW5nLzIwMTEucGRm0hcLGBlXTlMuZGF0YU8RAYAAAAAAAYAAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM7sZVxIKwAAABQyrAgyMDExLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAYy5+z3Tf+QAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAEd2FuZwAQAAgAAM7sq6wAAAARAAgAAM91GDkAAAABABQAFDKsABQxxAAFM58ABTOeAADARwACADxNYWNpbnRvc2ggSEQ6VXNlcnM6AGNqbWF5OgBEb2N1bWVudHM6AFBhcGVyczoAd2FuZzoAMjAxMS5wZGYADgASAAgAMgAwADEAMQAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAKlVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvd2FuZy8yMDExLnBkZgATAAEvAAAVAAIADP//AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAKgArQC1AjkCOwJAAksCVAJiAmYCbQJ2AnsCiAKLAp0CoAKlAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAqc=}}

@inbook{blake2011,
	Author = {Andrew Blake and Pushmeet Kohli},
	Chapter = {1},
	Date-Added = {2014-04-19 23:12:42 +0000},
	Date-Modified = {2014-04-19 23:14:49 +0000},
	Editor = {Andrew Blake and Pushmeet Kohli and Carsten Rother},
	Publisher = {MIT Press},
	Title = {Introduction to Markov Random Fields},
	Year = {2011},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGC4uL1BhcGVycy9ibGFrZS8yMDExLnBkZtIXCxgZV05TLmRhdGFPEQGGAAAAAAGGAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADO7GVcSCsAAABlQKAIMjAxMS5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGUSd8931HoAAAAAAAAAAAABAAMAAAkgAAAAAAAAAAAAAAAAAAAABWJsYWtlAAAQAAgAAM7sq6wAAAARAAgAAM94DLoAAAABABQAZUCgABQxxAAFM58ABTOeAADARwACAD1NYWNpbnRvc2ggSEQ6VXNlcnM6AGNqbWF5OgBEb2N1bWVudHM6AFBhcGVyczoAYmxha2U6ADIwMTEucGRmAAAOABIACAAyADAAMQAxAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgArVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9ibGFrZS8yMDExLnBkZgAAEwABLwAAFQACAAz//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgCpAK4AtgJAAkICRwJSAlsCaQJtAnQCfQKCAo8CkgKkAqcCrAAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAKu}}

@misc{may2014,
	Author = {Chandler May and Alex Clemmer and Benjamin {Van Durme}},
	Booktitle = {Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (ACL)},
	Date-Added = {2014-04-19 15:24:13 +0000},
	Date-Modified = {2014-04-19 15:26:29 +0000},
	Howpublished = {Poster},
	Title = {Particle Filter Rejuvenation and Latent {D}irichlet Allocation},
	Year = {2014},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QFi4uL1BhcGVycy9tYXkvMjAxNC5wZGbSFwsYGVdOUy5kYXRhTxEBgAAAAAABgAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAAFDJcCDIwMTQucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABEcLfPRyVbAAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAANtYXkAABAACAAAzuyrrAAAABEACAAAz0ddmwAAAAEAFAAUMlwAFDHEAAUznwAFM54AAMBHAAIAO01hY2ludG9zaCBIRDpVc2VyczoAY2ptYXk6AERvY3VtZW50czoAUGFwZXJzOgBtYXk6ADIwMTQucGRmAAAOABIACAAyADAAMQA0AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgApVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9tYXkvMjAxNC5wZGYAABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4ApwCsALQCOAI6Aj8CSgJTAmECZQJsAnUCegKHAooCnAKfAqQAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACpg==}}

@inbook{lin2004,
	Author = {Shu Lin and Daniel J. Costello},
	Chapter = {3},
	Date-Added = {2014-04-17 20:00:01 +0000},
	Date-Modified = {2014-04-17 20:01:41 +0000},
	Publisher = {Prentice Hall},
	Title = {Linear Block Codes},
	Year = {2004},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QFi4uL1BhcGVycy9saW4vMjAwNC5wZGbSFwsYGVdOUy5kYXRhTxEBgAAAAAABgAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAAY6MSCDIwMDQucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABV9AnPaYHzAAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAANsaW4AABAACAAAzuyrrAAAABEACAAAz2m6MwAAAAEAFABjoxIAFDHEAAUznwAFM54AAMBHAAIAO01hY2ludG9zaCBIRDpVc2VyczoAY2ptYXk6AERvY3VtZW50czoAUGFwZXJzOgBsaW46ADIwMDQucGRmAAAOABIACAAyADAAMAA0AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgApVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9saW4vMjAwNC5wZGYAABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4ApwCsALQCOAI6Aj8CSgJTAmECZQJsAnUCegKHAooCnAKfAqQAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACpg==}}

@inproceedings{aggarwal2003,
	Author = {Charu C. Aggarwal and Jiawei Han and Jianyong Wang and Philip S. Yu},
	Booktitle = {VLDB},
	Date-Added = {2014-04-17 19:58:53 +0000},
	Date-Modified = {2014-04-17 19:59:44 +0000},
	Title = {A Framework for Clustering Evolving Data Streams},
	Year = {2003},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGy4uL1BhcGVycy9hZ2dhcndhbC8yMDAzLnBkZtIXCxgZV05TLmRhdGFPEQGMAAAAAAGMAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADO7GVcSCsAAAA1rCwIMjAwMy5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFXoss9pgLYAAAAAAAAAAAABAAMAAAkgAAAAAAAAAAAAAAAAAAAACGFnZ2Fyd2FsABAACAAAzuyrrAAAABEACAAAz2m49gAAAAEAFAA1rCwAFDHEAAUznwAFM54AAMBHAAIAQE1hY2ludG9zaCBIRDpVc2VyczoAY2ptYXk6AERvY3VtZW50czoAUGFwZXJzOgBhZ2dhcndhbDoAMjAwMy5wZGYADgASAAgAMgAwADAAMwAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIALlVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvYWdnYXJ3YWwvMjAwMy5wZGYAEwABLwAAFQACAAz//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgCsALEAuQJJAksCUAJbAmQCcgJ2An0ChgKLApgCmwKtArACtQAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAK3}}

@article{teh2006,
	Author = {Yee Whye Teh and Michael I. Jordan and Matthew J. Beal and David M. Blei},
	Date-Added = {2014-04-17 19:55:20 +0000},
	Date-Modified = {2014-05-15 15:37:25 +0000},
	Journal = {Journal of the American Statistical Association},
	Number = {476},
	Pages = {1566--1581},
	Title = {Hierarchical {D}irichlet Processes},
	Volume = {101},
	Year = {2006},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QFy4uL1BhcGVycy90ZWgvMjAwNWEucGRm0hcLGBlXTlMuZGF0YU8RAYIAAAAAAYIAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM7sZVxIKwAAAGOh5AkyMDA1YS5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAeCAlz5naQwAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAADdGVoAAAQAAgAAM7sq6wAAAARAAgAAM+aEoMAAAABABQAY6HkABQxxAAFM58ABTOeAADARwACADxNYWNpbnRvc2ggSEQ6VXNlcnM6AGNqbWF5OgBEb2N1bWVudHM6AFBhcGVyczoAdGVoOgAyMDA1YS5wZGYADgAUAAkAMgAwADAANQBhAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgAqVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy90ZWgvMjAwNWEucGRmABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AqACtALUCOwI9AkICTQJWAmQCaAJvAngCfQKKAo0CnwKiAqcAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACqQ==}}

@incollection{pitman2006,
	Author = {Jim Pitman},
	Booktitle = {Lecture Notes in Mathematics},
	Date-Added = {2014-04-17 19:52:32 +0000},
	Date-Modified = {2014-04-17 19:54:33 +0000},
	Month = {Jul},
	Publisher = {Springer-Verlag},
	Title = {Combinatorial Stochastic Processes},
	Volume = {1875},
	Year = {2006},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGS4uL1BhcGVycy9waXRtYW4vMjAwNi5wZGbSFwsYGVdOUy5kYXRhTxEBhgAAAAABhgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAAY6GhCDIwMDYucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABWAI3PaYurAAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAAZwaXRtYW4AEAAIAADO7KusAAAAEQAIAADPacPrAAAAAQAUAGOhoQAUMcQABTOfAAUzngAAwEcAAgA+TWFjaW50b3NoIEhEOlVzZXJzOgBjam1heToARG9jdW1lbnRzOgBQYXBlcnM6AHBpdG1hbjoAMjAwNi5wZGYADgASAAgAMgAwADAANgAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIALFVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvcGl0bWFuLzIwMDYucGRmABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AqgCvALcCQQJDAkgCUwJcAmoCbgJ1An4CgwKQApMCpQKoAq0AAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACrw==}}

@unpublished{paisley2013,
	Author = {John Paisley and Chong Wang and David M. Blei and Michael I. Jordan},
	Comments = {Paisley et al. (2013) introduce the nested hierarchical Dirichlet process (nHDP), essentially a hierarchical Dirichlet process (HDP) applied to a tree-structured base distribution governed by the nested Chinese restaurant process (nCRP). This model is equivalent to the nested Chinese restaurant franchise (nCRF) introduced by Ahmed et al. (2013). However, Paisley et al. apply the nHDP slightly differently to the topic modeling problem and use stochastic variational inference rather than Gibbs sampling for learning. The topic modeling difference is primarily that Paisley et al. propose drawing topics from the base Dirichlet i.i.d. while Ahmed et al. propose cascading topics down the tree (drawing each topic from its parent). While the nHDP appears to allow copies of global nodes in a local tree, during inference each child of a node in the local tree is unique, so the true difference (if it exists) is moot. The more interesting departure in Paisley et al. is the learning algorithm: It is a straightforward application of stochastic variational inference, aside from a greedy subtree selection step used to speed up inference, but it is an online algorithm and a step toward streaming inference. Paisley et al. run experiments on three corpora of journal abstracts and on two larger datasets, The New York Times and Wikipedia. In these experiments the learning rate is set using a recently-published adaptive schedule, performance is measured by predictive likelihood, the trees are truncated to depth 3 with limits on the number of children per node that decrease with depth, and the initial variational parameters are set by nested $k$-means clustering on the document-term vectors. On the abstracts, variational nHDP outperforms variational and Gibbs nCRP in all but one case: Gibbs nCRP slightly outperforms variational nHDP on the JACM dataset, which has the smallest number of documents, average words per document, and vocabulary size. Moreover, the gap between variational nHDP and nCRP widens as the dataset size (quantified by those three metrics) increases, suggesting that the benefit of allowing each document access to the entire topic tree (or subtree) rather than a single path increases with dataset complexity. On the New York Times and Wikipedia datasets, which are much larger, nHDP significantly outperforms HDP, which outperforms LDA, and the topics found by nHDP are qualitatively reasonable when visualized. The number of topics effectively used by the nHDP also converges rather quickly as a function of the number of documents ingested in inference. The number of words allocated per level of the tree is highest in the second level, suggesting that much of the data does not utilize the third level of specialization available in the nHDP. Finally, a brief sensitivity analysis is performed, and the tree structure is found to be robust to the hyperparameters in a reasonable range.},
	Date-Added = {2014-04-15 13:58:10 +0000},
	Date-Modified = {2014-04-15 14:02:37 +0000},
	Journal = {Journal of Pattern Analysis and Machine Intelligence},
	Month = {Oct},
	Note = {arXiv:1210.6738v3},
	Title = {Nested Hierarchical {D}irichlet Processes},
	Year = {2013},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGi4uL1BhcGVycy9wYWlzbGV5LzIwMTMucGRm0hcLGBlXTlMuZGF0YU8RAYwAAAAAAYwAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM7sZVxIKwAAAGE1sggyMDEzLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAVb4wz2lnAgAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAHcGFpc2xleQAAEAAIAADO7KusAAAAEQAIAADPaZ9CAAAAAQAUAGE1sgAUMcQABTOfAAUzngAAwEcAAgA/TWFjaW50b3NoIEhEOlVzZXJzOgBjam1heToARG9jdW1lbnRzOgBQYXBlcnM6AHBhaXNsZXk6ADIwMTMucGRmAAAOABIACAAyADAAMQAzAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgAtVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9wYWlzbGV5LzIwMTMucGRmAAATAAEvAAAVAAIADP//AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAKsAsAC4AkgCSgJPAloCYwJxAnUCfAKFAooClwKaAqwCrwK0AAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAArY=}}

@article{rosen-zvi2010,
	Author = {Michal Rosen-Zvi and Chaitanya Chemudugunta and Thomas Griffiths and Padhraic Smyth and Mark Steyvers},
	Date-Added = {2014-04-07 17:02:28 +0000},
	Date-Modified = {2014-04-07 17:03:38 +0000},
	Journal = {ACM Transactions on Information Systems},
	Month = {Jan},
	Number = {1},
	Title = {Learning Author-Topic Models from Text Corpora},
	Volume = {28},
	Year = {2010},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QHC4uL1BhcGVycy9yb3Nlbi16dmkvMjAxMC5wZGbSFwsYGVdOUy5kYXRhTxEBkgAAAAABkgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAAVO3PCDIwMTAucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABU8TbPaFJgAAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAAlyb3Nlbi16dmkAABAACAAAzuyrrAAAABEACAAAz2iKoAAAAAEAFABU7c8AFDHEAAUznwAFM54AAMBHAAIAQU1hY2ludG9zaCBIRDpVc2VyczoAY2ptYXk6AERvY3VtZW50czoAUGFwZXJzOgByb3Nlbi16dmk6ADIwMTAucGRmAAAOABIACAAyADAAMQAwAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgAvVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9yb3Nlbi16dmkvMjAxMC5wZGYAABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4ArQCyALoCUAJSAlcCYgJrAnkCfQKEAo0CkgKfAqICtAK3ArwAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACvg==}}

@inproceedings{rosen-zvi2004,
	Author = {Michal Rosen-Zvi and Thomas Griffiths and Mark Steyvers and Padhraic Smyth},
	Booktitle = {Proceedings of the 20th Conference on Uncertainty in Artificial Intelligence (UAI)},
	Date-Added = {2014-04-07 17:00:21 +0000},
	Date-Modified = {2014-04-07 17:01:06 +0000},
	Title = {The Author-Topic Model for Authors and Documents},
	Year = {2004},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QHC4uL1BhcGVycy9yb3Nlbi16dmkvMjAwNC5wZGbSFwsYGVdOUy5kYXRhTxEBkgAAAAABkgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAAVO3PCDIwMDQucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABU7JjPaFHSAAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAAlyb3Nlbi16dmkAABAACAAAzuyrrAAAABEACAAAz2iKEgAAAAEAFABU7c8AFDHEAAUznwAFM54AAMBHAAIAQU1hY2ludG9zaCBIRDpVc2VyczoAY2ptYXk6AERvY3VtZW50czoAUGFwZXJzOgByb3Nlbi16dmk6ADIwMDQucGRmAAAOABIACAAyADAAMAA0AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgAvVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9yb3Nlbi16dmkvMjAwNC5wZGYAABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4ArQCyALoCUAJSAlcCYgJrAnkCfQKEAo0CkgKfAqICtAK3ArwAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACvg==}}

@unpublished{orbanz2013,
	Author = {Peter Orbanz and Daniel M. Roy},
	Date-Added = {2014-04-05 00:27:18 +0000},
	Date-Modified = {2014-04-05 00:28:19 +0000},
	Month = {Dec},
	Note = {arXiv:1312.7857v1},
	Title = {{B}ayesian Models of Graphs, Arrays and Other Exchangeable Random Structures},
	Year = {2013},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGS4uL1BhcGVycy9vcmJhbnovMjAxMy5wZGbSFwsYGVdOUy5kYXRhTxEBhgAAAAABhgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAAUzpMCDIwMTMucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABMJwvPVSKHAAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAAZvcmJhbnoAEAAIAADO7KusAAAAEQAIAADPVVrHAAAAAQAUAFM6TAAUMcQABTOfAAUzngAAwEcAAgA+TWFjaW50b3NoIEhEOlVzZXJzOgBjam1heToARG9jdW1lbnRzOgBQYXBlcnM6AG9yYmFuejoAMjAxMy5wZGYADgASAAgAMgAwADEAMwAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIALFVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvb3JiYW56LzIwMTMucGRmABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AqgCvALcCQQJDAkgCUwJcAmoCbgJ1An4CgwKQApMCpQKoAq0AAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACrw==}}

@unpublished{anandkumar2014,
	Author = {Anima Anandkumar and Rong Ge and Daniel Hsu and Sham M. Kakade and Matus Telgarsky},
	Date-Added = {2014-04-05 00:21:02 +0000},
	Date-Modified = {2014-04-05 00:22:06 +0000},
	Month = {Mar},
	Note = {arXiv:1210.7559v3},
	Title = {Tensor Decompositions for Learning Latent Variable Models},
	Year = {2014},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QHS4uL1BhcGVycy9hbmFuZGt1bWFyLzIwMTQucGRm0hcLGBlXTlMuZGF0YU8RAZIAAAAAAZIAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM7sZVxIKwAAAFM51ggyMDE0LnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAATvd/z1sergAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAKYW5hbmRrdW1hcgAQAAgAAM7sq6wAAAARAAgAAM9bVu4AAAABABQAUznWABQxxAAFM58ABTOeAADARwACAEJNYWNpbnRvc2ggSEQ6VXNlcnM6AGNqbWF5OgBEb2N1bWVudHM6AFBhcGVyczoAYW5hbmRrdW1hcjoAMjAxNC5wZGYADgASAAgAMgAwADEANAAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAMFVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvYW5hbmRrdW1hci8yMDE0LnBkZgATAAEvAAAVAAIADP//AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAK4AswC7AlECUwJYAmMCbAJ6An4ChQKOApMCoAKjArUCuAK9AAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAr8=}}

@unpublished{clarkson2013,
	Author = {Kenneth L. Clarkson and David P. Woodruff},
	Date-Added = {2014-04-05 00:19:38 +0000},
	Date-Modified = {2014-04-05 00:20:46 +0000},
	Month = {Apr},
	Note = {arXiv:1207.6365v4},
	Title = {Low Rank Approximation and Regression in Input Sparsity Time},
	Year = {2013},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGy4uL1BhcGVycy9jbGFya3Nvbi8yMDEzLnBkZtIXCxgZV05TLmRhdGFPEQGMAAAAAAGMAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADO7GVcSCsAAABTOcsIMjAxMy5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAE7+gM9bTYMAAAAAAAAAAAABAAMAAAkgAAAAAAAAAAAAAAAAAAAACGNsYXJrc29uABAACAAAzuyrrAAAABEACAAAz1uFwwAAAAEAFABTOcsAFDHEAAUznwAFM54AAMBHAAIAQE1hY2ludG9zaCBIRDpVc2VyczoAY2ptYXk6AERvY3VtZW50czoAUGFwZXJzOgBjbGFya3NvbjoAMjAxMy5wZGYADgASAAgAMgAwADEAMwAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIALlVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvY2xhcmtzb24vMjAxMy5wZGYAEwABLwAAFQACAAz//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgCsALEAuQJJAksCUAJbAmQCcgJ2An0ChgKLApgCmwKtArACtQAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAK3}}

@article{bartal2004,
	Author = {Yair Bartal and John W. Byers and Danny Raz},
	Date-Added = {2014-04-05 00:18:12 +0000},
	Date-Modified = {2014-04-05 00:19:27 +0000},
	Journal = {SIAM Journal on Computation},
	Number = {6},
	Pages = {1261--1279},
	Title = {Fast, Distributed Approximation Algorithms for Positive Linear Programming with Applications to Flow Control},
	Volume = {33},
	Year = {2004},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGS4uL1BhcGVycy9iYXJ0YWwvMjAwNC5wZGbSFwsYGVdOUy5kYXRhTxEBhgAAAAABhgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAAUzm8CDIwMDQucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABPBcLPW1EWAAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAAZiYXJ0YWwAEAAIAADO7KusAAAAEQAIAADPW4lWAAAAAQAUAFM5vAAUMcQABTOfAAUzngAAwEcAAgA+TWFjaW50b3NoIEhEOlVzZXJzOgBjam1heToARG9jdW1lbnRzOgBQYXBlcnM6AGJhcnRhbDoAMjAwNC5wZGYADgASAAgAMgAwADAANAAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIALFVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvYmFydGFsLzIwMDQucGRmABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AqgCvALcCQQJDAkgCUwJcAmoCbgJ1An4CgwKQApMCpQKoAq0AAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACrw==}}

@article{blei2010,
	Author = {David M. Blei and Thomas L. Griffiths and Michael I. Jordan},
	Comments = {Blei et al. (2010) introduce the nested Chinese restaurant process (nCRP), a stochastic process that generates a hierarchy of partitions of a countably infinite set. This can be interpreted as a nonparametric hierarchical clustering; the number of clusters is almost surely infinite. The nCRP is a natural extension of the Chinese restaurant process (CRP), a stochastic process that generates a partition of a countably infinite set. The nCRP generates a tree whose nodes are CRPs; a customer sitting at a given table is sent to a child node (restaurant) corresponding to that table. Blei et al. apply the nCRP as a prior on the topics of a text corpus, arriving at what they call hierarchical LDA (hLDA). In particular, a word distribution is associated with each node (topic) in the tree, each document is allocated a distribution over a single (infinite) path from the root of the tree (according to a two-parameter GEM distribution, a generalization of the CRP), and each token in that document is allocated a topic drawn from that distribution. The topic at each node in the tree contains word types common to the child nodes; that is, it is (loosely) the intersection of its children, not the union. Blei et al. perform experiments using collapsed Gibbs sampling to learn the hLDA model with interleaved Metropolis-Hastings steps on the hyperparameters. On simulated data, where the tree depth is truncated to three, the chain is shown to mix well and the inferred structure aligns with the truth in six out of eight trials. On journal abstracts, also with tree depth truncated to three, the inferred topic hierarchy is qualitatively reasonable; in particular, the root node contains mostly function words while the descendent topics consist mostly of content words (organized in a logical fashion). On this dataset hLDA is also compared against LDA, where the number of topics in LDA is varied to bracket the number of topics found by hLDA (specifically, the number of topics ranges from zero to 400). Predictive held-out likelihood is used as the evaluation metric. The likelihood obtained by hLDA dominates that obtained by LDA, although LDA's performance increases with the number of topics and the authors expect it to overtake hLDA for sufficiently many topics. The authors also suggest that it would be beneficial to extend hLDA (hence nCRP) to endow each document with a topic distribution over \emph{multiple} paths in the tree.},
	Date-Added = {2014-04-05 00:07:59 +0000},
	Date-Modified = {2014-04-05 00:09:22 +0000},
	Journal = {Journal of the ACM},
	Number = {2},
	Pages = {1--30},
	Title = {The Nested Chinese Restaurant Process and {B}ayesian Nonparametric Inference of Topic Hierarchies},
	Volume = {57},
	Year = {2010},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QFy4uL1BhcGVycy9ibGVpLzIwMTAucGRm0hcLGBlXTlMuZGF0YU8RAYAAAAAAAYAAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM7sZVxIKwAAABQyLggyMDEwLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAUzCcz2S98QAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAEYmxlaQAQAAgAAM7sq6wAAAARAAgAAM9k9jEAAAABABQAFDIuABQxxAAFM58ABTOeAADARwACADxNYWNpbnRvc2ggSEQ6VXNlcnM6AGNqbWF5OgBEb2N1bWVudHM6AFBhcGVyczoAYmxlaToAMjAxMC5wZGYADgASAAgAMgAwADEAMAAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAKlVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvYmxlaS8yMDEwLnBkZgATAAEvAAAVAAIADP//AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAKgArQC1AjkCOwJAAksCVAJiAmYCbQJ2AnsCiAKLAp0CoAKlAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAqc=}}

@inproceedings{irvine2014,
	Author = {Ann Irvine and Joshua Langfus and Chris Callison-Burch},
	Booktitle = {Proceedings of the Language Resources and Evaluation Conference},
	Date-Added = {2014-04-04 20:21:02 +0000},
	Date-Modified = {2014-04-04 20:23:14 +0000},
	Title = {The American Local News Corpus},
	Year = {2014},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGS4uL1BhcGVycy9pcnZpbmUvMjAxNC5wZGbSFwsYGVdOUy5kYXRhTxEBhgAAAAABhgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAAUyOZCDIwMTQucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABO9WvPWxmQAAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAAZpcnZpbmUAEAAIAADO7KusAAAAEQAIAADPW1HQAAAAAQAUAFMjmQAUMcQABTOfAAUzngAAwEcAAgA+TWFjaW50b3NoIEhEOlVzZXJzOgBjam1heToARG9jdW1lbnRzOgBQYXBlcnM6AGlydmluZToAMjAxNC5wZGYADgASAAgAMgAwADEANAAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIALFVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvaXJ2aW5lLzIwMTQucGRmABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AqgCvALcCQQJDAkgCUwJcAmoCbgJ1An4CgwKQApMCpQKoAq0AAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACrw==}}

@inproceedings{ahmed2013a,
	Author = {Amr Ahmed and Linagjie Hong and Alex Smola},
	Booktitle = {WWW},
	Comments = {Ahmed et al. essentially present the nested Chinese restaurant franchise (nCRF) again (see also the ICML paper in the same year). However, they tailor the introduction more towards the geolocation modeling task and spend less space developing the model and more space discussing the details of inference. In particular, they describe their use of the multi-scale Kalman filter and the auxiliary variable method that were relegated to the ``Appendix'' of the other paper. They also discuss the ablation study in somewhat greater detail and present results of a brief error analysis that shows their model makes smaller errors on the coasts of the U.S. but provides a greater improvement over previous state-of-the-art in the Midwest.},
	Date-Added = {2014-04-04 16:05:03 +0000},
	Date-Modified = {2014-04-04 16:06:03 +0000},
	Title = {Hierarchical Geographical Modeling of User Locations from Social Media Posts},
	Year = {2013},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGS4uL1BhcGVycy9haG1lZC8yMDEzYS5wZGbSFwsYGVdOUy5kYXRhTxEBiAAAAAABiAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAAFDH9CTIwMTNhLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABQo9bPYNOZAAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAAVhaG1lZAAAEAAIAADO7KusAAAAEQAIAADPYQvZAAAAAQAUABQx/QAUMcQABTOfAAUzngAAwEcAAgA+TWFjaW50b3NoIEhEOlVzZXJzOgBjam1heToARG9jdW1lbnRzOgBQYXBlcnM6AGFobWVkOgAyMDEzYS5wZGYADgAUAAkAMgAwADEAMwBhAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgAsVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9haG1lZC8yMDEzYS5wZGYAEwABLwAAFQACAAz//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgCqAK8AtwJDAkUCSgJVAl4CbAJwAncCgAKFApIClQKnAqoCrwAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAKx}}

@inproceedings{ahmed2013,
	Author = {Amr Ahmed and Linagjie Hong and Alexander J. Smola},
	Booktitle = {Proceedings of the 30th International Conference on Machine Learning (ICML)},
	Comments = {Ahmed et al. introduce the nested Chinese restaurant franchise (nCRF), a nonparametric Bayesian model of sets of tree structures built on the the Chinese restaurant franchise (CRF) and the nested Chinese restaurant process (nCRP). Essentially, the nCRF is a CRF whose elements are nCRPs. The generative story is that we first generate an infinite tree of CRPs using the nCRP. This is the ``global'' tree. If we apply a personalization metaphor, then for each ``user'' we generate an infinite tree of CRPs using the nCRP, where each node is drawn from the corresponding node in the global tree as in a CRF. Ahmed et al. describe a stick-breaking construction for the nCRF. The nCRF is applied as a prior on two observation models, a personalized joint hierarchical model of language and location for microblog data, and a comparatively simple topic model. In the microblog model, each tree represents a user, and each node of the nCRF is endowed with Gaussian parameters representing geolocation and Dirichlet parameters representing topic proportions and word proportions (a ``topic'' in the sense of latent Dirichlet allocation). All parameters are cascaded down the tree, facilitating specialization as a path of the tree is traversed. A global set of $T$ topics is also drawn; microblog entries are modeled using an LDA-like model with $T+1$ topics, where drawing the final topic corresponds to drawing a word from the user's regional language model. In the second observation model, the topic model, each tree of the nCRF represents a document, and each word in the document is drawn as a path from that tree. This is an improvement to the application of the nCRP to topic modeling, in which each document was modeled as a path from the tree and each word was constrained to use a topic from one of the nodes along that path. Ahmed et al. briefly describe inference using an exact Gibbs sampler and using an approximate Metropolis-Hastings sampler. They note that the implementation depends on how the nCRF is used; it will vary according to what kinds of variables are attributed to nodes of the trees. In the microblog application, sampling the Gaussian cascade is implemented using a multiscale Kalman filter and sampling the Dirichlet-multinomial cascades is implemented using the Antoniak distribution or a min-path/max-path approximation (depending on whether the cardinality is small or large, respectively). Experiments are performed on two Twitter datasets, one owned by the authors and one provided as a reference by previous authors. The model based on nCRF, implemented using the Metropolis-Hastings sampler, dominates other state-of-the-art models on the task of location prediction. The Gibbs implementation performs even better. It's shown that the nCRF prefers significantly larger numbers of regions (tree nodes) than the other models. An ablation study is also performed, revealing that each aspect of the nCRF model improves performance but the nested (tree-structured) regional language models appeared to provide the largest improvement. A topic modeling experiment, in which the topic model built on nCRF is compared against other hierarchical topic models on NIPS abstracts, is also briefly discussed; the nCRF model achieves better held-out likelihood than the other models and also produces a qualitatively reasonable hierarchy of topics.},
	Date-Added = {2014-04-04 16:04:01 +0000},
	Date-Modified = {2014-04-04 16:04:50 +0000},
	Title = {Nested Chinese Restaurant Franchise Processes: Applications to User Tracking and Document Modeling},
	Year = {2013},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGC4uL1BhcGVycy9haG1lZC8yMDEzLnBkZtIXCxgZV05TLmRhdGFPEQGGAAAAAAGGAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADO7GVcSCsAAAAUMf0IMjAxMy5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFCjcM9g05MAAAAAAAAAAAABAAMAAAkgAAAAAAAAAAAAAAAAAAAABWFobWVkAAAQAAgAAM7sq6wAAAARAAgAAM9hC9MAAAABABQAFDH9ABQxxAAFM58ABTOeAADARwACAD1NYWNpbnRvc2ggSEQ6VXNlcnM6AGNqbWF5OgBEb2N1bWVudHM6AFBhcGVyczoAYWhtZWQ6ADIwMTMucGRmAAAOABIACAAyADAAMQAzAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgArVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9haG1lZC8yMDEzLnBkZgAAEwABLwAAFQACAAz//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgCpAK4AtgJAAkICRwJSAlsCaQJtAnQCfQKCAo8CkgKkAqcCrAAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAKu}}

@inproceedings{ermon2013,
	Author = {Stefano Ermon and Carla P. Gomes and Ashish Sabharwal and Bart Selman},
	Booktitle = {Proceedings of the 30th International Conference on Machine Learning (ICML)},
	Comments = {Ermon et al. (2013) provide an approximation algorithm for discrete integration in high dimensions via random hashing and constrained optimization. In particular, they present an algorithm that yields a 16-approximation to the integral with probability $1 - \delta$ and show that this algorithm can be invoked on a (Cartesian) power of the input space to yield a $(1+\epsilon)$-approximation. The algorithm proceeds by repeatedly sampling pairwise independent hash functions, each of which defines a constraint on the input space, and computing maximum a posteriori (MAP) queries under the constraints. These values are aggregated to produce the estimate of the integral. In total, on the order of $n \log(n/\delta)$ MAP queries are required to achieve the 16-approximation with probability $1 - \delta$. However, during iteration of the algorithm, the intermediate result is always an approximate lower bound on the true value of the integral and is non-decreasing, so the algorithm is anytime. This holds even if the optimization routine used to perform the MAP query is terminated before optimality. Ermon et al. also note that the inner loop of their algorithm is trivially parallelizable. In experiments on Ising models, the authors find that their algorithm (WISH) consistently performs as well as alternative methods including mean field and belief propagation. WISH is also able to estimate the number of solutions in Sudoku, where mean field and belief propagation fail, and produce qualitatively good likelihood estimates for model selection in handwritten digit recognition.},
	Date-Added = {2014-04-02 04:08:36 +0000},
	Date-Modified = {2014-04-02 04:10:38 +0000},
	Title = {Taming the Curse of Dimensionality: Discrete Integration by Hashing and Optimization},
	Year = {2013},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGC4uL1BhcGVycy9lcm1vbi8yMDEzLnBkZtIXCxgZV05TLmRhdGFPEQGGAAAAAAGGAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADO7GVcSCsAAABRQHEIMjAxMy5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAE4qfM9Z9g8AAAAAAAAAAAABAAMAAAkgAAAAAAAAAAAAAAAAAAAABWVybW9uAAAQAAgAAM7sq6wAAAARAAgAAM9aLk8AAAABABQAUUBxABQxxAAFM58ABTOeAADARwACAD1NYWNpbnRvc2ggSEQ6VXNlcnM6AGNqbWF5OgBEb2N1bWVudHM6AFBhcGVyczoAZXJtb246ADIwMTMucGRmAAAOABIACAAyADAAMQAzAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgArVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9lcm1vbi8yMDEzLnBkZgAAEwABLwAAFQACAAz//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgCpAK4AtgJAAkICRwJSAlsCaQJtAnQCfQKCAo8CkgKkAqcCrAAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAKu}}

@inproceedings{zeger1994,
	Author = {Kenneth Zeger and Allen Gersho},
	Booktitle = {IEEE International Symposium on Information Theory},
	Date-Added = {2014-03-06 15:47:21 +0000},
	Date-Modified = {2014-03-06 15:49:26 +0000},
	Title = {How Many Points in Euclidean Space can have a Common Nearest Neighbor?},
	Year = {1994},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGC4uL1BhcGVycy96ZWdlci8xOTk0LnBkZtIXCxgZV05TLmRhdGFPEQGGAAAAAAGGAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADO7GVcSCsAAAA8Cu4IMTk5NC5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADu0bM881dsAAAAAAAAAAAABAAMAAAkgAAAAAAAAAAAAAAAAAAAABXplZ2VyAAAQAAgAAM7sq6wAAAARAAgAAM89HCsAAAABABQAPAruABQxxAAFM58ABTOeAADARwACAD1NYWNpbnRvc2ggSEQ6VXNlcnM6AGNqbWF5OgBEb2N1bWVudHM6AFBhcGVyczoAemVnZXI6ADE5OTQucGRmAAAOABIACAAxADkAOQA0AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgArVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy96ZWdlci8xOTk0LnBkZgAAEwABLwAAFQACAAz//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgCpAK4AtgJAAkICRwJSAlsCaQJtAnQCfQKCAo8CkgKkAqcCrAAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAKu}}

@inbook{murphy2001,
	Author = {Kevin Murphy and Stuart Russell},
	Chapter = {24},
	Comments = {Murphy and Russell (2001) describe how to use Rao-Blackwellization to reduce the variance in a particle filter (specifically, variance in the transition step) by marginalizing out some of the latent variables. This work overlaps that by Doucet et al. (2000) fundamentally, but focuses less on theoretical results and more on modeling questions, and empirical findings. The choice of which latent variables to marginalize out is considered in detail, with several examples; ultimately, however, it is left up to the modeler's preference and available computational resources. (A rule of thumb is to start with all variables marginalized out and remove variables from marginalization until the exact update step on the marginalized variables becomes computationally tractable.) Murphy and Russell (2001) restate the empirical results of Doucet et al. (2000) and also consider a more challenging robot localization problem in which the state space has size $2^100$ and the environment is a dynamic $10 \times 10$ grid. With 200 particles, the Rao-Blackwellized particle filter learns most of the map within 50 time steps.},
	Crossref = {doucet2001},
	Date-Added = {2014-03-06 03:22:26 +0000},
	Date-Modified = {2014-03-06 03:23:18 +0000},
	Publisher = {Springer},
	Title = {{R}ao-{B}lackwellised Particle Filtering for Dynamic {B}ayesian Networks},
	Year = {2001}}

@inbook{musso2001,
	Author = {Christian Musso and Nadia Oudjane and Francois Le Gland},
	Chapter = {12},
	Crossref = {doucet2001},
	Date-Added = {2014-03-06 03:21:44 +0000},
	Date-Modified = {2014-03-06 03:22:24 +0000},
	Publisher = {Springer},
	Title = {Improving Regularised Particle Filters},
	Year = {2001}}

@inbook{bolviken2001,
	Author = {Erik Bolviken and Geir Storvik},
	Chapter = {5},
	Crossref = {doucet2001},
	Date-Added = {2014-03-06 03:20:36 +0000},
	Date-Modified = {2014-03-06 03:21:43 +0000},
	Publisher = {Springer},
	Title = {Deterministic and Stochastic Particle Filters in State-Space Models},
	Year = {2001}}

@inbook{liu2001a,
	Author = {Jane Liu and Mike West},
	Chapter = {10},
	Crossref = {doucet2001},
	Date-Added = {2014-03-06 03:18:51 +0000},
	Date-Modified = {2014-03-06 03:19:23 +0000},
	Publisher = {Springer},
	Title = {Combined Parameter and State Estimation in Simulation-Based Filtering},
	Year = {2001}}

@inbook{stavropoulos2001,
	Author = {Photis Stavropoulos and D. M. Titterington},
	Chapter = {14},
	Crossref = {doucet2001},
	Date-Added = {2014-03-06 03:17:17 +0000},
	Date-Modified = {2014-03-06 03:18:19 +0000},
	Publisher = {Springer},
	Title = {Improved Particle Filters and Smoothing},
	Year = {2001}}

@inbook{pitt2001,
	Author = {Michael K. Pitt and Neil Shephard},
	Chapter = {13},
	Crossref = {doucet2001},
	Date-Added = {2014-03-06 03:14:53 +0000},
	Date-Modified = {2014-03-06 03:15:36 +0000},
	Publisher = {Springer},
	Title = {Auxiliary Variable Based Particle Filters},
	Year = {2001}}

@inbook{liu2001,
	Author = {Jun S. Liu and Rong Chen and Tanya Logvinenko},
	Chapter = {11},
	Crossref = {doucet2001},
	Date-Added = {2014-03-06 03:13:55 +0000},
	Date-Modified = {2014-03-06 03:16:19 +0000},
	Publisher = {Springer},
	Title = {A Theoretical Framework for Sequential Importance Sampling with Resampling},
	Year = {2001}}

@inbook{godsill2001,
	Author = {Simon Godsill and Tim Clapp},
	Chapter = {7},
	Crossref = {doucet2001},
	Date-Added = {2014-03-06 03:13:01 +0000},
	Date-Modified = {2014-03-06 03:13:30 +0000},
	Publisher = {Springer},
	Title = {Improvement Strategies for {M}onte {C}arlo Particle Filters},
	Year = {2001}}

@inbook{berzuini2001,
	Author = {Carlo Berzuini and Walter Gilks},
	Chapter = {6},
	Comments = {Berzuini and Gilks (2001) review their resample-move framework, in which MCMC steps are incorporated into a particle filter to enable moving to any location in state space at any timestep, and discuss how to apply this framework in the presence of model uncertainty. Specifically, in the setting where a sequence of observations is believed to have arisen from one of a finite set of models, the MCMC rejuvenation steps of the resample-move algorithm can move a particle within the state space of a single model, or can move a particle to a different model. As an example application, Berzuini and Gilks suggest the problem of tracking an airborne object that is believed to be an airplane or a missile---we do not know which type the object is, and the dynamics depend on that type. Berzuini and Gilks apply their framework to the toy problem of ship tracking in the plane, when there is uncertainty as to whether the ship is moving in both dimensions or only along the $x$ axis. (In this setting, the latter model is ``nested'' in the former, and the Metropolis Hastings proposals to move between models are particularly simple.) With 3000 particles, they find the resample-move algorithm achieves higher accuracy than the standard SIR filter. In the conclusion, it's suggested that the resample-move algorithm may be preferable to standard MCMC even when the data does not arrive sequentially, because the interaction of the particles improves mixing and reduces the impact of the choice of proposal distribution.},
	Crossref = {doucet2001},
	Date-Added = {2014-03-06 03:12:09 +0000},
	Date-Modified = {2014-03-06 03:12:40 +0000},
	Publisher = {Springer},
	Title = {RESAMPLE-MOVE Filtering with Cross-Model Jumps},
	Year = {2001}}

@inbook{andrieu2001,
	Author = {Christophe Andrieu and Arnaud Doucet and Elena Punskaya},
	Chapter = {4},
	Crossref = {doucet2001},
	Date-Added = {2014-03-06 03:10:27 +0000},
	Date-Modified = {2014-03-06 03:11:50 +0000},
	Publisher = {Springer},
	Title = {Sequential {M}onte {C}arlo Methods for Optimal Filtering},
	Year = {2001}}

@inbook{crisan2001,
	Author = {Dan Crisan},
	Chapter = {2},
	Crossref = {doucet2001},
	Date-Added = {2014-03-06 03:09:57 +0000},
	Date-Modified = {2014-03-06 03:10:22 +0000},
	Publisher = {Springer},
	Title = {Particle Filters -- A Theoretical Perspective},
	Year = {2001}}

@inbook{doucet2001b,
	Author = {Arnaud Doucet and Nando {de Freitas} and Neil Gordon},
	Chapter = {1},
	Comments = {Doucet et al. introduce sequential Monte Carlo estimation from the ground up. Specifically, they take the problem of estimating the expectation of a function under the posterior distribution in a Markov process, show how to update the posterior recursively (exactly, in theory), and then derive sequential importance sampling (the basic particle filter) as an application of Monte Carlo sampling to recursive posterior estimation. They extend this algorithm to the bootstrap filter, in which particles are resampled according to their weights after every state transition. The resampling procedure is justified by observation that importance sampling is inefficient in high dimensions, and statement of a bound on the squared error of the expectation of any bounded function under the resampled posterior. Finally, the bootstrap filter is briefly demonstrated on a one-dimensional toy problem.},
	Crossref = {doucet2001},
	Date-Added = {2014-03-06 03:00:25 +0000},
	Date-Modified = {2014-03-06 03:08:46 +0000},
	Publisher = {Springer},
	Title = {An Introduction to Sequential {M}onte {C}arlo Methods},
	Year = {2001}}

@article{chen2009,
	Author = {Ke Chen},
	Date-Added = {2014-03-05 17:57:42 +0000},
	Date-Modified = {2014-03-05 17:59:40 +0000},
	Journal = {SIAM Journal on Computation},
	Number = {3},
	Pages = {923--947},
	Title = {On Coresets for k-Median and k-Means Clustering in Metric and Euclidean Spaces and their Applications},
	Volume = {39},
	Year = {2009},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QFy4uL1BhcGVycy9jaGVuLzIwMDkucGRm0hcLGBlXTlMuZGF0YU8RAYAAAAAAAYAAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM7sZVxIKwAAADWl1QgyMDA5LnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAO6+NzzzBmAAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAEY2hlbgAQAAgAAM7sq6wAAAARAAgAAM89B+gAAAABABQANaXVABQxxAAFM58ABTOeAADARwACADxNYWNpbnRvc2ggSEQ6VXNlcnM6AGNqbWF5OgBEb2N1bWVudHM6AFBhcGVyczoAY2hlbjoAMjAwOS5wZGYADgASAAgAMgAwADAAOQAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAKlVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvY2hlbi8yMDA5LnBkZgATAAEvAAAVAAIADP//AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAKgArQC1AjkCOwJAAksCVAJiAmYCbQJ2AnsCiAKLAp0CoAKlAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAqc=}}

@article{doucet2001a,
	Author = {Arnaud Doucet and Neil J. Gordon and Vikram Krishnamurthy},
	Date-Added = {2014-03-04 02:50:00 +0000},
	Date-Modified = {2014-03-04 02:51:24 +0000},
	Journal = {IEEE Transactions on Signal Processing},
	Month = {Mar},
	Number = {3},
	Pages = {613--624},
	Title = {Particle Filters for State Estimation of Jump Markov Linear Systems},
	Volume = {49},
	Year = {2001},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGS4uL1BhcGVycy9kb3VjZXQvMjAwMS5wZGbSFwsYGVdOUy5kYXRhTxEBhgAAAAABhgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAAFDI/CDIwMDEucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA6qinPOnRpAAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAAZkb3VjZXQAEAAIAADO7KusAAAAEQAIAADPOrq5AAAAAQAUABQyPwAUMcQABTOfAAUzngAAwEcAAgA+TWFjaW50b3NoIEhEOlVzZXJzOgBjam1heToARG9jdW1lbnRzOgBQYXBlcnM6AGRvdWNldDoAMjAwMS5wZGYADgASAAgAMgAwADAAMQAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIALFVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvZG91Y2V0LzIwMDEucGRmABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AqgCvALcCQQJDAkgCUwJcAmoCbgJ1An4CgwKQApMCpQKoAq0AAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACrw==}}

@article{storvik2002,
	Author = {Geir Storvik},
	Date-Added = {2014-02-24 19:15:20 +0000},
	Date-Modified = {2014-02-24 19:16:43 +0000},
	Journal = {IEEE Transactions on Signal Processing},
	Pages = {281--289},
	Title = {Particle filters for state-space models with the presence of unknown static parameters},
	Year = {2002},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGi4uL1BhcGVycy9zdG9ydmlrLzIwMDIucGRm0hcLGBlXTlMuZGF0YU8RAYwAAAAAAYwAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM7sZVxIKwAAADenZggyMDAyLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAN6EGzzECmQAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAHc3RvcnZpawAAEAAIAADO7KusAAAAEQAIAADPMUjpAAAAAQAUADenZgAUMcQABTOfAAUzngAAwEcAAgA/TWFjaW50b3NoIEhEOlVzZXJzOgBjam1heToARG9jdW1lbnRzOgBQYXBlcnM6AHN0b3J2aWs6ADIwMDIucGRmAAAOABIACAAyADAAMAAyAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgAtVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9zdG9ydmlrLzIwMDIucGRmAAATAAEvAAAVAAIADP//AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAKsAsAC4AkgCSgJPAloCYwJxAnUCfAKFAooClwKaAqwCrwK0AAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAArY=}}

@inproceedings{andrieu1999,
	Author = {Christophe Andrieu and Nando {de Freitas} and Arnaud Doucet},
	Booktitle = {IEEE Signal Processing Workshop on Higher-Order Statistics},
	Date-Added = {2014-02-24 19:09:28 +0000},
	Date-Modified = {2014-02-24 19:14:32 +0000},
	Title = {Sequential MCMC for {B}ayesian model selection},
	Year = {1999},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGi4uL1BhcGVycy9hbmRyaWV1LzE5OTkucGRm0hcLGBlXTlMuZGF0YU8RAYwAAAAAAYwAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM7sZVxIKwAAADemwwgxOTk5LnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAN6CRzzECkgAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAHYW5kcmlldQAAEAAIAADO7KusAAAAEQAIAADPMUjiAAAAAQAUADemwwAUMcQABTOfAAUzngAAwEcAAgA/TWFjaW50b3NoIEhEOlVzZXJzOgBjam1heToARG9jdW1lbnRzOgBQYXBlcnM6AGFuZHJpZXU6ADE5OTkucGRmAAAOABIACAAxADkAOQA5AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgAtVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9hbmRyaWV1LzE5OTkucGRmAAATAAEvAAAVAAIADP//AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAKsAsAC4AkgCSgJPAloCYwJxAnUCfAKFAooClwKaAqwCrwK0AAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAArY=}}

@article{kitagawa1996,
	Author = {Genshiro Kitagawa},
	Date-Added = {2014-02-24 15:11:15 +0000},
	Date-Modified = {2014-02-24 15:12:35 +0000},
	Journal = {Journal of Computational and Graphical Statistics},
	Month = {Mar},
	Number = {1},
	Pages = {1--25},
	Title = {{M}onte {C}arlo Filter and Smoother for Non-Gaussian Nonlinear State Space Models},
	Volume = {5},
	Year = {1996},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGy4uL1BhcGVycy9raXRhZ2F3YS8xOTk2LnBkZtIXCxgZV05TLmRhdGFPEQGMAAAAAAGMAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADO7GVcSCsAAAA3j8UIMTk5Ni5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADd3S88wqcAAAAAAAAAAAAABAAMAAAkgAAAAAAAAAAAAAAAAAAAACGtpdGFnYXdhABAACAAAzuyrrAAAABEACAAAzzDwEAAAAAEAFAA3j8UAFDHEAAUznwAFM54AAMBHAAIAQE1hY2ludG9zaCBIRDpVc2VyczoAY2ptYXk6AERvY3VtZW50czoAUGFwZXJzOgBraXRhZ2F3YToAMTk5Ni5wZGYADgASAAgAMQA5ADkANgAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIALlVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMva2l0YWdhd2EvMTk5Ni5wZGYAEwABLwAAFQACAAz//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgCsALEAuQJJAksCUAJbAmQCcgJ2An0ChgKLApgCmwKtArACtQAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAK3}}

@inproceedings{minka2002,
	Author = {Thomas Minka and John Lafferty},
	Booktitle = {Proceedings of the 18th Conference on Uncertainty in Artificial Intelligence (UAI)},
	Date-Added = {2014-02-24 13:42:55 +0000},
	Date-Modified = {2014-02-24 13:43:26 +0000},
	Month = {Aug},
	Pages = {352--359},
	Title = {Expectation-Propagation for the Generative Aspect Model},
	Year = {2002},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGC4uL1BhcGVycy9taW5rYS8yMDAyLnBkZtIXCxgZV05TLmRhdGFPEQGGAAAAAAGGAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADO7GVcSCsAAAAUMmEIMjAwMi5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADeFPc8wtogAAAAAAAAAAAABAAMAAAkgAAAAAAAAAAAAAAAAAAAABW1pbmthAAAQAAgAAM7sq6wAAAARAAgAAM8w/NgAAAABABQAFDJhABQxxAAFM58ABTOeAADARwACAD1NYWNpbnRvc2ggSEQ6VXNlcnM6AGNqbWF5OgBEb2N1bWVudHM6AFBhcGVyczoAbWlua2E6ADIwMDIucGRmAAAOABIACAAyADAAMAAyAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgArVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9taW5rYS8yMDAyLnBkZgAAEwABLwAAFQACAAz//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgCpAK4AtgJAAkICRwJSAlsCaQJtAnQCfQKCAo8CkgKkAqcCrAAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAKu}}

@inproceedings{song2005,
	Author = {Xiaodan Song and Ching-Yung Lin and Belle L. Tseng and Ming-Ting Sun},
	Booktitle = {Proceedings of the 11th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
	Date-Added = {2014-02-24 13:40:00 +0000},
	Date-Modified = {2014-02-24 13:40:49 +0000},
	Title = {Modeling and Predicting Personal Information Dissemination Behavior},
	Year = {2005},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QFy4uL1BhcGVycy9zb25nLzIwMDUucGRm0hcLGBlXTlMuZGF0YU8RAYAAAAAAAYAAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM7sZVxIKwAAADeDDwgyMDA1LnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAN4CYzzC10QAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAEc29uZwAQAAgAAM7sq6wAAAARAAgAAM8w/CEAAAABABQAN4MPABQxxAAFM58ABTOeAADARwACADxNYWNpbnRvc2ggSEQ6VXNlcnM6AGNqbWF5OgBEb2N1bWVudHM6AFBhcGVyczoAc29uZzoAMjAwNS5wZGYADgASAAgAMgAwADAANQAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAKlVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvc29uZy8yMDA1LnBkZgATAAEvAAAVAAIADP//AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAKgArQC1AjkCOwJAAksCVAJiAmYCbQJ2AnsCiAKLAp0CoAKlAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAqc=}}

@book{doucet2001,
	Address = {New York},
	Date-Added = {2014-02-24 13:36:19 +0000},
	Date-Modified = {2014-02-24 13:37:21 +0000},
	Editor = {Arnaud Doucet and Nando {de Freitas} and Neil Gordon},
	Publisher = {Springer},
	Title = {Sequential {M}onte {C}arlo Methods in Practice},
	Year = {2001}}

@article{liu1998,
	Author = {Jun S. Liu and Rong Chen},
	Date-Added = {2014-02-24 13:33:58 +0000},
	Date-Modified = {2014-02-24 13:35:34 +0000},
	Journal = {Journal of the American Statistical Association},
	Month = {Sep},
	Number = {443},
	Pages = {1032--1044},
	Title = {Sequential {M}onte {C}arlo Methods for Dynamic Systems},
	Volume = {93},
	Year = {1998},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QFi4uL1BhcGVycy9saXUvMTk5OC5wZGbSFwsYGVdOUy5kYXRhTxEBgAAAAAABgAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAANZmJCDE5OTgucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA3dQ3PMKi8AAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAANsaXUAABAACAAAzuyrrAAAABEACAAAzzDvDAAAAAEAFAA1mYkAFDHEAAUznwAFM54AAMBHAAIAO01hY2ludG9zaCBIRDpVc2VyczoAY2ptYXk6AERvY3VtZW50czoAUGFwZXJzOgBsaXU6ADE5OTgucGRmAAAOABIACAAxADkAOQA4AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgApVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9saXUvMTk5OC5wZGYAABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4ApwCsALQCOAI6Aj8CSgJTAmECZQJsAnUCegKHAooCnAKfAqQAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACpg==}}

@article{pitt1999,
	Author = {Michael K. Pitt and Neil Shephard},
	Date-Added = {2014-02-24 03:41:32 +0000},
	Date-Modified = {2014-02-24 03:47:34 +0000},
	Journal = {Journal of the American Statistical Association},
	Month = {Jun},
	Number = {446},
	Pages = {590--599},
	Title = {Filtering via simulation: Auxiliary particle filters},
	Volume = {94},
	Year = {1999},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QFy4uL1BhcGVycy9waXR0LzE5OTkucGRm0hcLGBlXTlMuZGF0YU8RAYAAAAAAAYAAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM7sZVxIKwAAADdTwQgxOTk5LnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANzL4zzAoPQAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAEcGl0dAAQAAgAAM7sq6wAAAARAAgAAM8wbo0AAAABABQAN1PBABQxxAAFM58ABTOeAADARwACADxNYWNpbnRvc2ggSEQ6VXNlcnM6AGNqbWF5OgBEb2N1bWVudHM6AFBhcGVyczoAcGl0dDoAMTk5OS5wZGYADgASAAgAMQA5ADkAOQAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAKlVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvcGl0dC8xOTk5LnBkZgATAAEvAAAVAAIADP//AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAKgArQC1AjkCOwJAAksCVAJiAmYCbQJ2AnsCiAKLAp0CoAKlAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAqc=}}

@inproceedings{lee2006,
	Author = {Su-In Lee and Varun Ganapathi and Daphne Koller},
	Booktitle = {Advances in Neural Information Processing Systems 19 (NIPS)},
	Date-Added = {2014-02-24 02:03:32 +0000},
	Date-Modified = {2014-02-24 02:04:39 +0000},
	Title = {Efficient Structure Learning of Markov Networks using L1-Regularization},
	Year = {2006},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QFi4uL1BhcGVycy9sZWUvMjAwNi5wZGbSFwsYGVdOUy5kYXRhTxEBgAAAAAABgAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAANysaCDIwMDYucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA3KIPPMBKHAAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAANsZWUAABAACAAAzuyrrAAAABEACAAAzzBY1wAAAAEAFAA3KxoAFDHEAAUznwAFM54AAMBHAAIAO01hY2ludG9zaCBIRDpVc2VyczoAY2ptYXk6AERvY3VtZW50czoAUGFwZXJzOgBsZWU6ADIwMDYucGRmAAAOABIACAAyADAAMAA2AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgApVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9sZWUvMjAwNi5wZGYAABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4ApwCsALQCOAI6Aj8CSgJTAmECZQJsAnUCegKHAooCnAKfAqQAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACpg==}}

@unpublished{minka2000,
	Author = {Thomas P. Minka},
	Date-Added = {2014-02-23 15:33:18 +0000},
	Date-Modified = {2014-02-23 15:33:58 +0000},
	Month = {Dec},
	Title = {Old and New Matrix Algebra Useful for Statistics},
	Year = {2000},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGC4uL1BhcGVycy9taW5rYS8yMDAwLnBkZtIXCxgZV05TLmRhdGFPEQGGAAAAAAGGAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADO7GVcSCsAAAAUMmEIMjAwMC5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADYXTc8sUwwAAAAAAAAAAAABAAMAAAkgAAAAAAAAAAAAAAAAAAAABW1pbmthAAAQAAgAAM7sq6wAAAARAAgAAM8smVwAAAABABQAFDJhABQxxAAFM58ABTOeAADARwACAD1NYWNpbnRvc2ggSEQ6VXNlcnM6AGNqbWF5OgBEb2N1bWVudHM6AFBhcGVyczoAbWlua2E6ADIwMDAucGRmAAAOABIACAAyADAAMAAwAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgArVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9taW5rYS8yMDAwLnBkZgAAEwABLwAAFQACAAz//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgCpAK4AtgJAAkICRwJSAlsCaQJtAnQCfQKCAo8CkgKkAqcCrAAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAKu}}

@unpublished{petersen2012,
	Author = {Kaare Brandt Petersen and Michael Syskind Pedersen},
	Date-Added = {2014-02-20 15:49:29 +0000},
	Date-Modified = {2014-02-20 15:50:27 +0000},
	Month = {Nov},
	Title = {The Matrix Cookbook},
	Year = {2012},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGy4uL1BhcGVycy9wZXRlcnNlbi8yMDEyLnBkZtIXCxgZV05TLmRhdGFPEQGMAAAAAAGMAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADO7GVcSCsAAAA12lYIMjAxMi5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADXaO88rjjIAAAAAAAAAAAABAAMAAAkgAAAAAAAAAAAAAAAAAAAACHBldGVyc2VuABAACAAAzuyrrAAAABEACAAAzyvUggAAAAEAFAA12lYAFDHEAAUznwAFM54AAMBHAAIAQE1hY2ludG9zaCBIRDpVc2VyczoAY2ptYXk6AERvY3VtZW50czoAUGFwZXJzOgBwZXRlcnNlbjoAMjAxMi5wZGYADgASAAgAMgAwADEAMgAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIALlVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvcGV0ZXJzZW4vMjAxMi5wZGYAEwABLwAAFQACAAz//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgCsALEAuQJJAksCUAJbAmQCcgJ2An0ChgKLApgCmwKtArACtQAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAK3}}

@inproceedings{wang2013b,
	Author = {Liming Wang and David Carlson and Miguel Dias Rodrigues and David Wilcox and Robert Calderbank and Lawrence Carin},
	Booktitle = {Advances in Neural Information Processing Systems 26 (NIPS)},
	Date-Added = {2014-02-20 15:09:22 +0000},
	Date-Modified = {2014-02-20 15:09:58 +0000},
	Month = {Dec},
	Title = {Designed Measurements for Vector Count Data},
	Year = {2013},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGC4uL1BhcGVycy93YW5nLzIwMTNhLnBkZtIXCxgZV05TLmRhdGFPEQGGAAAAAAGGAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADO7GVcSCsAAAAUMqwJMjAxM2EucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADXM7c8rgU8AAAAAAAAAAAABAAMAAAkgAAAAAAAAAAAAAAAAAAAABHdhbmcAEAAIAADO7KusAAAAEQAIAADPK8efAAAAAQAUABQyrAAUMcQABTOfAAUzngAAwEcAAgA9TWFjaW50b3NoIEhEOlVzZXJzOgBjam1heToARG9jdW1lbnRzOgBQYXBlcnM6AHdhbmc6ADIwMTNhLnBkZgAADgAUAAkAMgAwADEAMwBhAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgArVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy93YW5nLzIwMTNhLnBkZgAAEwABLwAAFQACAAz//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgCpAK4AtgJAAkICRwJSAlsCaQJtAnQCfQKCAo8CkgKkAqcCrAAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAKu}}

@inproceedings{beeferman1997,
	Author = {Doug Beeferman and Adam Berger and John Lafferty},
	Booktitle = {Proceedings of the 35th Annual Meeting of the Association for Computational Linguistics (ACL)},
	Date-Added = {2014-02-20 15:07:03 +0000},
	Date-Modified = {2014-02-20 15:08:59 +0000},
	Title = {A Model of Lexical Attraction and Repulsion},
	Year = {1997},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QHC4uL1BhcGVycy9iZWVmZXJtYW4vMTk5Ny5wZGbSFwsYGVdOUy5kYXRhTxEBkgAAAAABkgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAANdODCDE5OTcucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA1xR3PK39AAAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAAliZWVmZXJtYW4AABAACAAAzuyrrAAAABEACAAAzyvFkAAAAAEAFAA104MAFDHEAAUznwAFM54AAMBHAAIAQU1hY2ludG9zaCBIRDpVc2VyczoAY2ptYXk6AERvY3VtZW50czoAUGFwZXJzOgBiZWVmZXJtYW46ADE5OTcucGRmAAAOABIACAAxADkAOQA3AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgAvVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9iZWVmZXJtYW4vMTk5Ny5wZGYAABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4ArQCyALoCUAJSAlcCYgJrAnkCfQKEAo0CkgKfAqICtAK3ArwAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACvg==}}

@unpublished{wang2013a,
	Author = {Liming Wang and David Carlson and Miguel R. D. Rodrigues and Robert Calderbank and Lawrence Carin},
	Date-Added = {2014-02-20 15:06:13 +0000},
	Date-Modified = {2014-02-20 15:06:48 +0000},
	Title = {A Bregman Matrix and the Gradient of Mutual Information for Vector Poisson and Gaussian Channels},
	Year = {2013},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QFy4uL1BhcGVycy93YW5nLzIwMTMucGRm0hcLGBlXTlMuZGF0YU8RAYAAAAAAAYAAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM7sZVxIKwAAABQyrAgyMDEzLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANc3VzyuBWAAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAEd2FuZwAQAAgAAM7sq6wAAAARAAgAAM8rx6gAAAABABQAFDKsABQxxAAFM58ABTOeAADARwACADxNYWNpbnRvc2ggSEQ6VXNlcnM6AGNqbWF5OgBEb2N1bWVudHM6AFBhcGVyczoAd2FuZzoAMjAxMy5wZGYADgASAAgAMgAwADEAMwAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAKlVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvd2FuZy8yMDEzLnBkZgATAAEvAAAVAAIADP//AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAKgArQC1AjkCOwJAAksCVAJiAmYCbQJ2AnsCiAKLAp0CoAKlAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAqc=}}

@article{oreilly2013,
	Author = {Jill X. O'Reilly and Saad Jbabdi and Matthew F. S. Rushworth and Timothy E. J. Behrens},
	Date-Added = {2014-02-20 15:03:25 +0000},
	Date-Modified = {2014-02-20 15:04:26 +0000},
	Journal = {PLOS Biology},
	Number = {9},
	Title = {Brain Systems for Probabilistic and Dynamic Prediction: Computational Specificity and Integration},
	Volume = {11},
	Year = {2013},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGy4uL1BhcGVycy9vJ3JlaWxseS8yMDEzLnBkZtIXCxgZV05TLmRhdGFPEQGMAAAAAAGMAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADO7GVcSCsAAAA10gwIMjAxMy5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADXGA88rf9AAAAAAAAAAAAABAAMAAAkgAAAAAAAAAAAAAAAAAAAACG8ncmVpbGx5ABAACAAAzuyrrAAAABEACAAAzyvGIAAAAAEAFAA10gwAFDHEAAUznwAFM54AAMBHAAIAQE1hY2ludG9zaCBIRDpVc2VyczoAY2ptYXk6AERvY3VtZW50czoAUGFwZXJzOgBvJ3JlaWxseToAMjAxMy5wZGYADgASAAgAMgAwADEAMwAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIALlVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvbydyZWlsbHkvMjAxMy5wZGYAEwABLwAAFQACAAz//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgCsALEAuQJJAksCUAJbAmQCcgJ2An0ChgKLApgCmwKtArACtQAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAK3}}

@inproceedings{shi2014,
	Author = {Tianlin Shi and Jun Zhu},
	Booktitle = {Proceedings of the 31st International Conference on Machine Learning (ICML)},
	Date-Added = {2014-02-20 15:02:19 +0000},
	Date-Modified = {2014-02-20 15:03:11 +0000},
	Title = {Online {B}ayesian Passive-Aggressive Learning},
	Year = {2014},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QFi4uL1BhcGVycy9zaGkvMjAxNC5wZGbSFwsYGVdOUy5kYXRhTxEBgAAAAAABgAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAANcBmCDIwMTQucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA1zvHPK4FnAAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAANzaGkAABAACAAAzuyrrAAAABEACAAAzyvHtwAAAAEAFAA1wGYAFDHEAAUznwAFM54AAMBHAAIAO01hY2ludG9zaCBIRDpVc2VyczoAY2ptYXk6AERvY3VtZW50czoAUGFwZXJzOgBzaGk6ADIwMTQucGRmAAAOABIACAAyADAAMQA0AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgApVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9zaGkvMjAxNC5wZGYAABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4ApwCsALQCOAI6Aj8CSgJTAmECZQJsAnUCegKHAooCnAKfAqQAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACpg==}}

@unpublished{neiswanger2013,
	Author = {Willie Neiswanger and Chong Wang and Eric Xing},
	Date-Added = {2014-02-20 15:01:18 +0000},
	Date-Modified = {2014-02-20 15:02:18 +0000},
	Title = {Asymptotically Exact, Embarrassingly Parallel MCMC},
	Year = {2013},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QHS4uL1BhcGVycy9uZWlzd2FuZ2VyLzIwMTMucGRm0hcLGBlXTlMuZGF0YU8RAZIAAAAAAZIAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM7sZVxIKwAAADXR8QgyMDEzLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANcgqzyuAhgAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAKbmVpc3dhbmdlcgAQAAgAAM7sq6wAAAARAAgAAM8rxtYAAAABABQANdHxABQxxAAFM58ABTOeAADARwACAEJNYWNpbnRvc2ggSEQ6VXNlcnM6AGNqbWF5OgBEb2N1bWVudHM6AFBhcGVyczoAbmVpc3dhbmdlcjoAMjAxMy5wZGYADgASAAgAMgAwADEAMwAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAMFVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvbmVpc3dhbmdlci8yMDEzLnBkZgATAAEvAAAVAAIADP//AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAK4AswC7AlECUwJYAmMCbAJ6An4ChQKOApMCoAKjArUCuAK9AAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAr8=}}

@inproceedings{diao2013,
	Author = {Qiming Diao and Jing Jiang},
	Booktitle = {Proceedings of the Conference on Empirical Methods on Natural Language Processing (EMNLP)},
	Date-Added = {2014-02-20 15:00:23 +0000},
	Date-Modified = {2014-02-20 15:01:01 +0000},
	Title = {A Unified Model for Topics, Events and Users on Twitter},
	Year = {2013},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QFy4uL1BhcGVycy9kaWFvLzIwMTMucGRm0hcLGBlXTlMuZGF0YU8RAYAAAAAAAYAAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM7sZVxIKwAAADXR3ggyMDEzLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANcdYzyuAdgAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAEZGlhbwAQAAgAAM7sq6wAAAARAAgAAM8rxsYAAAABABQANdHeABQxxAAFM58ABTOeAADARwACADxNYWNpbnRvc2ggSEQ6VXNlcnM6AGNqbWF5OgBEb2N1bWVudHM6AFBhcGVyczoAZGlhbzoAMjAxMy5wZGYADgASAAgAMgAwADEAMwAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAKlVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvZGlhby8yMDEzLnBkZgATAAEvAAAVAAIADP//AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAKgArQC1AjkCOwJAAksCVAJiAmYCbQJ2AnsCiAKLAp0CoAKlAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAqc=}}

@article{radhakrishnan1997,
	Author = {Jaikumar Radhakrishnan},
	Date-Added = {2014-02-20 14:59:41 +0000},
	Date-Modified = {2014-02-20 15:00:14 +0000},
	Journal = {Journal of Combinatorial Theory},
	Title = {An Entropy Proof of Bregman's Theorem},
	Year = {1997},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QIC4uL1BhcGVycy9yYWRoYWtyaXNobmFuLzE5OTcucGRm0hcLGBlXTlMuZGF0YU8RAZ4AAAAAAZ4AAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM7sZVxIKwAAADXR0QgxOTk3LnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANc+azyuBmwAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAANcmFkaGFrcmlzaG5hbgAAEAAIAADO7KusAAAAEQAIAADPK8frAAAAAQAUADXR0QAUMcQABTOfAAUzngAAwEcAAgBFTWFjaW50b3NoIEhEOlVzZXJzOgBjam1heToARG9jdW1lbnRzOgBQYXBlcnM6AHJhZGhha3Jpc2huYW46ADE5OTcucGRmAAAOABIACAAxADkAOQA3AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgAzVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9yYWRoYWtyaXNobmFuLzE5OTcucGRmAAATAAEvAAAVAAIADP//AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOALEAtgC+AmACYgJnAnICewKJAo0ClAKdAqICrwKyAsQCxwLMAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAs4=}}

@inproceedings{bawa2005,
	Author = {Mayank Bawa and Tyson Condie and Prasanna Ganesan},
	Booktitle = {WWW},
	Date-Added = {2014-02-20 14:59:07 +0000},
	Date-Modified = {2014-02-20 14:59:34 +0000},
	Title = {LSH Forest: Self-Tuning Indexes for Similarity Search},
	Year = {2005},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QFy4uL1BhcGVycy9iYXdhLzIwMDUucGRm0hcLGBlXTlMuZGF0YU8RAYAAAAAAAYAAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM7sZVxIKwAAADXRyAgyMDA1LnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANcKQzyt/BQAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAEYmF3YQAQAAgAAM7sq6wAAAARAAgAAM8rxVUAAAABABQANdHIABQxxAAFM58ABTOeAADARwACADxNYWNpbnRvc2ggSEQ6VXNlcnM6AGNqbWF5OgBEb2N1bWVudHM6AFBhcGVyczoAYmF3YToAMjAwNS5wZGYADgASAAgAMgAwADAANQAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAKlVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvYmF3YS8yMDA1LnBkZgATAAEvAAAVAAIADP//AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAKgArQC1AjkCOwJAAksCVAJiAmYCbQJ2AnsCiAKLAp0CoAKlAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAqc=}}

@inproceedings{shi2009,
	Author = {Lei Shi and Thomas L. Griffiths},
	Booktitle = {Advances in Neural Information Processing Systems 22 (NIPS)},
	Date-Added = {2014-02-20 14:40:32 +0000},
	Date-Modified = {2014-02-20 14:41:59 +0000},
	Title = {Neural Implementation of Hierarchical {B}ayesian Inference by Importance Sampling},
	Year = {2009},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QFi4uL1BhcGVycy9zaGkvMjAwOS5wZGbSFwsYGVdOUy5kYXRhTxEBgAAAAAABgAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAANcBmCDIwMDkucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAy4DLPJAc7AAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAANzaGkAABAACAAAzuyrrAAAABEACAAAzyRNiwAAAAEAFAA1wGYAFDHEAAUznwAFM54AAMBHAAIAO01hY2ludG9zaCBIRDpVc2VyczoAY2ptYXk6AERvY3VtZW50czoAUGFwZXJzOgBzaGk6ADIwMDkucGRmAAAOABIACAAyADAAMAA5AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgApVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9zaGkvMjAwOS5wZGYAABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4ApwCsALQCOAI6Aj8CSgJTAmECZQJsAnUCegKHAooCnAKfAqQAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACpg==}}

@article{slaney2008,
	Author = {Malcolm Slaney and Michael Casey},
	Date-Added = {2014-02-20 14:32:31 +0000},
	Date-Modified = {2014-02-20 14:33:35 +0000},
	Journal = {IEEE Signal Processing Magazine},
	Month = {Mar},
	Title = {Locality-Sensitive Hashing for Finding Nearest Neighbors},
	Year = {2008},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGS4uL1BhcGVycy9zbGFuZXkvMjAwOC5wZGbSFwsYGVdOUy5kYXRhTxEBhgAAAAABhgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAANaw+CDIwMDgucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQYVHOqjHlAAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAAZzbGFuZXkAEAAIAADO7KusAAAAEQAIAADOqng1AAAAAQAUADWsPgAUMcQABTOfAAUzngAAwEcAAgA+TWFjaW50b3NoIEhEOlVzZXJzOgBjam1heToARG9jdW1lbnRzOgBQYXBlcnM6AHNsYW5leToAMjAwOC5wZGYADgASAAgAMgAwADAAOAAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIALFVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvc2xhbmV5LzIwMDgucGRmABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AqgCvALcCQQJDAkgCUwJcAmoCbgJ1An4CgwKQApMCpQKoAq0AAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACrw==}}

@unpublished{aggarwal2006,
	Author = {Charu C. Aggarwal},
	Date-Added = {2014-02-20 14:31:42 +0000},
	Date-Modified = {2014-02-20 14:32:31 +0000},
	Note = {Slides from VLDB Conference 2006},
	Title = {On Biased Reservoir Sampling in the Presence of Stream Evolution},
	Year = {2006},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGy4uL1BhcGVycy9hZ2dhcndhbC8yMDA2LnBkZtIXCxgZV05TLmRhdGFPEQGMAAAAAAGMAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADO7GVcSCsAAAA1rCwIMjAwNi5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAB7XQM77RfUAAAAAAAAAAAABAAMAAAkgAAAAAAAAAAAAAAAAAAAACGFnZ2Fyd2FsABAACAAAzuyrrAAAABEACAAAzvuMRQAAAAEAFAA1rCwAFDHEAAUznwAFM54AAMBHAAIAQE1hY2ludG9zaCBIRDpVc2VyczoAY2ptYXk6AERvY3VtZW50czoAUGFwZXJzOgBhZ2dhcndhbDoAMjAwNi5wZGYADgASAAgAMgAwADAANgAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIALlVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvYWdnYXJ3YWwvMjAwNi5wZGYAEwABLwAAFQACAAz//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgCsALEAuQJJAksCUAJbAmQCcgJ2An0ChgKLApgCmwKtArACtQAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAK3}}

@unpublished{indyk2013,
	Author = {Piotr Indyk},
	Date-Added = {2014-02-20 14:30:20 +0000},
	Date-Modified = {2014-02-20 14:31:35 +0000},
	Title = {Near-Optimal Hashing Algorithms for Approximate Near(est) Neighbor Problem},
	Year = {2013},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGC4uL1BhcGVycy9pbmR5ay8yMDEzLnBkZtIXCxgZV05TLmRhdGFPEQGGAAAAAAGGAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADO7GVcSCsAAAAUMlEIMjAxMy5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABBozc6qMdgAAAAAAAAAAAABAAMAAAkgAAAAAAAAAAAAAAAAAAAABWluZHlrAAAQAAgAAM7sq6wAAAARAAgAAM6qeCgAAAABABQAFDJRABQxxAAFM58ABTOeAADARwACAD1NYWNpbnRvc2ggSEQ6VXNlcnM6AGNqbWF5OgBEb2N1bWVudHM6AFBhcGVyczoAaW5keWs6ADIwMTMucGRmAAAOABIACAAyADAAMQAzAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgArVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9pbmR5ay8yMDEzLnBkZgAAEwABLwAAFQACAAz//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgCpAK4AtgJAAkICRwJSAlsCaQJtAnQCfQKCAo8CkgKkAqcCrAAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAKu}}

@inproceedings{cisse2013,
	Author = {Moustapha Ciss\'{e} and Nicolas Usunier and Thierry Artieres and Patrick Gallinari},
	Booktitle = {Advances in Neural Information Processing Systems 26 (NIPS)},
	Date-Added = {2014-02-20 14:29:04 +0000},
	Date-Modified = {2014-02-20 14:30:04 +0000},
	Month = {Dec},
	Title = {Robust Bloom Filters for Large Multilabel Classification Tasks},
	Year = {2013},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGC4uL1BhcGVycy9jaXNzZS8yMDEzLnBkZtIXCxgZV05TLmRhdGFPEQGGAAAAAAGGAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADO7GVcSCsAAAA1rBQIMjAxMy5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABBoxM7PX2MAAAAAAAAAAAABAAMAAAkgAAAAAAAAAAAAAAAAAAAABWNpc3NlAAAQAAgAAM7sq6wAAAARAAgAAM7PpbMAAAABABQANawUABQxxAAFM58ABTOeAADARwACAD1NYWNpbnRvc2ggSEQ6VXNlcnM6AGNqbWF5OgBEb2N1bWVudHM6AFBhcGVyczoAY2lzc2U6ADIwMTMucGRmAAAOABIACAAyADAAMQAzAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgArVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9jaXNzZS8yMDEzLnBkZgAAEwABLwAAFQACAAz//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgCpAK4AtgJAAkICRwJSAlsCaQJtAnQCfQKCAo8CkgKkAqcCrAAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAKu}}

@unpublished{braverman2014,
	Author = {Vladimir Braverman and Jonathan Katzman and Charles Seidell and Gregory Vorsanger},
	Date-Added = {2014-02-20 14:22:42 +0000},
	Date-Modified = {2014-02-20 14:23:47 +0000},
	Title = {Approximating Large Frequency Moments with O(n^{1-2/k}) Bits},
	Year = {2014},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QHC4uL1BhcGVycy9icmF2ZXJtYW4vMjAxNC5wZGbSFwsYGVdOUy5kYXRhTxEBkgAAAAABkgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAANaoHCDIwMTQucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAoKeXPCuB9AAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAAlicmF2ZXJtYW4AABAACAAAzuyrrAAAABEACAAAzwsmzQAAAAEAFAA1qgcAFDHEAAUznwAFM54AAMBHAAIAQU1hY2ludG9zaCBIRDpVc2VyczoAY2ptYXk6AERvY3VtZW50czoAUGFwZXJzOgBicmF2ZXJtYW46ADIwMTQucGRmAAAOABIACAAyADAAMQA0AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgAvVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9icmF2ZXJtYW4vMjAxNC5wZGYAABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4ArQCyALoCUAJSAlcCYgJrAnkCfQKEAo0CkgKfAqICtAK3ArwAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACvg==}}

@article{goldwater2011,
	Author = {Sharon Goldwater and Thomas L. Griffiths and Mark Johnson},
	Date-Added = {2014-02-20 14:17:08 +0000},
	Date-Modified = {2014-02-20 14:22:08 +0000},
	Journal = {Journal of Machine Learning Research},
	Title = {Producing Power-Law Distributions and Damping Word Frequencies with Two-Stage Language Models},
	Year = {2011},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QHC4uL1BhcGVycy9nb2xkd2F0ZXIvMjAxMS5wZGbSFwsYGVdOUy5kYXRhTxEBkgAAAAABkgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAANanfCDIwMTEucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAe1rTO+0XpAAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAAlnb2xkd2F0ZXIAABAACAAAzuyrrAAAABEACAAAzvuMOQAAAAEAFAA1qd8AFDHEAAUznwAFM54AAMBHAAIAQU1hY2ludG9zaCBIRDpVc2VyczoAY2ptYXk6AERvY3VtZW50czoAUGFwZXJzOgBnb2xkd2F0ZXI6ADIwMTEucGRmAAAOABIACAAyADAAMQAxAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgAvVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9nb2xkd2F0ZXIvMjAxMS5wZGYAABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4ArQCyALoCUAJSAlcCYgJrAnkCfQKEAo0CkgKfAqICtAK3ArwAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACvg==}}

@inbook{ripley2008,
	Author = {Brian D. Ripley},
	Chapter = {2.7},
	Date-Added = {2014-02-20 14:13:53 +0000},
	Date-Modified = {2014-02-20 14:16:25 +0000},
	Pages = {66--77},
	Publisher = {Cambridge University Press},
	Title = {Pattern Recognition and Neural Networks},
	Year = {2008},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGS4uL1BhcGVycy9yaXBsZXkvMjAwOC5wZGbSFwsYGVdOUy5kYXRhTxEBhgAAAAABhgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAANamuCDIwMDgucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwfu3PHsF/AAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAAZyaXBsZXkAEAAIAADO7KusAAAAEQAIAADPHwfPAAAAAQAUADWprgAUMcQABTOfAAUzngAAwEcAAgA+TWFjaW50b3NoIEhEOlVzZXJzOgBjam1heToARG9jdW1lbnRzOgBQYXBlcnM6AHJpcGxleToAMjAwOC5wZGYADgASAAgAMgAwADAAOAAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIALFVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvcmlwbGV5LzIwMDgucGRmABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AqgCvALcCQQJDAkgCUwJcAmoCbgJ1An4CgwKQApMCpQKoAq0AAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACrw==}}

@article{morris1978,
	Author = {Robert Morris},
	Date-Added = {2014-02-20 14:12:40 +0000},
	Date-Modified = {2014-02-20 14:13:20 +0000},
	Journal = {Communications of the ACM},
	Title = {Counting Large Numbers of Events in Small Registers},
	Year = {1978},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGS4uL1BhcGVycy9tb3JyaXMvMTk3OC5wZGbSFwsYGVdOUy5kYXRhTxEBhgAAAAABhgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAANagJCDE5NzgucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAlc1LPBXuIAAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAAZtb3JyaXMAEAAIAADO7KusAAAAEQAIAADPBcHYAAAAAQAUADWoCQAUMcQABTOfAAUzngAAwEcAAgA+TWFjaW50b3NoIEhEOlVzZXJzOgBjam1heToARG9jdW1lbnRzOgBQYXBlcnM6AG1vcnJpczoAMTk3OC5wZGYADgASAAgAMQA5ADcAOAAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIALFVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvbW9ycmlzLzE5NzgucGRmABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AqgCvALcCQQJDAkgCUwJcAmoCbgJ1An4CgwKQApMCpQKoAq0AAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACrw==}}

@inproceedings{ravichandran2005,
	Author = {Deepak Ravichandran and Patrick Pantel and Eduard Hovy},
	Booktitle = {Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL)},
	Date-Added = {2014-02-20 14:10:52 +0000},
	Date-Modified = {2014-02-20 14:11:53 +0000},
	Pages = {622--629},
	Title = {Randomized Algorithms and NLP: Using Locality Sensitive Hash Function for High Speed Noun Clustering},
	Year = {2005},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QHy4uL1BhcGVycy9yYXZpY2hhbmRyYW4vMjAwNS5wZGbSFwsYGVdOUy5kYXRhTxEBmAAAAAABmAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAANaf1CDIwMDUucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAj2xLPAgYIAAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAAxyYXZpY2hhbmRyYW4AEAAIAADO7KusAAAAEQAIAADPAkxYAAAAAQAUADWn9QAUMcQABTOfAAUzngAAwEcAAgBETWFjaW50b3NoIEhEOlVzZXJzOgBjam1heToARG9jdW1lbnRzOgBQYXBlcnM6AHJhdmljaGFuZHJhbjoAMjAwNS5wZGYADgASAAgAMgAwADAANQAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAMlVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvcmF2aWNoYW5kcmFuLzIwMDUucGRmABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AsAC1AL0CWQJbAmACawJ0AoIChgKNApYCmwKoAqsCvQLAAsUAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACxw==}}

@inproceedings{gopalan2012,
	Author = {Prem Gopalan and David Mimno and Sean M. Gerrish and Michael J. Freedman and David M. Blei},
	Booktitle = {Advances in Neural Information Processing Systems 25 (NIPS)},
	Date-Added = {2014-02-20 14:09:48 +0000},
	Date-Modified = {2014-02-20 14:10:41 +0000},
	Title = {Scalable Inference of Overlapping Communities},
	Year = {2012},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGi4uL1BhcGVycy9nb3BhbGFuLzIwMTIucGRm0hcLGBlXTlMuZGF0YU8RAYwAAAAAAYwAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM7sZVxIKwAAADWn7QgyMDEyLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAMZcPzyHN3QAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAHZ29wYWxhbgAAEAAIAADO7KusAAAAEQAIAADPIhQtAAAAAQAUADWn7QAUMcQABTOfAAUzngAAwEcAAgA/TWFjaW50b3NoIEhEOlVzZXJzOgBjam1heToARG9jdW1lbnRzOgBQYXBlcnM6AGdvcGFsYW46ADIwMTIucGRmAAAOABIACAAyADAAMQAyAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgAtVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9nb3BhbGFuLzIwMTIucGRmAAATAAEvAAAVAAIADP//AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAKsAsAC4AkgCSgJPAloCYwJxAnUCfAKFAooClwKaAqwCrwK0AAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAArY=}}

@inproceedings{miller2013,
	Author = {Jeffrey W. Miller and Matthew T. Harrison},
	Booktitle = {Advances in Neural Information Processing Systems 26 (NIPS)},
	Date-Added = {2014-02-20 14:08:05 +0000},
	Date-Modified = {2014-02-20 14:09:31 +0000},
	Month = {Dec},
	Title = {A Simple Example of {D}irichlet Process Mixture Inconsistency for the Number of Components},
	Year = {2013},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGS4uL1BhcGVycy9taWxsZXIvMjAxMy5wZGbSFwsYGVdOUy5kYXRhTxEBhgAAAAABhgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAANafnCDIwMTMucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQYevOtNxYAAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAAZtaWxsZXIAEAAIAADO7KusAAAAEQAIAADOtSKoAAAAAQAUADWn5wAUMcQABTOfAAUzngAAwEcAAgA+TWFjaW50b3NoIEhEOlVzZXJzOgBjam1heToARG9jdW1lbnRzOgBQYXBlcnM6AG1pbGxlcjoAMjAxMy5wZGYADgASAAgAMgAwADEAMwAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIALFVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvbWlsbGVyLzIwMTMucGRmABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AqgCvALcCQQJDAkgCUwJcAmoCbgJ1An4CgwKQApMCpQKoAq0AAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACrw==}}

@inproceedings{min2010,
	Author = {Kerui Min and Zhengdong Zhang and John Wright and Yi Ma},
	Booktitle = {CIKM},
	Date-Added = {2014-02-20 14:06:53 +0000},
	Date-Modified = {2014-02-20 14:07:59 +0000},
	Title = {Decomposing Background Topics from Keywords by Principal Component Pursuit},
	Year = {2010},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QFi4uL1BhcGVycy9taW4vMjAxMC5wZGbSFwsYGVdOUy5kYXRhTxEBgAAAAAABgAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAANaXiCDIwMTAucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQaMbOsS3OAAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAANtaW4AABAACAAAzuyrrAAAABEACAAAzrF0HgAAAAEAFAA1peIAFDHEAAUznwAFM54AAMBHAAIAO01hY2ludG9zaCBIRDpVc2VyczoAY2ptYXk6AERvY3VtZW50czoAUGFwZXJzOgBtaW46ADIwMTAucGRmAAAOABIACAAyADAAMQAwAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgApVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9taW4vMjAxMC5wZGYAABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4ApwCsALQCOAI6Aj8CSgJTAmECZQJsAnUCegKHAooCnAKfAqQAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACpg==}}

@techreport{chen1998,
	Author = {Stanley F. Chen and Joshua Goodman},
	Date-Added = {2014-02-20 14:05:49 +0000},
	Date-Modified = {2014-02-20 14:06:46 +0000},
	Institution = {Center for Research in Computing Technology, Harvard University},
	Title = {An Empirical Study of Smoothing Techniques for Language Modeling},
	Year = {1998},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QFy4uL1BhcGVycy9jaGVuLzE5OTgucGRm0hcLGBlXTlMuZGF0YU8RAYAAAAAAAYAAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM7sZVxIKwAAADWl1QgxOTk4LnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEGI/zp9oFwAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAEY2hlbgAQAAgAAM7sq6wAAAARAAgAAM6frmcAAAABABQANaXVABQxxAAFM58ABTOeAADARwACADxNYWNpbnRvc2ggSEQ6VXNlcnM6AGNqbWF5OgBEb2N1bWVudHM6AFBhcGVyczoAY2hlbjoAMTk5OC5wZGYADgASAAgAMQA5ADkAOAAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAKlVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvY2hlbi8xOTk4LnBkZgATAAEvAAAVAAIADP//AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAKgArQC1AjkCOwJAAksCVAJiAmYCbQJ2AnsCiAKLAp0CoAKlAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAqc=}}

@inproceedings{levenberg2009,
	Author = {Abby Levenberg and Miles Osborne},
	Booktitle = {Proceedings of the Conference on Empirical Methods on Natural Language Processing (EMNLP)},
	Date-Added = {2014-02-20 14:04:46 +0000},
	Date-Modified = {2014-02-20 14:05:39 +0000},
	Title = {Stream-based Randomised Language Models for SMT},
	Year = {2009},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QHC4uL1BhcGVycy9sZXZlbmJlcmcvMjAwOS5wZGbSFwsYGVdOUy5kYXRhTxEBkgAAAAABkgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAANaXACDIwMDkucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAtnxTPF7U0AAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAAlsZXZlbmJlcmcAABAACAAAzuyrrAAAABEACAAAzxf7hAAAAAEAFAA1pcAAFDHEAAUznwAFM54AAMBHAAIAQU1hY2ludG9zaCBIRDpVc2VyczoAY2ptYXk6AERvY3VtZW50czoAUGFwZXJzOgBsZXZlbmJlcmc6ADIwMDkucGRmAAAOABIACAAyADAAMAA5AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgAvVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9sZXZlbmJlcmcvMjAwOS5wZGYAABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4ArQCyALoCUAJSAlcCYgJrAnkCfQKEAo0CkgKfAqICtAK3ArwAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACvg==}}

@unpublished{dyer2014,
	Author = {Chris Dyer},
	Date-Added = {2014-02-20 14:02:59 +0000},
	Date-Modified = {2014-02-20 14:04:23 +0000},
	Title = {Notes on AdaGrad},
	Year = {2014},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QFy4uL1BhcGVycy9keWVyLzIwMTQucGRm0hcLGBlXTlMuZGF0YU8RAYAAAAAAAYAAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM7sZVxIKwAAADWlsQgyMDE0LnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANaFEzyt0fQAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAEZHllcgAQAAgAAM7sq6wAAAARAAgAAM8rus0AAAABABQANaWxABQxxAAFM58ABTOeAADARwACADxNYWNpbnRvc2ggSEQ6VXNlcnM6AGNqbWF5OgBEb2N1bWVudHM6AFBhcGVyczoAZHllcjoAMjAxNC5wZGYADgASAAgAMgAwADEANAAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAKlVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvZHllci8yMDE0LnBkZgATAAEvAAAVAAIADP//AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAKgArQC1AjkCOwJAAksCVAJiAmYCbQJ2AnsCiAKLAp0CoAKlAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAqc=}}

@article{wang2013,
	Author = {Heng Wang and Minh Tang and Youngser Park and Carey E. Priebe},
	Date-Added = {2014-02-20 14:01:00 +0000},
	Date-Modified = {2014-02-20 14:02:33 +0000},
	Journal = {IEEE Transactions on Signal Processing},
	Number = {3},
	Title = {Locality statistics for anomaly detection in time series of graphs},
	Volume = {62},
	Year = {2014},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QFy4uL1BhcGVycy93YW5nLzIwMTQucGRm0hcLGBlXTlMuZGF0YU8RAYAAAAAAAYAAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM7sZVxIKwAAABQyrAgyMDE0LnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEGJBzsuuzwAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAEd2FuZwAQAAgAAM7sq6wAAAARAAgAAM7L9R8AAAABABQAFDKsABQxxAAFM58ABTOeAADARwACADxNYWNpbnRvc2ggSEQ6VXNlcnM6AGNqbWF5OgBEb2N1bWVudHM6AFBhcGVyczoAd2FuZzoAMjAxNC5wZGYADgASAAgAMgAwADEANAAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAKlVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvd2FuZy8yMDE0LnBkZgATAAEvAAAVAAIADP//AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAKgArQC1AjkCOwJAAksCVAJiAmYCbQJ2AnsCiAKLAp0CoAKlAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAqc=}}

@inproceedings{duchi2013,
	Author = {John C. Duchi and Michael I. Jordan and H. Brendan McMahan},
	Booktitle = {Advances in Neural Information Processing Systems 26 (NIPS)},
	Date-Added = {2014-02-20 13:56:26 +0000},
	Date-Modified = {2014-02-20 13:57:47 +0000},
	Month = {Dec},
	Title = {Estimation, Optimization, and Parallelism when Data is Sparse},
	Year = {2013},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGC4uL1BhcGVycy9kdWNoaS8yMDEzLnBkZtIXCxgZV05TLmRhdGFPEQGGAAAAAAGGAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADO7GVcSCsAAAA1n2kIMjAxMy5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABBiK8603GIAAAAAAAAAAAABAAMAAAkgAAAAAAAAAAAAAAAAAAAABWR1Y2hpAAAQAAgAAM7sq6wAAAARAAgAAM61IrIAAAABABQANZ9pABQxxAAFM58ABTOeAADARwACAD1NYWNpbnRvc2ggSEQ6VXNlcnM6AGNqbWF5OgBEb2N1bWVudHM6AFBhcGVyczoAZHVjaGk6ADIwMTMucGRmAAAOABIACAAyADAAMQAzAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgArVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9kdWNoaS8yMDEzLnBkZgAAEwABLwAAFQACAAz//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgCpAK4AtgJAAkICRwJSAlsCaQJtAnQCfQKCAo8CkgKkAqcCrAAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAKu}}

@unpublished{carpenter2010,
	Author = {Bob Carpenter},
	Date-Added = {2014-02-20 13:54:10 +0000},
	Date-Modified = {2014-02-20 13:55:01 +0000},
	Title = {Integrating Out Multinomial Parameters in Latent {D}irichlet Allocation and Naive {B}ayes for Collapsed Gibbs Sampling},
	Year = {2010},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QHS4uL1BhcGVycy9jYXJwZW50ZXIvMjAxMGEucGRm0hcLGBlXTlMuZGF0YU8RAZQAAAAAAZQAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM7sZVxIKwAAADWeQAkyMDEwYS5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJVb1zwU81AAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAJY2FycGVudGVyAAAQAAgAAM7sq6wAAAARAAgAAM8FgyQAAAABABQANZ5AABQxxAAFM58ABTOeAADARwACAEJNYWNpbnRvc2ggSEQ6VXNlcnM6AGNqbWF5OgBEb2N1bWVudHM6AFBhcGVyczoAY2FycGVudGVyOgAyMDEwYS5wZGYADgAUAAkAMgAwADEAMABhAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgAwVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9jYXJwZW50ZXIvMjAxMGEucGRmABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4ArgCzALsCUwJVAloCZQJuAnwCgAKHApAClQKiAqUCtwK6Ar8AAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACwQ==},
	Bdsk-File-2 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QHS4uL1BhcGVycy9jYXJwZW50ZXIvMjAxMGEucGRm0hcLGBlXTlMuZGF0YU8RAZQAAAAAAZQAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM7sZVxIKwAAADWeQAkyMDEwYS5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJVb1zwU81AAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAJY2FycGVudGVyAAAQAAgAAM7sq6wAAAARAAgAAM8FgyQAAAABABQANZ5AABQxxAAFM58ABTOeAADARwACAEJNYWNpbnRvc2ggSEQ6VXNlcnM6AGNqbWF5OgBEb2N1bWVudHM6AFBhcGVyczoAY2FycGVudGVyOgAyMDEwYS5wZGYADgAUAAkAMgAwADEAMABhAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgAwVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9jYXJwZW50ZXIvMjAxMGEucGRmABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4ArgCzALsCUwJVAloCZQJuAnwCgAKHApAClQKiAqUCtwK6Ar8AAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACwQ==}}

@unpublished{tang2008,
	Author = {Lei Tang},
	Date-Added = {2014-02-20 13:53:15 +0000},
	Date-Modified = {2014-02-20 13:54:02 +0000},
	Month = {Jan},
	Note = {slides showing derivation},
	Title = {Gibbs Sampling for LDA},
	Year = {2008},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QFy4uL1BhcGVycy90YW5nLzIwMDgucGRm0hcLGBlXTlMuZGF0YU8RAYAAAAAAAYAAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM7sZVxIKwAAADWeGwgyMDA4LnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJVyFzwU9bQAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAEdGFuZwAQAAgAAM7sq6wAAAARAAgAAM8Fg70AAAABABQANZ4bABQxxAAFM58ABTOeAADARwACADxNYWNpbnRvc2ggSEQ6VXNlcnM6AGNqbWF5OgBEb2N1bWVudHM6AFBhcGVyczoAdGFuZzoAMjAwOC5wZGYADgASAAgAMgAwADAAOAAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAKlVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvdGFuZy8yMDA4LnBkZgATAAEvAAAVAAIADP//AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAKgArQC1AjkCOwJAAksCVAJiAmYCbQJ2AnsCiAKLAp0CoAKlAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAqc=}}

@inbook{vidal2014b,
	Author = {Rene Vidal and Yi Ma and S. Sastry},
	Chapter = {Appendix},
	Date-Added = {2014-02-20 13:52:15 +0000},
	Date-Modified = {2014-05-03 15:56:40 +0000},
	Publisher = {Springer-Verlag},
	Title = {Basic Facts from Optimization, Mathematical Statistics},
	Year = {2014},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGS4uL1BhcGVycy92aWRhbC8yMDE0Yi5wZGbSFwsYGVdOUy5kYXRhTxEBiAAAAAABiAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAAFDKkCTIwMTRiLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA1AGHPJ/CjAAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAAV2aWRhbAAAEAAIAADO7KusAAAAEQAIAADPKDbzAAAAAQAUABQypAAUMcQABTOfAAUzngAAwEcAAgA+TWFjaW50b3NoIEhEOlVzZXJzOgBjam1heToARG9jdW1lbnRzOgBQYXBlcnM6AHZpZGFsOgAyMDE0Yi5wZGYADgAUAAkAMgAwADEANABiAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgAsVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy92aWRhbC8yMDE0Yi5wZGYAEwABLwAAFQACAAz//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgCqAK8AtwJDAkUCSgJVAl4CbAJwAncCgAKFApIClQKnAqoCrwAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAKx}}

@inbook{vidal2014a,
	Author = {Rene Vidal and Yi Ma and S. Sastry},
	Chapter = {2},
	Date-Added = {2014-02-20 13:51:23 +0000},
	Date-Modified = {2014-05-03 15:56:00 +0000},
	Publisher = {Springer-Verlag},
	Title = {Principal Component Analysis},
	Year = {2014},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGS4uL1BhcGVycy92aWRhbC8yMDE0YS5wZGbSFwsYGVdOUy5kYXRhTxEBiAAAAAABiAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAAFDKkCTIwMTRhLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA1AOzPJ/CpAAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAAV2aWRhbAAAEAAIAADO7KusAAAAEQAIAADPKDb5AAAAAQAUABQypAAUMcQABTOfAAUzngAAwEcAAgA+TWFjaW50b3NoIEhEOlVzZXJzOgBjam1heToARG9jdW1lbnRzOgBQYXBlcnM6AHZpZGFsOgAyMDE0YS5wZGYADgAUAAkAMgAwADEANABhAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgAsVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy92aWRhbC8yMDE0YS5wZGYAEwABLwAAFQACAAz//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgCqAK8AtwJDAkUCSgJVAl4CbAJwAncCgAKFApIClQKnAqoCrwAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAKx}}

@inbook{vidal2014,
	Author = {Rene Vidal and Yi Ma and S. Sastry},
	Chapter = {TOC},
	Date-Added = {2014-02-20 13:48:23 +0000},
	Date-Modified = {2014-05-03 15:55:38 +0000},
	Publisher = {Springer-Verlag},
	Title = {Table of Contents},
	Year = {2014},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGC4uL1BhcGVycy92aWRhbC8yMDE0LnBkZtIXCxgZV05TLmRhdGFPEQGGAAAAAAGGAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADO7GVcSCsAAAAUMqQIMjAxNC5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACyEFc8VUD4AAAAAAAAAAAABAAMAAAkgAAAAAAAAAAAAAAAAAAAABXZpZGFsAAAQAAgAAM7sq6wAAAARAAgAAM8Vlo4AAAABABQAFDKkABQxxAAFM58ABTOeAADARwACAD1NYWNpbnRvc2ggSEQ6VXNlcnM6AGNqbWF5OgBEb2N1bWVudHM6AFBhcGVyczoAdmlkYWw6ADIwMTQucGRmAAAOABIACAAyADAAMQA0AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgArVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy92aWRhbC8yMDE0LnBkZgAAEwABLwAAFQACAAz//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgCpAK4AtgJAAkICRwJSAlsCaQJtAnQCfQKCAo8CkgKkAqcCrAAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAKu}}

@article{cormode2005,
	Author = {Graham Cormode and S. Muthukrishnan},
	Date-Added = {2014-02-20 13:44:56 +0000},
	Date-Modified = {2014-02-20 13:48:20 +0000},
	Journal = {Journal of Algorithms},
	Note = {preprint},
	Title = {An Improved Data Stream Summary: The Count-Min Sketch and its Applications},
	Year = {2005},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGi4uL1BhcGVycy9jb3Jtb2RlLzIwMDUucGRm0hcLGBlXTlMuZGF0YU8RAYwAAAAAAYwAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM7sZVxIKwAAABQyOAgyMDA1LnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANZzszytxvgAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAHY29ybW9kZQAAEAAIAADO7KusAAAAEQAIAADPK7gOAAAAAQAUABQyOAAUMcQABTOfAAUzngAAwEcAAgA/TWFjaW50b3NoIEhEOlVzZXJzOgBjam1heToARG9jdW1lbnRzOgBQYXBlcnM6AGNvcm1vZGU6ADIwMDUucGRmAAAOABIACAAyADAAMAA1AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgAtVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9jb3Jtb2RlLzIwMDUucGRmAAATAAEvAAAVAAIADP//AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAKsAsAC4AkgCSgJPAloCYwJxAnUCfAKFAooClwKaAqwCrwK0AAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAArY=}}

@inproceedings{das2011,
	Author = {Abhimanyu Das and David Kempe},
	Booktitle = {Proceedings of the 28th International Conference on Machine Learning (ICML)},
	Date-Added = {2014-02-20 13:43:26 +0000},
	Date-Modified = {2014-02-20 13:44:55 +0000},
	Title = {Submodular Meets Spectral: Greedy Algorithms for Subset Selection, Sparse Approximation and Dictionary Selection},
	Year = {2011},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QFi4uL1BhcGVycy9kYXMvMjAxMS5wZGbSFwsYGVdOUy5kYXRhTxEBgAAAAAABgAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAANZoVCDIwMTEucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAwej/PHrp8AAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAANkYXMAABAACAAAzuyrrAAAABEACAAAzx8AzAAAAAEAFAA1mhUAFDHEAAUznwAFM54AAMBHAAIAO01hY2ludG9zaCBIRDpVc2VyczoAY2ptYXk6AERvY3VtZW50czoAUGFwZXJzOgBkYXM6ADIwMTEucGRmAAAOABIACAAyADAAMQAxAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgApVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9kYXMvMjAxMS5wZGYAABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4ApwCsALQCOAI6Aj8CSgJTAmECZQJsAnUCegKHAooCnAKfAqQAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACpg==}}

@article{efron1997,
	Author = {Bradley Efron and Robert Tibshirani},
	Date-Added = {2014-02-20 13:42:01 +0000},
	Date-Modified = {2014-02-20 13:43:09 +0000},
	Journal = {Journal of the American Statistical Association},
	Number = {438},
	Pages = {548--560},
	Title = {Improvements on Cross-Validation: the .632+ Bootstrap Method},
	Volume = {92},
	Year = {1997},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGC4uL1BhcGVycy9lZnJvbi8xOTk3LnBkZtIXCxgZV05TLmRhdGFPEQGGAAAAAAGGAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADO7GVcSCsAAAA1mZkIMTk5Ny5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADCB6M8ewkcAAAAAAAAAAAABAAMAAAkgAAAAAAAAAAAAAAAAAAAABWVmcm9uAAAQAAgAAM7sq6wAAAARAAgAAM8fCJcAAAABABQANZmZABQxxAAFM58ABTOeAADARwACAD1NYWNpbnRvc2ggSEQ6VXNlcnM6AGNqbWF5OgBEb2N1bWVudHM6AFBhcGVyczoAZWZyb246ADE5OTcucGRmAAAOABIACAAxADkAOQA3AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgArVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9lZnJvbi8xOTk3LnBkZgAAEwABLwAAFQACAAz//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgCpAK4AtgJAAkICRwJSAlsCaQJtAnQCfQKCAo8CkgKkAqcCrAAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAKu}}

@article{trunk1979,
	Author = {G. V. Trunk},
	Date-Added = {2014-02-20 13:40:50 +0000},
	Date-Modified = {2014-02-20 13:41:29 +0000},
	Journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	Month = {Jul},
	Number = {3},
	Title = {A Problem of Dimensionality: A Simple Example},
	Volume = {1},
	Year = {1979},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGC4uL1BhcGVycy90cnVuay8xOTc5LnBkZtIXCxgZV05TLmRhdGFPEQGGAAAAAAGGAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADO7GVcSCsAAAA1mZYIMTk3OS5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADThIs8noNQAAAAAAAAAAAABAAMAAAkgAAAAAAAAAAAAAAAAAAAABXRydW5rAAAQAAgAAM7sq6wAAAARAAgAAM8n5yQAAAABABQANZmWABQxxAAFM58ABTOeAADARwACAD1NYWNpbnRvc2ggSEQ6VXNlcnM6AGNqbWF5OgBEb2N1bWVudHM6AFBhcGVyczoAdHJ1bms6ADE5NzkucGRmAAAOABIACAAxADkANwA5AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgArVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy90cnVuay8xOTc5LnBkZgAAEwABLwAAFQACAAz//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgCpAK4AtgJAAkICRwJSAlsCaQJtAnQCfQKCAo8CkgKkAqcCrAAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAKu}}

@inproceedings{liu2012,
	Author = {Qiang Liu and Alexander T. Ihler},
	Booktitle = {Proceedings of the 28th Conference on Uncertainty in Artificial Intelligence (UAI)},
	Date-Added = {2014-02-20 13:38:16 +0000},
	Date-Modified = {2014-02-20 13:39:55 +0000},
	Note = {arXiv:1202.3742},
	Title = {Variational Algorithms for Marginal MAP},
	Year = {2012},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QFi4uL1BhcGVycy9saXUvMjAxMi5wZGbSFwsYGVdOUy5kYXRhTxEBgAAAAAABgAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAANZmJCDIwMTIucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAuRnHPGI8fAAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAANsaXUAABAACAAAzuyrrAAAABEACAAAzxjVbwAAAAEAFAA1mYkAFDHEAAUznwAFM54AAMBHAAIAO01hY2ludG9zaCBIRDpVc2VyczoAY2ptYXk6AERvY3VtZW50czoAUGFwZXJzOgBsaXU6ADIwMTIucGRmAAAOABIACAAyADAAMQAyAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgApVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9saXUvMjAxMi5wZGYAABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4ApwCsALQCOAI6Aj8CSgJTAmECZQJsAnUCegKHAooCnAKfAqQAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACpg==}}

@unpublished{alon2002,
	Author = {Noga Alon and Yossi Matias and Mario Szegedy},
	Date-Added = {2014-02-20 13:33:35 +0000},
	Date-Modified = {2014-02-20 13:36:07 +0000},
	Note = {Revision of 1996 STOC paper},
	Title = {The space complexity of approximating the frequency moments},
	Year = {2002},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QFy4uL1BhcGVycy9hbG9uLzIwMDIucGRm0hcLGBlXTlMuZGF0YU8RAYAAAAAAAYAAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM7sZVxIKwAAADWPZggyMDAyLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAJXSwzwV7lgAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAEYWxvbgAQAAgAAM7sq6wAAAARAAgAAM8FweYAAAABABQANY9mABQxxAAFM58ABTOeAADARwACADxNYWNpbnRvc2ggSEQ6VXNlcnM6AGNqbWF5OgBEb2N1bWVudHM6AFBhcGVyczoAYWxvbjoAMjAwMi5wZGYADgASAAgAMgAwADAAMgAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAKlVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvYWxvbi8yMDAyLnBkZgATAAEvAAAVAAIADP//AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAKgArQC1AjkCOwJAAksCVAJiAmYCbQJ2AnsCiAKLAp0CoAKlAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAqc=}}

@article{gilks2001,
	Author = {Walter R. Gilks and Carlo Berzuini},
	Date-Added = {2014-02-20 13:29:54 +0000},
	Date-Modified = {2014-02-20 13:31:35 +0000},
	Journal = {Journal of the Royal Statistical Society},
	Number = {1},
	Pages = {127--146},
	Title = {Following a moving target---{M}onte {C}arlo inference for dynamic {B}ayesian models},
	Volume = {63},
	Year = {2001},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGC4uL1BhcGVycy9naWxrcy8yMDAxLnBkZtIXCxgZV05TLmRhdGFPEQGGAAAAAAGGAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADO7GVcSCsAAAA1jgMIMjAwMS5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADWFKM8q394AAAAAAAAAAAABAAMAAAkgAAAAAAAAAAAAAAAAAAAABWdpbGtzAAAQAAgAAM7sq6wAAAARAAgAAM8rJi4AAAABABQANY4DABQxxAAFM58ABTOeAADARwACAD1NYWNpbnRvc2ggSEQ6VXNlcnM6AGNqbWF5OgBEb2N1bWVudHM6AFBhcGVyczoAZ2lsa3M6ADIwMDEucGRmAAAOABIACAAyADAAMAAxAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgArVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9naWxrcy8yMDAxLnBkZgAAEwABLwAAFQACAAz//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgCpAK4AtgJAAkICRwJSAlsCaQJtAnQCfQKCAo8CkgKkAqcCrAAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAKu}}

@inproceedings{martins2011,
	Author = {Andr\'{e} F. T. Martins and Noah A. Smith and Pedro M. Q. Aguiar and M\'{a}rio A. T. Figueiredo},
	Booktitle = {Proceedings of the Conference on Empirical Methods on Natural Language Processing (EMNLP)},
	Date-Added = {2014-02-16 23:59:20 +0000},
	Date-Modified = {2014-02-20 13:27:44 +0000},
	Pages = {1500-1511},
	Read = {1},
	Title = {Structured Sparsity in Structured Prediction},
	Year = {2011},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGi4uL1BhcGVycy9tYXJ0aW5zLzIwMTEucGRm0hcLGBlXTlMuZGF0YU8RAYwAAAAAAYwAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM7sZVxIKwAAADS22ggyMDExLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANEofzyKwhwAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAHbWFydGlucwAAEAAIAADO7KusAAAAEQAIAADPIvbXAAAAAQAUADS22gAUMcQABTOfAAUzngAAwEcAAgA/TWFjaW50b3NoIEhEOlVzZXJzOgBjam1heToARG9jdW1lbnRzOgBQYXBlcnM6AG1hcnRpbnM6ADIwMTEucGRmAAAOABIACAAyADAAMQAxAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgAtVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9tYXJ0aW5zLzIwMTEucGRmAAATAAEvAAAVAAIADP//AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAKsAsAC4AkgCSgJPAloCYwJxAnUCfAKFAooClwKaAqwCrwK0AAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAArY=}}

@inproceedings{schmidt2010,
	Author = {Mark Schmidt and Kevin Murphy},
	Booktitle = {Proceedings of the 13th International Conference on Artificial Intelligence and Statistics (AISTATS)},
	Date-Added = {2014-02-16 23:57:30 +0000},
	Date-Modified = {2014-02-16 23:59:04 +0000},
	Title = {Convex Structure Learning in Log-Linear Models: Beyond Pairwise Potentials},
	Year = {2010},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGi4uL1BhcGVycy9zY2htaWR0LzIwMTAucGRm0hcLGBlXTlMuZGF0YU8RAYwAAAAAAYwAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM7sZVxIKwAAADS2xAgyMDEwLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAANGS/zyKwgwAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAHc2NobWlkdAAAEAAIAADO7KusAAAAEQAIAADPIvbTAAAAAQAUADS2xAAUMcQABTOfAAUzngAAwEcAAgA/TWFjaW50b3NoIEhEOlVzZXJzOgBjam1heToARG9jdW1lbnRzOgBQYXBlcnM6AHNjaG1pZHQ6ADIwMTAucGRmAAAOABIACAAyADAAMQAwAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgAtVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9zY2htaWR0LzIwMTAucGRmAAATAAEvAAAVAAIADP//AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAKsAsAC4AkgCSgJPAloCYwJxAnUCfAKFAooClwKaAqwCrwK0AAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAArY=}}

@inproceedings{wahabzada2011,
	Author = {Mirwaes Wahabzada and Kristian Kersting},
	Booktitle = {Proceedings of the European Conference on Machine Learning},
	Comments = {Wahabzada and Kersting (2011) create a document schedule (order) for LDA that improves the convergence rate of the variational online LDA algorithm for large datasets. Part of the motivation for this work stems from the conceptual problem that current batch LDA methods start optimizing before they have seen the entire dataset. To ameliorate this issue, Wahabzada and Kersting propose to sort the dataset such that the most ``influential'' documents come first. They propose two approaches. The first is a static schedule based on a metric inspired by matrix factorization that depends solely on the per-document word (type) counts. Under this schedule, documents with high word counts go toward the beginning of the dataset. Wahabzada and Kersting note that the most influential documents may change during learning, as the model is updated according to the data. Thus they propose another schedule based on the change in the variational parameters between iterations. Ultimately, their influence score roughly resembles the second derivative of the variational parameters $\gamma$ corresponding to the per-document topic distributions. Rather than iterating between learning the model and sorting the dataset based on the model, Wahabzada and Kersting propose drawing mini-batches according to the influence score and recomputing the scores after learning on each mini-batch. In experiments on several corpora, measuring performance by held-out perplexity and in some cases by accuracy (using the model as input to a multi-class SVM and comparing to e.g. newsgroup categories), the authors find that both schedules improve the the convergence rate with respect to wall-clock time. In a supporting experiment, the static importance scores were used to generate samples of the dataset, and uniform samples of the same cardinality were also taken, and online LDA run on each of these samples yielded considerably lower held-out perplexity on the importance score samples than on the uniform samples. The static schedule used in the standard way, to simply order the dataset, was also evaluated, and actually outperformed the dynamic schedule on a couple of tasks. However, when run on a Wikipedia dataset larger than the other datasets, the dynamic schedule dominated.},
	Date-Added = {2014-02-13 22:35:01 +0000},
	Date-Modified = {2014-02-20 13:26:34 +0000},
	Read = {1},
	Title = {Larger Residuals, Less Work: Active Document Scheduling for Latent {D}irichlet Allocation},
	Year = {2011},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QHC4uL1BhcGVycy93YWhhYnphZGEvMjAxMS5wZGbSFwsYGVdOUy5kYXRhTxEBkgAAAAABkgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAAMkDdCDIwMTEucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAxjRDPIcykAAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAAl3YWhhYnphZGEAABAACAAAzuyrrAAAABEACAAAzyIS9AAAAAEAFAAyQN0AFDHEAAUznwAFM54AAMBHAAIAQU1hY2ludG9zaCBIRDpVc2VyczoAY2ptYXk6AERvY3VtZW50czoAUGFwZXJzOgB3YWhhYnphZGE6ADIwMTEucGRmAAAOABIACAAyADAAMQAxAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgAvVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy93YWhhYnphZGEvMjAxMS5wZGYAABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4ArQCyALoCUAJSAlcCYgJrAnkCfQKEAo0CkgKfAqICtAK3ArwAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACvg==}}

@unpublished{bach2012a,
	Author = {Francis Bach},
	Date-Added = {2014-02-07 15:48:18 +0000},
	Date-Modified = {2014-02-07 15:49:02 +0000},
	Month = {May},
	Note = {Slides at Cambridge University talk},
	Title = {Structured Sparsity through Convex Optimization},
	Year = {2012},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGC4uL1BhcGVycy9iYWNoLzIwMTJhLnBkZtIXCxgZV05TLmRhdGFPEQGGAAAAAAGGAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADO7GVcSCsAAAAu0SwJMjAxMmEucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAC2z8s8XuhUAAAAAAAAAAAABAAMAAAkgAAAAAAAAAAAAAAAAAAAABGJhY2gAEAAIAADO7KusAAAAEQAIAADPGABlAAAAAQAUAC7RLAAUMcQABTOfAAUzngAAwEcAAgA9TWFjaW50b3NoIEhEOlVzZXJzOgBjam1heToARG9jdW1lbnRzOgBQYXBlcnM6AGJhY2g6ADIwMTJhLnBkZgAADgAUAAkAMgAwADEAMgBhAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgArVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9iYWNoLzIwMTJhLnBkZgAAEwABLwAAFQACAAz//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgCpAK4AtgJAAkICRwJSAlsCaQJtAnQCfQKCAo8CkgKkAqcCrAAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAKu}}

@inproceedings{bach2012,
	Author = {Francis Bach and Rodolphe Jenatton and Julien Mairal and Guillaume Obozinski},
	Booktitle = {Statistical Science},
	Date-Added = {2014-02-07 15:46:52 +0000},
	Date-Modified = {2014-02-07 15:47:43 +0000},
	Number = {4},
	Pages = {450--468},
	Title = {Structured Sparsity through Convex Optimization},
	Volume = {27},
	Year = {2012},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QFy4uL1BhcGVycy9iYWNoLzIwMTIucGRm0hcLGBlXTlMuZGF0YU8RAYAAAAAAAYAAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM7sZVxIKwAAAC7RLAgyMDEyLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALawazxe4FwAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAEYmFjaAAQAAgAAM7sq6wAAAARAAgAAM8X/mcAAAABABQALtEsABQxxAAFM58ABTOeAADARwACADxNYWNpbnRvc2ggSEQ6VXNlcnM6AGNqbWF5OgBEb2N1bWVudHM6AFBhcGVyczoAYmFjaDoAMjAxMi5wZGYADgASAAgAMgAwADEAMgAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAKlVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvYmFjaC8yMDEyLnBkZgATAAEvAAAVAAIADP//AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAKgArQC1AjkCOwJAAksCVAJiAmYCbQJ2AnsCiAKLAp0CoAKlAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAqc=}}

@inproceedings{bryant2012,
	Author = {Michael Bryant and Erik B. Sudderth},
	Booktitle = {Advances in Neural Information Processing Systems 25 (NIPS)},
	Comments = {Bryant and Sudderth (2012) apply split-merge topic updates and stochastic gradient descent to learn a nonparametric topic model (the hierarchical Dirichlet process, or HDP) with on-line adaptation of the number of topics in the variational Bayes framework. Previous work has applied split-merge proposals to variational inference in parametric models, and to MCMC inference in nonparametric models, but not to variational inference in nonparametric models. In addition, the previous work only investigated split-merge proposals based on an objective evaluated over the entire dataset. For scalability, Bryant and Sudderth employ stochastic gradient descent for online variational inference in a nonparametric model. They introduce an unbiased estimate for the split-merge objective based only on a mini-batch of the data and interleave split and merge updates with the E and M steps of stochastic gradient descent in the variational inference framework (drawing a metaphor to the EM algorithm). Specifically, after the E step, each topic in turn is considered to be split into two topics, and the split is accepted if an estimate of the variational lower bound under the split is higher than the original variational lower bound. (However, in practice the number of splits that may be accepted in an iteration is constrained to be no larger than a user-specified parameter.) Then, after the M step, pairs of topics whose word distributions have sufficiently large positive sample covariance will be considered for merging, and again, if the estimate of the variational lower bound under the merge is greater than the original variational lower bound, the merge will be accepted. Bryant and Sudderth evaluate their algorithm against the status quo variational inference algorithm for HDP, in which the number of topics is truncated at some large number that is believed to be greater than the number of topics present in the data. They also compare against collapsed Gibbs sampling and a CRF-style approach. Held-out likelihood estimation, in which the first part of each document is used to infer topic proportions and the latter part is used for likelihood estimation itself, is used for evaluation. Evaluation is performed both on a synthetic dataset and on two real corpora, and the new split-merge approach in online VB is shown to generalize better and better avoid local optima than the other methods.},
	Date-Added = {2014-02-07 15:40:15 +0000},
	Date-Modified = {2014-02-07 15:41:05 +0000},
	Title = {Truly Nonparametric Online Variational Inference for Hierarchical {D}irichlet Processes},
	Year = {2012},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGS4uL1BhcGVycy9icnlhbnQvMjAxMi5wZGbSFwsYGVdOUy5kYXRhTxEBhgAAAAABhgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAALtBbCDIwMTIucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAuz1DPGmd0AAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAAZicnlhbnQAEAAIAADO7KusAAAAEQAIAADPGq3EAAAAAQAUAC7QWwAUMcQABTOfAAUzngAAwEcAAgA+TWFjaW50b3NoIEhEOlVzZXJzOgBjam1heToARG9jdW1lbnRzOgBQYXBlcnM6AGJyeWFudDoAMjAxMi5wZGYADgASAAgAMgAwADEAMgAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIALFVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvYnJ5YW50LzIwMTIucGRmABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AqgCvALcCQQJDAkgCUwJcAmoCbgJ1An4CgwKQApMCpQKoAq0AAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACrw==}}

@article{hoffman2013,
	Author = {Matthew D. Hoffman and David M. Blei and Chong Wang and John Paisley},
	Comments = {Hoffman et al. (2013) put forth a general framework for stochastic variational inference. They assume a graphical model in which global variables give rise to local variables and observations, and each observation also depends on a local variable. The conditional posteriors and priors are assumed to be exponential family. This structure subsumes latent Dirichlet allocation (LDA), the hierarchical Dirichlet process (HDP), and other models. Hoffman et al. (2013) describe coordinate ascent mean-field variational inference in this class of models, and show how this fundamental batch algorithm relates to stochastic gradient ascent using natural gradients (which correspond to KL divergence rather than the Euclidean distance, and thus more appropriately measure dissimilarity between distributions). Using a first-order approximation, Hoffman et al. (2013) derive an efficient natural gradient update. They also show how their framework can easily be extended to operate on mini-batches for the sake of efficiency and robustness, and estimate model hyperparameters empirically. Implementation of the stochastic variational inference framework to LDA and HDP is described in significant detail. The authors then study how stochastic variational inference compares to batch variational inference, how a learned LDA model compares to a learned HDP model via stochastic variational inference, and how stochastic variational inference reacts to mini-batch size and learning rate parameters in both models, using experiments on Nature and New York Times corpora. The results are reported in terms of the log predictive probability, which is computed as a likelihood of fractional held-out documents. (The first part of each testing document is used for inference of topic proportions.) The authors find that stochastic variational inference achieves better log predictive probability than batch, and in less time; as expected, better log predictive probability is achieved for HDP than for LDA; and stochastic variational inference is somewhat sensitive to the mini-batch size and learning rate parameters, although finding the right parameters appears to be a matter of setting them ``high enough.''},
	Date-Added = {2014-02-07 15:38:56 +0000},
	Date-Modified = {2014-02-20 13:25:35 +0000},
	Journal = {Journal of Machine Learning Research},
	Month = {May},
	Pages = {1303--1347},
	Read = {1},
	Title = {Stochastic Variational Inference},
	Volume = {14},
	Year = {2013},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGi4uL1BhcGVycy9ob2ZmbWFuLzIwMTMucGRm0hcLGBlXTlMuZGF0YU8RAYwAAAAAAYwAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM7sZVxIKwAAABQyTAgyMDEzLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAALs7GzxpnbAAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAHaG9mZm1hbgAAEAAIAADO7KusAAAAEQAIAADPGq28AAAAAQAUABQyTAAUMcQABTOfAAUzngAAwEcAAgA/TWFjaW50b3NoIEhEOlVzZXJzOgBjam1heToARG9jdW1lbnRzOgBQYXBlcnM6AGhvZmZtYW46ADIwMTMucGRmAAAOABIACAAyADAAMQAzAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgAtVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9ob2ZmbWFuLzIwMTMucGRmAAATAAEvAAAVAAIADP//AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAKsAsAC4AkgCSgJPAloCYwJxAnUCfAKFAooClwKaAqwCrwK0AAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAArY=}}

@misc{liang2009a,
	Author = {Percy Liang and Dan Klein},
	Date-Added = {2014-02-07 15:37:36 +0000},
	Date-Modified = {2014-02-20 13:27:51 +0000},
	Howpublished = {Slides presented at NAACL talk},
	Month = {Jun},
	Read = {1},
	Title = {Online EM for Unsupervised Models},
	Year = {2009},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGS4uL1BhcGVycy9saWFuZy8yMDA5YS5wZGbSFwsYGVdOUy5kYXRhTxEBiAAAAAABiAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAALtA4CTIwMDlhLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAtqBXPF7c1AAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAAVsaWFuZwAAEAAIAADO7KusAAAAEQAIAADPF/2FAAAAAQAUAC7QOAAUMcQABTOfAAUzngAAwEcAAgA+TWFjaW50b3NoIEhEOlVzZXJzOgBjam1heToARG9jdW1lbnRzOgBQYXBlcnM6AGxpYW5nOgAyMDA5YS5wZGYADgAUAAkAMgAwADAAOQBhAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgAsVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9saWFuZy8yMDA5YS5wZGYAEwABLwAAFQACAAz//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgCqAK8AtwJDAkUCSgJVAl4CbAJwAncCgAKFApIClQKnAqoCrwAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAKx}}

@inproceedings{liang2009,
	Author = {Percy Liang and Dan Klein},
	Booktitle = {NAACL},
	Comments = {Liang and Klein (2009) perform a thorough study of batch and online expectation-maximization (EM) algorithms on four unsupervised learning tasks in natural language processing: part-of-speech tagging, document classification, word segmentation, and word alignment. Specifically, they evaluate the standard batch EM algorithm, incremental EM, an online algorithm that updates one sufficient statistic value at a time, and stepwise EM, an online algorithm that updates all sufficient statistics at once by taking a convex combination of the previous statistics and the new local statistics, similar to stochastic gradient descent. Performance is measured by likelihood, which is equivalent to the objective function of the algorithms, as well as accuracy, which in previous studies has been shown not to correlate strongly with likelihood. Liang and Klein study performance as an effect of mini-batch size in both online algorithms, and as an effect of a step-size parameter $\alpha$ in stepwise EM. The online algorithms are sensitive to these parameters. However, the choice of mini-batch size and step-size parameter tuned to maximize likelihood on a small held-out set yields a stepwise EM algorithm that achieves higher likelihood and accuracy than batch EM on almost all tasks, and reaches those levels of performance in only a few iterations---much sooner than batch EM. The notable exception is Chinese word segmentation, in which after four iterations batch EM obtains a higher F1-score than stepwise EM. If the parameters are tuned instead to maximize accuracy on a small held-out set, then stepwise EM shows a large performance increase over batch EM in all tasks but Chinese word segmentation, in which it achieves F1-score almost equal to batch EM (78.1 versus 78.2). In these experiments, stepwise EM with step-size parameter and mini-batch size arbitrarily set to one, and incremental EM, generally perform poorly. (They do, however, match the likelihood obtained by the other algorithms in English and Chinese word segmentation.) Liang and Klein also perform a small factorial study over the step-size and mini-batch size parameters in stepwise EM. A negative relationship is observed between the two parameters at the optimal level of performance: If the parameters have been tuned appropriately, and one wishes to decrease the mini-batch size without harming accuracy and likelihood, the step-size parameter should be decreased. The authors also study the impact of the random seed used to initialize the parameters and the random seed used to shuffle the data, and find that stepwise EM is slightly more sensitive to the data order than batch EM.},
	Date-Added = {2014-02-07 15:35:41 +0000},
	Date-Modified = {2014-02-20 13:25:47 +0000},
	Read = {1},
	Title = {Online EM for Unsupervised Models},
	Year = {2009},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGC4uL1BhcGVycy9saWFuZy8yMDA5LnBkZtIXCxgZV05TLmRhdGFPEQGGAAAAAAGGAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADO7GVcSCsAAAAu0DgIMjAwOS5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAC2iDs8XtWwAAAAAAAAAAAABAAMAAAkgAAAAAAAAAAAAAAAAAAAABWxpYW5nAAAQAAgAAM7sq6wAAAARAAgAAM8X+7wAAAABABQALtA4ABQxxAAFM58ABTOeAADARwACAD1NYWNpbnRvc2ggSEQ6VXNlcnM6AGNqbWF5OgBEb2N1bWVudHM6AFBhcGVyczoAbGlhbmc6ADIwMDkucGRmAAAOABIACAAyADAAMAA5AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgArVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9saWFuZy8yMDA5LnBkZgAAEwABLwAAFQACAAz//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgCpAK4AtgJAAkICRwJSAlsCaQJtAnQCfQKCAo8CkgKkAqcCrAAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAKu}}

@book{bickel2001,
	Author = {Peter J. Bickel and Kjell A. Doksum},
	Date-Added = {2014-01-31 19:53:25 +0000},
	Date-Modified = {2014-01-31 19:54:35 +0000},
	Publisher = {Prentice Hall},
	Title = {Mathematical Statistics: Basic Ideas and Selected Topics},
	Year = {2001},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGS4uL1BhcGVycy9iaWNrZWwvMjAwMS5wZGbSFwsYGVdOUy5kYXRhTxEBhgAAAAABhgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAAKo3GCDIwMDEucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAqjV7PEWkQAAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAAZiaWNrZWwAEAAIAADO7KusAAAAEQAIAADPEa9gAAAAAQAUACqNxgAUMcQABTOfAAUzngAAwEcAAgA+TWFjaW50b3NoIEhEOlVzZXJzOgBjam1heToARG9jdW1lbnRzOgBQYXBlcnM6AGJpY2tlbDoAMjAwMS5wZGYADgASAAgAMgAwADAAMQAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIALFVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvYmlja2VsLzIwMDEucGRmABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AqgCvALcCQQJDAkgCUwJcAmoCbgJ1An4CgwKQApMCpQKoAq0AAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACrw==}}

@book{cover1991,
	Author = {Thomas M. Cover and Joy A. Thomas},
	Date-Added = {2014-01-31 19:52:25 +0000},
	Date-Modified = {2014-01-31 19:53:18 +0000},
	Publisher = {John Wiley \& Sons},
	Title = {Elements of Information Theory},
	Year = {1991},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGC4uL1BhcGVycy9jb3Zlci8xOTkxLnBkZtIXCxgZV05TLmRhdGFPEQGGAAAAAAGGAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADO7GVcSCsAAAAqjbYIMTk5MS5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACnxDM8QGvgAAAAAAAAAAAABAAMAAAkgAAAAAAAAAAAAAAAAAAAABWNvdmVyAAAQAAgAAM7sq6wAAAARAAgAAM8QYUgAAAABABQAKo22ABQxxAAFM58ABTOeAADARwACAD1NYWNpbnRvc2ggSEQ6VXNlcnM6AGNqbWF5OgBEb2N1bWVudHM6AFBhcGVyczoAY292ZXI6ADE5OTEucGRmAAAOABIACAAxADkAOQAxAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgArVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9jb3Zlci8xOTkxLnBkZgAAEwABLwAAFQACAAz//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgCpAK4AtgJAAkICRwJSAlsCaQJtAnQCfQKCAo8CkgKkAqcCrAAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAKu}}

@inproceedings{mimno2011,
	Author = {David Mimno and Hanna M. Wallach and Edmund Talley and Miriam Leenders and Andrew McCallum},
	Booktitle = {Proceedings of the Conference on Empirical Methods on Natural Language Processing (EMNLP)},
	Comments = {Mimno et al. (2011) study types of flaws in the topics under a topic model, propose a new estimator for topic coherence that does not require external resources, and introduce a new topic model that allows more general interactions between words than latent Dirichlet allocation (in which seeing a word can only increase the relative weight of that word in its inferred topic). The new estimator is based on the hypothesis that previous coherence estimators did not make full use of the co-occurrence information in the topics. It resembles pointwise mutual information and is computed over the corpus being modeled, rather than an external reference corpus as in Newman et al. (2010). It is found to be a good indicator of topic quality, as measured by human annotators, at least in relation to topic size. Mimno et al. (2011) developed an extension of latent Dirichlet allocation to directly optimize for this metric: specifically, when a token is observed in a Gibbs sampling setup, a count is incremented for the sampled topic and word type, and fractional counts are also incremented for other word types in the topic. The degree to which those fractional counts are updated is called the schema, and Mimno et al. (2011) choose to use inverse document frequency weighting in the schemas used in their experiments on NIH abstracts. They find that traditional latent Dirichlet allocation ultimately achieves better held-out likelihood than the new (generalized P\'{o}lya urn) model, but lower coherence. This result agrees with a previous study's observation that the two metrics do not always correlate. Finally, it is noted that while the proposed coherence metric facilitates detection of bad topics (as judged by human annotators) and the new topic model improves the quality (as judged by human annotators) of bad topics, the new model does not reduce the number of bad topics that are produced.},
	Date-Added = {2014-01-31 17:15:15 +0000},
	Date-Modified = {2014-02-20 13:27:36 +0000},
	Month = {Jul},
	Pages = {262-272},
	Read = {1},
	Title = {Optimizing Semantic Coherence in Topic Models},
	Year = {2011},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGC4uL1BhcGVycy9taW1uby8yMDExLnBkZtIXCxgZV05TLmRhdGFPEQGGAAAAAAGGAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADO7GVcSCsAAAAUMl8IMjAxMS5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACndFs8P1+0AAAAAAAAAAAABAAMAAAkgAAAAAAAAAAAAAAAAAAAABW1pbW5vAAAQAAgAAM7sq6wAAAARAAgAAM8QHj0AAAABABQAFDJfABQxxAAFM58ABTOeAADARwACAD1NYWNpbnRvc2ggSEQ6VXNlcnM6AGNqbWF5OgBEb2N1bWVudHM6AFBhcGVyczoAbWltbm86ADIwMTEucGRmAAAOABIACAAyADAAMQAxAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgArVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9taW1uby8yMDExLnBkZgAAEwABLwAAFQACAAz//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgCpAK4AtgJAAkICRwJSAlsCaQJtAnQCfQKCAo8CkgKkAqcCrAAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAKu}}

@inproceedings{newman2010,
	Author = {David Newman and Jey Han Lau and Karl Grieser and Timothy Baldwin},
	Booktitle = {Human Language Technologies: 11th Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL HLT)},
	Comments = {Newman et al. (2010) introduce the task of evaluating topic coherence in a topic model, where topic coherence intuitively measures how sensical a topic individually is. The authors define topic coherence as an empirical measure, estimated by human annotators. They then propose several automatic approaches for estimating coherence, including metrics based on WordNet, Wikipedia, and Google. A topic is approximated by the ten most probable words in its distribution; metrics based on WordNet and Wikipedia are computed as a mean of pairwise similarities, and metrics based on Google are computed from the results of a Google query consisting of the ten words representing the topic. Newman et al. (2010) evaluate these coherence estimates empirically on a news corpus and on a corpus of books. They find that computing pointwise mutual information based on co-occurrence in Wikipedia yields the closest and most consistent coherence estimates, closely approximating the inter-annotator agreement (in terms of the Spearman rank correlation) on both datasets. The Google-based approaches perform well on the news corpus, even surpassing inter-annotator agreement, but falter on the books corpus due to domain mismatch. Wikipedia-based approaches other than pointwise mutual information perform relatively well; on the other hand, WordNet-based approaches perform generally poorly and high variance is observed between them.},
	Date-Added = {2014-01-31 17:12:34 +0000},
	Date-Modified = {2014-02-07 15:45:16 +0000},
	Month = {Jun},
	Pages = {100--108},
	Read = {1},
	Title = {Automatic Evaluation of Topic Coherence},
	Year = {2010},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGS4uL1BhcGVycy9uZXdtYW4vMjAxMC5wZGbSFwsYGVdOUy5kYXRhTxEBhgAAAAABhgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAAFDJlCDIwMTAucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAqlCbPD3qMAAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAAZuZXdtYW4AEAAIAADO7KusAAAAEQAIAADPD8DcAAAAAQAUABQyZQAUMcQABTOfAAUzngAAwEcAAgA+TWFjaW50b3NoIEhEOlVzZXJzOgBjam1heToARG9jdW1lbnRzOgBQYXBlcnM6AG5ld21hbjoAMjAxMC5wZGYADgASAAgAMgAwADEAMAAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIALFVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvbmV3bWFuLzIwMTAucGRmABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AqgCvALcCQQJDAkgCUwJcAmoCbgJ1An4CgwKQApMCpQKoAq0AAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACrw==}}

@book{devroye1997,
	Author = {Luc Devroye and L\'{a}szl\'{o} Gy\"{o}rfi and G\'{a}bor Lugosi},
	Date-Added = {2014-01-28 17:20:46 +0000},
	Date-Modified = {2014-01-28 17:24:24 +0000},
	Publisher = {Springer},
	Title = {A Probabilistic Theory of Pattern Recognition},
	Year = {1997},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGi4uL1BhcGVycy9kZXZyb3llLzE5OTcucGRm0hcLGBlXTlMuZGF0YU8RAYwAAAAAAYwAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM7sZVxIKwAAACjNqQgxOTk3LnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKMeuzw1PLAAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAHZGV2cm95ZQAAEAAIAADO7KusAAAAEQAIAADPDZV8AAAAAQAUACjNqQAUMcQABTOfAAUzngAAwEcAAgA/TWFjaW50b3NoIEhEOlVzZXJzOgBjam1heToARG9jdW1lbnRzOgBQYXBlcnM6AGRldnJveWU6ADE5OTcucGRmAAAOABIACAAxADkAOQA3AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgAtVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9kZXZyb3llLzE5OTcucGRmAAATAAEvAAAVAAIADP//AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAKsAsAC4AkgCSgJPAloCYwJxAnUCfAKFAooClwKaAqwCrwK0AAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAArY=}}

@inproceedings{broderick2013,
	Author = {Tamara Broderick and Nicholas Boyd and Andre Wibisono and Ashia C. Wilson and Michael I. Jordan},
	Booktitle = {Advances in Neural Information Processing Systems 26 (NIPS)},
	Comments = {Broderick et al. (2013) describe a framework for streaming, distributed (asynchronous) Bayesian learning, named SDA-Bayes. Specifically, they lay out a model for recursively updating a posterior with mini-batches of data, where the prior is in the exponential family and there is an (approximating) algorithm for the posterior update that yields distributions in that same exponential family. The posterior updates can be combined by simply summing the respective exponential family parameters, which lends immediately to (synchronous) parallelization. However, in practice one or two mini-batches may require significantly more computation time than the others, so the authors propose a simple, approximate asynchronous computation model. The SDA-Bayes framework is applied to the task of learning the topic distributions (over words) in latent Dirichlet allocation, using variational Bayes for the algorithm approximating posterior updates. (Expectation propagation was also investigated, but proved impractical due to high resource requirements.) It is evaluated against two other one-pass algorithms, stochastic variational inference and a ``sufficient statistics update algorithm'' based on variational Bayes, in experiments on Wikipedia and Nature data. SDA-Bayes yields better held-out likelihood and runtime, when parallelized. It is also found to be less sensitive to mini-batch size and the learning rate than stochastic variational inference, and does not require the stream length to be fixed and specified \emph{a priori}.},
	Date-Added = {2014-01-27 14:03:08 +0000},
	Date-Modified = {2014-02-07 15:43:23 +0000},
	Month = {Dec},
	Read = {1},
	Title = {Streaming Variational {B}ayes},
	Year = {2013},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QHC4uL1BhcGVycy9icm9kZXJpY2svMjAxMy5wZGbSFwsYGVdOUy5kYXRhTxEBkgAAAAABkgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAAKE3wCDIwMTMucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQbRDOtNxqAAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAAlicm9kZXJpY2sAABAACAAAzuyrrAAAABEACAAAzrUiugAAAAEAFAAoTfAAFDHEAAUznwAFM54AAMBHAAIAQU1hY2ludG9zaCBIRDpVc2VyczoAY2ptYXk6AERvY3VtZW50czoAUGFwZXJzOgBicm9kZXJpY2s6ADIwMTMucGRmAAAOABIACAAyADAAMQAzAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgAvVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9icm9kZXJpY2svMjAxMy5wZGYAABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4ArQCyALoCUAJSAlcCYgJrAnkCfQKEAo0CkgKfAqICtAK3ArwAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACvg==}}

@article{fearnhead2002,
	Author = {Paul Fearnhead},
	Comments = {Fearnhead (2002) describes how to use sufficient statistics of a particle's trajectory, instead of the trajectory itself, to reduce the storage complexity of the MCMC (rejuvenation) step of a particle filter. Specifically, the static and state parameters of a model at a given time $t$ are partitioned into two groups, $\gamma$, the parameters of interest at time $t$, and $\delta$, parameters that are no longer needed except for the MCMC step. For example, $\delta$ may be the trajectory up to time $t - 1$. Then, if there is a sufficient statistic for $\gamma$ conditioned on $\delta$ that can be recursively updated, the MCMC steps can be performed over $\gamma$ conditioned on that sufficient statistic instead of $\delta$ itself, and maintained as the particle is propagated using the recursive update. The trajectory itself, meanwhile, can be forgotten, which may effect a reduction in the storage complexity. This approach is tested against other particle filter approaches on the bearings-only tracking model, a classic particle filter example problem in which the position and velocity of a moving ship are tracked in the plane. The observations are the arc tangent of the angle the ship makes with zero, with respect to the origin. Fearnhead evaluates the SIR and ASIR particle filters, as well as the SIR filter with modified initialization and stratified resampling, all with and without MCMC moves; algorithm parameters are chosen such that the runtime of all particle filters is roughly the same. The evaluation is quantified by the effective sample size (ESS) at different time steps in the simulation. Fearnhead notes that the MCMC moves increase the efficiency of all three particle filters; the modified initialization and stratified resampling also improve significantly on the standard SIR filter, but neither augmentation on its own yields a large improvement. Overall, the SIR filter with those two modifications is the most efficient, performing much better (as measured by ESS) than the standard SIR filter and significantly better than the ASIR filter as well. Fearnhead notes that conditioning on sufficient statistics instead of the full trajectory restricts the set of possible MCMC moves, and thus it may be harder to find an approach that mixes well. Additionally, Fearnhead argues that over time the sufficient statistics in the particles will become positively correlated (whereas if the full trajectory is used, independent particles can be produced in theory).},
	Date-Added = {2014-01-24 00:46:48 +0000},
	Date-Modified = {2014-02-07 15:44:20 +0000},
	Journal = {Journal of Computational and Graphical Statistics},
	Month = {Dec},
	Number = {4},
	Pages = {848--862},
	Read = {1},
	Title = {Markov Chain {M}onte {C}arlo, Sufficient Statistics, and Particle Filters},
	Volume = {11},
	Year = {2002},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QHC4uL1BhcGVycy9mZWFybmhlYWQvMjAwMi5wZGbSFwsYGVdOUy5kYXRhTxEBkgAAAAABkgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAAJr1sCDIwMDIucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAhbTbO/Z6XAAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAAlmZWFybmhlYWQAABAACAAAzuyrrAAAABEACAAAzv3k5wAAAAEAFAAmvWwAFDHEAAUznwAFM54AAMBHAAIAQU1hY2ludG9zaCBIRDpVc2VyczoAY2ptYXk6AERvY3VtZW50czoAUGFwZXJzOgBmZWFybmhlYWQ6ADIwMDIucGRmAAAOABIACAAyADAAMAAyAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgAvVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9mZWFybmhlYWQvMjAwMi5wZGYAABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4ArQCyALoCUAJSAlcCYgJrAnkCfQKEAo0CkgKfAqICtAK3ArwAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACvg==}}

@inproceedings{kantas2009,
	Author = {N. Kantas and A. Doucet and S.S. Singh and J.M. Maciejowski},
	Booktitle = {IFAC Symposium on System Identification (SYSID)},
	Comments = {Kantas et al. (2009) survey sequential monte carlo (particle filtering) methods for parameter estimation in state-space models. They begin with a review of basic sequential monte carlo, including error bounds that show full joint posterior estimation is a difficult task. In particular, as the filter progresses and resampling is repeatedly performed on the particles, any given state in the stream will eventually be approximated by only a single unique particle, known as the degeneracy problem. However, many models have an exponential forgetting property, which allows error bounds to be established on the most recent $L$ states that depend on $L$ but not $n$. If exponential forgetting holds, we may not be able to approximate the full joint posterior well but we can estimate the posterior for the most recent $L$ states more accurately; errors will not accumulate if the optimal filter has good mixing properties. To combat degeneracy in the smoothing problem with a fixed underlying parameter $\theta$, several approaches have been proposed including a fixed-lag approximation, the forward filtering--backward smoothing algorithm, and the generalized two-filter smoothing approach. Kantas et al. organize their review of parameter estimation methods by whether the methods are Bayesian or maximum-likelihood, and whether they are offline or online. Offline maximum-likelihood estimation can be accomplished by gradient ascent, EM, or an alternative approach called iterated filtering in which the parameter is given artificial state-space dynamics. Methods for approximating the likelihood and gradient are discussed. Online maximum-likelihood estimation includes online variants of gradient ascent and EM, which require $O(N^2)$ computations per time step (where $N$ is the number of particles) but are relatively robust because the depend only on the marginalized joint posterior distribution, the posterior of the most recent state in the sequence. Offline Bayesian methods include a new method called Particle MCMC, in which sequential monte carlo methods are used to estimate proposal distributions for MCMC. This framework has nice theoretical properties; in particular, even with one particle, the invariant distribution of the Markov chain is the joint posterior. The naive online Bayesian approach, in which the parameter $\theta$ is added to the state space, does not work because $\theta$ is quickly approximated by only a single unique particle. In particular, the transition for $\theta$ is the identity function so the initialization of the particle filter is the only time when useful estimation is performed for $\theta$. More sensible online Bayesian approaches include ``practical filtering'' using the fixed-lag approximation, introducing artificial dynamics to the parameter, and incorporating MCMC steps to diversify the particles (referred to by Canini et al. (2009) as ``rejuvenation''). These online approaches are not as robust as the maximum-likelihood methods because they rely implicitly on the full joint posterior, compared to the marginalized posterior. The takeaway message seems to be that if you're doing online inference, use a maximum-likelihood method like online EM or online gradient ascent; Kantas et al. (2009) provide some suggestions between these two methods in the paper. If you're doing offline inference, Particle MCMC might be worth trying. In any case, sequential parameter estimation in these models is hard.},
	Date-Added = {2014-01-16 14:16:08 +0000},
	Date-Modified = {2014-02-07 15:44:38 +0000},
	Read = {1},
	Title = {An Overview of Sequential {M}onte {C}arlo Methods for Parameter Estimation in General State-Space Models},
	Year = {2009},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGS4uL1BhcGVycy9rYW50YXMvMjAwOS5wZGbSFwsYGVdOUy5kYXRhTxEBhgAAAAABhgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAAIU0UCDIwMDkucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAVp47O8H2FAAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAAZrYW50YXMAEAAIAADO7KusAAAAEQAIAADO8MPVAAAAAQAUACFNFAAUMcQABTOfAAUzngAAwEcAAgA+TWFjaW50b3NoIEhEOlVzZXJzOgBjam1heToARG9jdW1lbnRzOgBQYXBlcnM6AGthbnRhczoAMjAwOS5wZGYADgASAAgAMgAwADAAOQAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIALFVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMva2FudGFzLzIwMDkucGRmABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AqgCvALcCQQJDAkgCUwJcAmoCbgJ1An4CgwKQApMCpQKoAq0AAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACrw==}}

@unpublished{doucet2009,
	Author = {Arnaud Doucet and Nando {de Freitas}},
	Date-Added = {2014-01-06 20:53:22 +0000},
	Date-Modified = {2014-02-20 13:28:52 +0000},
	Note = {in NIPS},
	Read = {1},
	Title = {Sequential {M}onte {C}arlo Methods},
	Year = {2009},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGS4uL1BhcGVycy9kb3VjZXQvMjAwOS5wZGbSFwsYGVdOUy5kYXRhTxEBhgAAAAABhgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAAFDI/CDIwMDkucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAVpLrO8HWRAAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAAZkb3VjZXQAEAAIAADO7KusAAAAEQAIAADO8LvhAAAAAQAUABQyPwAUMcQABTOfAAUzngAAwEcAAgA+TWFjaW50b3NoIEhEOlVzZXJzOgBjam1heToARG9jdW1lbnRzOgBQYXBlcnM6AGRvdWNldDoAMjAwOS5wZGYADgASAAgAMgAwADAAOQAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIALFVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvZG91Y2V0LzIwMDkucGRmABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AqgCvALcCQQJDAkgCUwJcAmoCbgJ1An4CgwKQApMCpQKoAq0AAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACrw==},
	Bdsk-File-2 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGi4uL1BhcGVycy9kb3VjZXQvMjAwOWEucGRm0hcLGBlXTlMuZGF0YU8RAYwAAAAAAYwAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM7sZVxIKwAAABQyPwkyMDA5YS5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFZ8szvB1egAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAGZG91Y2V0ABAACAAAzuyrrAAAABEACAAAzvC7ygAAAAEAFAAUMj8AFDHEAAUznwAFM54AAMBHAAIAP01hY2ludG9zaCBIRDpVc2VyczoAY2ptYXk6AERvY3VtZW50czoAUGFwZXJzOgBkb3VjZXQ6ADIwMDlhLnBkZgAADgAUAAkAMgAwADAAOQBhAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgAtVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9kb3VjZXQvMjAwOWEucGRmAAATAAEvAAAVAAIADP//AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAKsAsAC4AkgCSgJPAloCYwJxAnUCfAKFAooClwKaAqwCrwK0AAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAArY=}}

@unpublished{doucet2008e,
	Author = {Arnaud Doucet},
	Date-Added = {2014-01-06 18:12:14 +0000},
	Date-Modified = {2014-02-20 13:28:43 +0000},
	Read = {1},
	Title = {Sequential {M}onte {C}arlo Samplers},
	Year = {2008},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGi4uL1BhcGVycy9kb3VjZXQvMjAwOGUucGRm0hcLGBlXTlMuZGF0YU8RAYwAAAAAAYwAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM7sZVxIKwAAABQyPwkyMDA4ZS5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFP4IzvA4TgAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAGZG91Y2V0ABAACAAAzuyrrAAAABEACAAAzvB+ngAAAAEAFAAUMj8AFDHEAAUznwAFM54AAMBHAAIAP01hY2ludG9zaCBIRDpVc2VyczoAY2ptYXk6AERvY3VtZW50czoAUGFwZXJzOgBkb3VjZXQ6ADIwMDhlLnBkZgAADgAUAAkAMgAwADAAOABlAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgAtVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9kb3VjZXQvMjAwOGUucGRmAAATAAEvAAAVAAIADP//AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAKsAsAC4AkgCSgJPAloCYwJxAnUCfAKFAooClwKaAqwCrwK0AAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAArY=}}

@unpublished{doucet2008d,
	Author = {Arnaud Doucet},
	Date-Added = {2014-01-06 18:10:48 +0000},
	Date-Modified = {2014-02-20 13:28:45 +0000},
	Read = {1},
	Title = {SMC for Recursive Parameter Estimation in State-Space Models},
	Year = {2008},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGi4uL1BhcGVycy9kb3VjZXQvMjAwOGQucGRm0hcLGBlXTlMuZGF0YU8RAYwAAAAAAYwAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM7sZVxIKwAAABQyPwkyMDA4ZC5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFP3bzvA4TQAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAGZG91Y2V0ABAACAAAzuyrrAAAABEACAAAzvB+nQAAAAEAFAAUMj8AFDHEAAUznwAFM54AAMBHAAIAP01hY2ludG9zaCBIRDpVc2VyczoAY2ptYXk6AERvY3VtZW50czoAUGFwZXJzOgBkb3VjZXQ6ADIwMDhkLnBkZgAADgAUAAkAMgAwADAAOABkAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgAtVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9kb3VjZXQvMjAwOGQucGRmAAATAAEvAAAVAAIADP//AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAKsAsAC4AkgCSgJPAloCYwJxAnUCfAKFAooClwKaAqwCrwK0AAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAArY=}}

@unpublished{doucet2008c,
	Author = {Arnaud Doucet},
	Date-Added = {2014-01-06 16:49:39 +0000},
	Date-Modified = {2014-02-20 13:28:45 +0000},
	Read = {1},
	Title = {Advanced Sequential {M}onte {C}arlo Methods},
	Year = {2008},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGi4uL1BhcGVycy9kb3VjZXQvMjAwOGMucGRm0hcLGBlXTlMuZGF0YU8RAYwAAAAAAYwAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM7sZVxIKwAAABQyPwkyMDA4Yy5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFP1szvA4SwAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAGZG91Y2V0ABAACAAAzuyrrAAAABEACAAAzvB+mwAAAAEAFAAUMj8AFDHEAAUznwAFM54AAMBHAAIAP01hY2ludG9zaCBIRDpVc2VyczoAY2ptYXk6AERvY3VtZW50czoAUGFwZXJzOgBkb3VjZXQ6ADIwMDhjLnBkZgAADgAUAAkAMgAwADAAOABjAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgAtVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9kb3VjZXQvMjAwOGMucGRmAAATAAEvAAAVAAIADP//AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAKsAsAC4AkgCSgJPAloCYwJxAnUCfAKFAooClwKaAqwCrwK0AAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAArY=}}

@unpublished{doucet2008b,
	Author = {Arnaud Doucet},
	Date-Added = {2014-01-06 16:26:52 +0000},
	Date-Modified = {2014-02-20 13:28:46 +0000},
	Read = {1},
	Title = {Sequential Importance Sampling Resampling},
	Year = {2008},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGi4uL1BhcGVycy9kb3VjZXQvMjAwOGIucGRm0hcLGBlXTlMuZGF0YU8RAYwAAAAAAYwAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM7sZVxIKwAAABQyPwkyMDA4Yi5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFP0RzvA4SgAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAGZG91Y2V0ABAACAAAzuyrrAAAABEACAAAzvB+mgAAAAEAFAAUMj8AFDHEAAUznwAFM54AAMBHAAIAP01hY2ludG9zaCBIRDpVc2VyczoAY2ptYXk6AERvY3VtZW50czoAUGFwZXJzOgBkb3VjZXQ6ADIwMDhiLnBkZgAADgAUAAkAMgAwADAAOABiAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgAtVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9kb3VjZXQvMjAwOGIucGRmAAATAAEvAAAVAAIADP//AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAKsAsAC4AkgCSgJPAloCYwJxAnUCfAKFAooClwKaAqwCrwK0AAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAArY=}}

@unpublished{doucet2008a,
	Author = {Arnaud Doucet},
	Date-Added = {2014-01-06 16:26:22 +0000},
	Date-Modified = {2014-02-20 13:28:47 +0000},
	Read = {1},
	Title = {Importance Sampling & Sequential Importance Sampling},
	Year = {2008},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGi4uL1BhcGVycy9kb3VjZXQvMjAwOGEucGRm0hcLGBlXTlMuZGF0YU8RAYwAAAAAAYwAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM7sZVxIKwAAABQyPwkyMDA4YS5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFPznzvA4SAAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAGZG91Y2V0ABAACAAAzuyrrAAAABEACAAAzvB+mAAAAAEAFAAUMj8AFDHEAAUznwAFM54AAMBHAAIAP01hY2ludG9zaCBIRDpVc2VyczoAY2ptYXk6AERvY3VtZW50czoAUGFwZXJzOgBkb3VjZXQ6ADIwMDhhLnBkZgAADgAUAAkAMgAwADAAOABhAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgAtVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9kb3VjZXQvMjAwOGEucGRmAAATAAEvAAAVAAIADP//AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAKsAsAC4AkgCSgJPAloCYwJxAnUCfAKFAooClwKaAqwCrwK0AAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAArY=}}

@unpublished{doucet2008,
	Author = {Arnaud Doucet},
	Date-Added = {2014-01-06 16:20:22 +0000},
	Date-Modified = {2014-02-20 13:28:48 +0000},
	Read = {1},
	Title = {Sequential {M}onte {C}arlo: An Introduction},
	Year = {2008},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGS4uL1BhcGVycy9kb3VjZXQvMjAwOC5wZGbSFwsYGVdOUy5kYXRhTxEBhgAAAAABhgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAAFDI/CDIwMDgucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAU/MHO8DhEAAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAAZkb3VjZXQAEAAIAADO7KusAAAAEQAIAADO8H6UAAAAAQAUABQyPwAUMcQABTOfAAUzngAAwEcAAgA+TWFjaW50b3NoIEhEOlVzZXJzOgBjam1heToARG9jdW1lbnRzOgBQYXBlcnM6AGRvdWNldDoAMjAwOC5wZGYADgASAAgAMgAwADAAOAAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIALFVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvZG91Y2V0LzIwMDgucGRmABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AqgCvALcCQQJDAkgCUwJcAmoCbgJ1An4CgwKQApMCpQKoAq0AAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACrw==}}

@article{carvalho2010,
	Author = {Carlos M. Carvalho and Michael S. Johannes and Hedibert F. Lopes and Nicholas G. Polson},
	Comments = {Carvalho et al. (2010) propose an approach to filtering and smoothing in state-space models that is simpler to implement and more efficient, in terms of convergence, than other methods. Their approach, deemed ``particle learning'' (PL), builds on other particle-based methods by utilizing a fully-adapted filter in which resampling is performed before state propagation and by representing hidden parameters and states with sufficient statistics where plausible. PL can be viewed as an extension of the auxiliary particle filter (APF) to accommodate uncertainty in static model parameters. PL thus shares many of the advantages and disadvantages of APF: it facilitates exact draws from the approximated posterior and by consequence yields more evenly-weighted particles, but that hinges on the assumption that the predictive likelihood and conditional state transition distribution are analytically tractable. (If those distributions are not tractable, other proposal distributions may be used instead. This may adversely affect convergence.) The authors note that PL lends not only to sequential filtering but also to smoothing (estimation of all parameters and states based on all observations) and Bayesian model assessment. PL is applied to linear and non-linear state-space models with Gaussian noise, namely, the conditional dynamic linear model and conditional Gaussian dynamic model. Notably, these models both satisfy the tractability requirement of PL. Simulation results suggest that representing uncertainty by sufficient statistics reduces error, when the number of particles is modest, due to reduced dimensionality. (When the number of particles is large, there is no discernible effect.) Generally, PL yields lower-error approximations than competing filtering methods. For smoothing, PL produces similar results to Markov Chain Monte Carlo, and is arguably simpler to implement, but features worse runtime complexity in the number of particles.},
	Date-Modified = {2014-02-07 15:43:28 +0000},
	Journal = {Statistical Science},
	Number = 1,
	Pages = {88--106},
	Read = {1},
	Title = {Particle Learning and Smoothing},
	Volume = 25,
	Year = 2010,
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGy4uL1BhcGVycy9jYXJ2YWxoby8yMDEwLnBkZtIXCxgZV05TLmRhdGFPEQGMAAAAAAGMAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADO7GVcSCsAAAAUMjIIMjAxMC5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABFz2c7hyyEAAAAAAAAAAAABAAMAAAkgAAAAAAAAAAAAAAAAAAAACGNhcnZhbGhvABAACAAAzuyrrAAAABEACAAAzuIRcQAAAAEAFAAUMjIAFDHEAAUznwAFM54AAMBHAAIAQE1hY2ludG9zaCBIRDpVc2VyczoAY2ptYXk6AERvY3VtZW50czoAUGFwZXJzOgBjYXJ2YWxobzoAMjAxMC5wZGYADgASAAgAMgAwADEAMAAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIALlVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvY2FydmFsaG8vMjAxMC5wZGYAEwABLwAAFQACAAz//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgCsALEAuQJJAksCUAJbAmQCcgJ2An0ChgKLApgCmwKtArACtQAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAK3}}

@inproceedings{doucet2000,
	Author = {Arnaud Doucet and Nando {de Freitas} and Kevin Murphy and Stuart Russell},
	Booktitle = {Proceedings of the 16th Conference on Uncertainty in Artificial Intelligence (UAI)},
	Comments = {Doucet et al. (2000) describe the application of particle filtering for learning in dynamic Bayesian networks (DBNs). In particular, they apply Rao-Blackwellized particle filters (RBPFs) to learn in DBNs whose hidden variables can be separated into two layers, one of which can be marginalized out. By marginalizing out some of the hidden variables the dimensionality of the sample space is reduced, hence the variance of the particle filter is also reduced. Doucet et al. justify these intuitions theoretically, discuss practical implementation issues including resampling and rejuvenation, and demonstrate the efficacy of their approach with experiments on a regression model and on a small robot localization problem. The RBPF performs well in these experiments, closely approximating the exact solution in the robot localization problem. Doucet et al. conclude by suggesting efficiency improvements and alternative models to which RBPFs could be applied.},
	Date-Modified = {2014-02-07 15:44:00 +0000},
	Month = {Jun},
	Pages = {176--183},
	Read = {1},
	Title = {{R}ao-{B}lackwellised Particle Filtering for Dynamic {B}ayesian Networks},
	Year = 2000,
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGS4uL1BhcGVycy9kb3VjZXQvMjAwMC5wZGbSFwsYGVdOUy5kYXRhTxEBhgAAAAABhgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAAFDI/CDIwMDAucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAARc6bO4eG4AAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAAZkb3VjZXQAEAAIAADO7KusAAAAEQAIAADO4igIAAAAAQAUABQyPwAUMcQABTOfAAUzngAAwEcAAgA+TWFjaW50b3NoIEhEOlVzZXJzOgBjam1heToARG9jdW1lbnRzOgBQYXBlcnM6AGRvdWNldDoAMjAwMC5wZGYADgASAAgAMgAwADAAMAAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIALFVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvZG91Y2V0LzIwMDAucGRmABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AqgCvALcCQQJDAkgCUwJcAmoCbgJ1An4CgwKQApMCpQKoAq0AAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACrw==}}

@inproceedings{scott2013,
	Author = {James G. Scott and Jason Baldridge},
	Booktitle = {Proceedings of the 16th International Conference on Artificial Intelligence and Statistics (AISTATS)},
	Comments = {Scott and Baldridge (2013) attack the problem of efficiently computing the predictive log likelihood under a topic model such as LDA. They first propose an approach analogous to particle filtering, called ``particle learning'' in this context. This algorithm is similar to the left-to-right evaluation algorithm of Wallach et al. (2009), and like the left-to-right algorithm, has runtime complexity quadratic in the number of tokens. Scott and Baldridge (2013) then suggest a filtering approximation, in which a single particle approximates the first moment of the posterior, instead of a particle cloud approximating the posterior itself (as in particle learning). This approach has runtime linear in the number of tokens, and is therefore more appropriate for evaluation over a large held-out dataset. A variant of the left-to-right algorithm without resampling is also briefly considered but the authors make a firm argument against this approach. The original left-to-right algorithm, particle learning, and the proposed filtering approach yield similar likelihood estimates on real and simulated corpora, but the filtering approach does so in a fraction of the time. The authors therefore recommend the filtering algorithm for evaluating topic models, especially when the held-out dataset is large.},
	Date-Modified = {2014-02-07 15:45:25 +0000},
	Month = {Apr},
	Read = {1},
	Title = {A recursive estimate for the predictive likelihood in a topic model},
	Year = 2013,
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGC4uL1BhcGVycy9zY290dC8yMDEzLnBkZtIXCxgZV05TLmRhdGFPEQGGAAAAAAGGAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADO7GVcSCsAAAAUMpQIMjAxMy5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABFziM7LodsAAAAAAAAAAAABAAMAAAkgAAAAAAAAAAAAAAAAAAAABXNjb3R0AAAQAAgAAM7sq6wAAAARAAgAAM7L6CsAAAABABQAFDKUABQxxAAFM58ABTOeAADARwACAD1NYWNpbnRvc2ggSEQ6VXNlcnM6AGNqbWF5OgBEb2N1bWVudHM6AFBhcGVyczoAc2NvdHQ6ADIwMTMucGRmAAAOABIACAAyADAAMQAzAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgArVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9zY290dC8yMDEzLnBkZgAAEwABLwAAFQACAAz//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgCpAK4AtgJAAkICRwJSAlsCaQJtAnQCfQKCAo8CkgKkAqcCrAAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAKu}}

@inproceedings{borschinger2012,
	Author = {Benjamin B\"{o}rschinger and Mark Johnson},
	Booktitle = {Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (ACL)},
	Comments = {In previous work, Borschinger and Johnson (2011) introduced a particle filter for streaming learning in a nonparametric Bayesian word segmentation model. In this study, Borschinger and Johnson (2012) add a rejuvenation step to this particle filter and study the effects on performance (as measured by token F-score and model log probability). The augmentation of the rejuvenation step is motivated in part by Decayed Markov Chain Monte Carlo, an online algorithm that assumes access to history of the stream and performed well in learning the bigram model in a previous paper. (In comparison, the particle filter performed poorly on the bigram model.) Borschinger and Johnson find that rejuvenation helps the token F1 score considerably on the bigram model, and that effect is magnified as the number of particles grows. However, as in the previous study, the particle filter assigns relatively low probabilities to the models it learns. This trend is hypothesized to be a fundamental gap between batch and incremental learners.},
	Date-Modified = {2014-02-07 15:42:43 +0000},
	Month = {Jul},
	Pages = {85--89},
	Read = {1},
	Title = {Using Rejuvenation to Improve Particle Filtering for {B}ayesian Word Segmentation},
	Year = 2012,
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QHi4uL1BhcGVycy9ib3JzY2hpbmdlci8yMDEyLnBkZtIXCxgZV05TLmRhdGFPEQGYAAAAAAGYAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADO7GVcSCsAAAAUMgkIMjAxMi5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABFzoM7FHbAAAAAAAAAAAAABAAMAAAkgAAAAAAAAAAAAAAAAAAAAC2JvcnNjaGluZ2VyAAAQAAgAAM7sq6wAAAARAAgAAM7FZAAAAAABABQAFDIJABQxxAAFM58ABTOeAADARwACAENNYWNpbnRvc2ggSEQ6VXNlcnM6AGNqbWF5OgBEb2N1bWVudHM6AFBhcGVyczoAYm9yc2NoaW5nZXI6ADIwMTIucGRmAAAOABIACAAyADAAMQAyAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgAxVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9ib3JzY2hpbmdlci8yMDEyLnBkZgAAEwABLwAAFQACAAz//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgCvALQAvAJYAloCXwJqAnMCgQKFAowClQKaAqcCqgK8Ar8CxAAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAALG}}

@inproceedings{borschinger2011,
	Author = {Benjamin B\"{o}rschinger and Mark Johnson},
	Booktitle = {Australasian Language Technology Association Workshop (ALTA)},
	Comments = {Borschinger and Johnson (2011) tackle the problem of streaming learning in a word segmentation model based on the Chinese Restaurant Process. They note that a streaming algorithm is both attractive from the standpoint of computational efficiency and relatively plausible as a model of human cognition. They introduce a particle filter algorithm for learning the model in a streaming setting, and compare this algorithm against other online (but not streaming) algorithms as well as a batch algorithm. According to the authors, no competing streaming algorithm has been applied to this model. The authors find that the particle filter performs well in recovering tokens and segmentation boundaries (as measured by F-score) for a unigram model. Although a particle filter achieves higher F-score on these tasks than the other algorithms, it assigns lower probabililty to its model. For the particle filter, lower effective sample sizes, and larger numbers of particles, seem to yield better performance. Performance is poor for a bigram model, presumably due to the high dimensionality of the state space relative to the number of particles. Additionally, the particle filter exhibits relatively large variance, and this variance does not correlate with the number of particles.},
	Date-Modified = {2014-02-07 15:42:42 +0000},
	Month = {Dec},
	Pages = {10--18},
	Read = {1},
	Title = {A Particle Filter algorithm for {B}ayesian Wordsegmentation},
	Year = 2011,
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QHi4uL1BhcGVycy9ib3JzY2hpbmdlci8yMDExLnBkZtIXCxgZV05TLmRhdGFPEQGYAAAAAAGYAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADO7GVcSCsAAAAUMgkIMjAxMS5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABFzn87FHawAAAAAAAAAAAABAAMAAAkgAAAAAAAAAAAAAAAAAAAAC2JvcnNjaGluZ2VyAAAQAAgAAM7sq6wAAAARAAgAAM7FY/wAAAABABQAFDIJABQxxAAFM58ABTOeAADARwACAENNYWNpbnRvc2ggSEQ6VXNlcnM6AGNqbWF5OgBEb2N1bWVudHM6AFBhcGVyczoAYm9yc2NoaW5nZXI6ADIwMTEucGRmAAAOABIACAAyADAAMQAxAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgAxVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9ib3JzY2hpbmdlci8yMDExLnBkZgAAEwABLwAAFQACAAz//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgCvALQAvAJYAloCXwJqAnMCgQKFAowClQKaAqcCqgK8Ar8CxAAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAALG}}

@inproceedings{dechoudhury2013,
	Author = {Munmun {De Choudhury} and Scott Counts and Eric Horvitz},
	Booktitle = {CSCW '13},
	Comments = {De Choudhury et al. (2013) analyze the effect of childbirth on new mothers as expressed via Twitter. They use a relatively high-recall keyword search to identify childbirth announcements in a two-month window in the middle of a year-long Twitter dataset, filter that candidate set to a set of 85 new mothers using a name-based gender classifier and crowdsourcing (in turn), collect all tweets posted by those new mothers in the year-long collection period, and analyze how features of activity, emotion, and linguistic style change both over time and between the new mothers and a set of background Twitter users. The authors find that new mothers differ significantly along many dimensions before and after birth, and also differ significantly along many dimensions from the background user set after birth. The specific changes are largely the same between the two comparisons (mothers before and after birth, mothers after birth and background after birth). They include decreased activity, increased negative affect, decreased positive affect, increased first-person pronouns, decreased second- and third-person pronouns, increased articles, increased conjunctions, increased adverbs, increased negation, decreased certainty, increased swear words, and decreased activation and dominance. These observations generally align with results from the psycholinguistic literature on post-partum depression and depression in general. Plots of selected measures over time for the mothers often show a ``smile'' after birth, that is, a gradual decrease (or increase), leveling-off, then return to normal. De Choudhury et al. (2013) also observe that there is high variability among new mothers. For each type of measure (activity, emotion, linguistic style), they partition new mothers into four groups: those with large effect sizes, those with medium effect sizes, those with small effect sizes, and those whose effects were negligible. This partition was decided using Cohen's d statistic with thresholds of 0.8, 0.5, and 0.2 for large, medium, and small effect sizes, respectively. The authors then narrow down to the mothers with large overall effects, i.e. whose effects in all three measure types were large, and mothers will small overall effects, i.e. whose effects in all three measure types were small. There were 12 and 15 mothers in these two groups, respectively. The authors compute the unigrams whose occurrences change most between the prenatal and postnatal periods in both of those groups, as well as the background user set. The largest-changing unigrams in the mothers with large overall effects suggest those mothers are experiencing significantly increased negative emotion. The largest-changing unigrams in the other two user sets do not indicate such a clear trend. The authors also use a ``greedy differencing'' analysis to estimate how many unigram types contributed to the change in the mothers with large overall effects. They concluded that the difference between large-overall-effect mothers and small-overall-effect mothers is attributable to approximately one percent of the vocabulary, whereas the difference between large-overal-effect mothers and the background user set is attributable to approximately ten percent of the vocabulary. In their conclusion, the authors reiterate that their study is meant as a proof of concept and point out several shortcomings in the particular methods they used. They claim, however, that their results suggest the viability of automated detection and prediction of postpartum depression.},
	Date-Modified = {2014-02-07 15:43:53 +0000},
	Month = {Feb},
	Read = {1},
	Title = {Major Life Changes and Behavioral Markers in Social Media: Case of Childbirth},
	Year = 2013,
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QHy4uL1BhcGVycy9kZSBjaG91ZGh1cnkvMjAxMy5wZGbSFwsYGVdOUy5kYXRhTxEBmAAAAAABmAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAAFDI7CDIwMTMucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAARc8/Owj5OAAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAAxkZSBjaG91ZGh1cnkAEAAIAADO7KusAAAAEQAIAADOwoSeAAAAAQAUABQyOwAUMcQABTOfAAUzngAAwEcAAgBETWFjaW50b3NoIEhEOlVzZXJzOgBjam1heToARG9jdW1lbnRzOgBQYXBlcnM6AGRlIGNob3VkaHVyeToAMjAxMy5wZGYADgASAAgAMgAwADEAMwAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAMlVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvZGUgY2hvdWRodXJ5LzIwMTMucGRmABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AsAC1AL0CWQJbAmACawJ0AoIChgKNApYCmwKoAqsCvQLAAsUAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACxw==}}

@inproceedings{monroyhernandez2013,
	Author = {Andr\'{e}s Monroy-Hern\'{a}ndez and danah boyd and Emre Kiciman and Munmun {De Choudhury} and Scott Counts},
	Booktitle = {Proceedings of the 16th ACM Conference on Computer Supported Cooperative Work},
	Comments = {Monroy-Hern\'{a}ndez et al. (2013) analyze the use of Twitter in four Mexican cities affected by the drug war, Monterrey, Reynosa, Saltillo, and Veracruz. The authors first study the social network as a whole and then analyze the behaviors and impacts of a few users, deemed social media curators, who collect and spread large amounts of information on the network. The authors' dataset constitutes approximately six hundred thousand tweets that match one of the four hashtags #mtyfollow, #reynosafollow, #saltillo, and #verfollow, corresponding to the four cities under study Monterrey, Reynosa, Saltillo, and Veracruz, respectively. Roughly one third of the tweets are retweets. The median number of tweets in a day is on the order of three hundred, while the maximum is an order of magnitude greater. The authors show some correlation across cities in unnormalized volume, and also note a peak in volume in Monterrey and Veracruz on the same day but consider it a coincidence. Most tweets were created by a small number of users. The four hashtags queried were used for spreading alerts and also for community-building. In the second part of their study the authors attempted to contact and interview the ``social media curators'' who exerted most influence in the Twitter network under question. These curators are generally not large media organizations, who were not found to use the query hashtags effectively. Moreover, individual curators are perceived to be more reliable than government officials and news organizations, who have been censored by criminal organizations some of which may have collaborated with those criminal organizations. The combined followers of four curators in Monterrey outnumber the followers of the governor and nearly outnumber the followers of the most popular news organization. The contacted curators responded cautiously if at all, guarding their privacy tightly. Of those who responded, all indicated they felt abandoned by their government, two cited altruism as a motivation, and at least two voiced concerns about other users plagiarizing their work. They are generally wary of other curators due to privacy concerns and competition; it is important to be the first user to report an event. Their sources vary from traditional media reports to offline sources. One curator, dubbed ``Center for Civic Integration,'' is actually a grassroots organization born out of frustration with the traditional media and government. The authors claim that most of the curators' success stems from their reporting of news that other organizations refuse to report. Furthermore, they identify privacy and credibility as crucial components of a social networking infrastructure that can support the emergence of individual curators as seen on Twitter regarding the Mexican drug war.},
	Date-Modified = {2014-02-07 15:45:10 +0000},
	Month = {Feb},
	Read = {1},
	Title = {The New War Correspondents: The Rise of Civic Media Curation in Urban Warfare},
	Year = 2013,
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QIy4uL1BhcGVycy9tb25yb3ktaGVybmFuZGV6LzIwMTMucGRm0hcLGBlXTlMuZGF0YU8RAaQAAAAAAaQAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM7sZVxIKwAAABQyYwgyMDEzLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEXOKzrMjEAAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAQbW9ucm95LWhlcm5hbmRlegAQAAgAAM7sq6wAAAARAAgAAM6zaWAAAAABABQAFDJjABQxxAAFM58ABTOeAADARwACAEhNYWNpbnRvc2ggSEQ6VXNlcnM6AGNqbWF5OgBEb2N1bWVudHM6AFBhcGVyczoAbW9ucm95LWhlcm5hbmRlejoAMjAxMy5wZGYADgASAAgAMgAwADEAMwAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIANlVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvbW9ucm95LWhlcm5hbmRlei8yMDEzLnBkZgATAAEvAAAVAAIADP//AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOALQAuQDBAmkCawJwAnsChAKSApYCnQKmAqsCuAK7As0C0ALVAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAtc=}}

@article{berman1994,
	Author = {Oded Berman},
	Comments = {Berman (1994) introduces the p partial center problem, a variant of MCLP in which the objective is to minimize the sum of distances from each facility location to the farthest demand point covered by that facility. Pareto optimum locations are introduced and studied in both problems.},
	Date-Modified = {2014-02-07 15:43:15 +0000},
	Journal = {European Journal of Operational Research},
	Pages = {432--442},
	Read = {1},
	Title = {The p maximal cover -- p partial center problem on networks},
	Volume = 72,
	Year = 1994,
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGS4uL1BhcGVycy9iZXJtYW4vMTk5NC5wZGbSFwsYGVdOUy5kYXRhTxEBhgAAAAABhgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAAFDIfCDE5OTQucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAARc5DOqrtCAAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAAZiZXJtYW4AEAAIAADO7KusAAAAEQAIAADOqwGSAAAAAQAUABQyHwAUMcQABTOfAAUzngAAwEcAAgA+TWFjaW50b3NoIEhEOlVzZXJzOgBjam1heToARG9jdW1lbnRzOgBQYXBlcnM6AGJlcm1hbjoAMTk5NC5wZGYADgASAAgAMQA5ADkANAAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIALFVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvYmVybWFuLzE5OTQucGRmABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AqgCvALcCQQJDAkgCUwJcAmoCbgJ1An4CgwKQApMCpQKoAq0AAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACrw==}}

@unpublished{andoni2014,
	Author = {Alexandr Andoni and Piotr Indyk and Huy L. Nguyen and Ilya Razenshteyn},
	Comments = {Andoni et al. (2014) describe and analyze a new datastructure and algorithm for the c-approximate near neighbor problem based on locality sensitive hashing (LSH). The authors show that their approach undercuts the query-time and storage lower bounds previously determined for LSH. Specifically, Andoni et al. (2014) describe a partially data-aware structure: The data are first binned into bounded-diameter buckets using standard LSH and the elements in each bucket are then hashed by an independent sample from a family of Gaussian LSH functions. The improvement obtained over the LSH lower bound is small and only takes effect when c is large: the exponent in the query-time and storage complexity is 7/(8c^2) + O(1/c^3) + o(1) for the proposed approach versus 1/c^2 + o(1) for standard LSH. However, this proof of concept may set the stage for a new class of solutions to the approximate nearest neighbor problem.},
	Date-Modified = {2014-02-07 15:42:37 +0000},
	Keywords = {locality sensitive hashing},
	Note = {To appear at ACM-SIAM Symposium on Discrete Algorithms (SODA) 2014},
	Read = {1},
	Title = {Beyond Locality-Sensitive Hashing},
	Year = {2014},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGS4uL1BhcGVycy9hbmRvbmkvMjAxNC5wZGbSFwsYGVdOUy5kYXRhTxEBhgAAAAABhgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAAFDIDCDIwMTQucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAARc7rOoPlpAAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAAZhbmRvbmkAEAAIAADO7KusAAAAEQAIAADOoT+5AAAAAQAUABQyAwAUMcQABTOfAAUzngAAwEcAAgA+TWFjaW50b3NoIEhEOlVzZXJzOgBjam1heToARG9jdW1lbnRzOgBQYXBlcnM6AGFuZG9uaToAMjAxNC5wZGYADgASAAgAMgAwADEANAAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIALFVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvYW5kb25pLzIwMTQucGRmABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AqgCvALcCQQJDAkgCUwJcAmoCbgJ1An4CgwKQApMCpQKoAq0AAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACrw==}}

@article{bentley1980,
	Acmid = {355927},
	Address = {New York, NY, USA},
	Author = {Jon Louis Bentley and Bruce W. Weide and Andrew C. Yao},
	Comments = {Bentley et al. (1980) build on the work of Shamos and Hoey (1957) and give optimal expected-time algorithms for Euclidean minimum spanning tree and Euclidean k-nearest neighbors in an arbitrary number of dimensions. The crux of their approach seems to be the division of the space into a grid of cells. They start by proving results under the assumption that the points are uniformly distributed, and generalize to other distributions that satisfy a condition similar to (and stronger than) local Lipschitz continuity. Their approach requires that the space is bounded. Additionally, while their query time is constant with respect to the number of points for a fixed density of points in the space and fixed dimensionality of the space, it appears to be exponential in the latter two quantities (if they are allowed to vary).},
	Date-Modified = {2014-02-07 15:43:02 +0000},
	Doi = {10.1145/355921.355927},
	Issn = {0098-3500},
	Issue_Date = {Dec. 1980},
	Journal = {ACM Trans. Math. Softw.},
	Month = dec,
	Number = {4},
	Numpages = {18},
	Pages = {563--580},
	Publisher = {ACM},
	Read = {1},
	Title = {Optimal Expected-Time Algorithms for Closest Point Problems},
	Url = {http://doi.acm.org/10.1145/355921.355927},
	Volume = {6},
	Year = {1980},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGi4uL1BhcGVycy9iZW50bGV5LzE5ODAucGRm0hcLGBlXTlMuZGF0YU8RAYwAAAAAAYwAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM7sZVxIKwAAABQyGAgxOTgwLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEXPzzqBOKQAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAHYmVudGxleQAAEAAIAADO7KusAAAAEQAIAADOoJR5AAAAAQAUABQyGAAUMcQABTOfAAUzngAAwEcAAgA/TWFjaW50b3NoIEhEOlVzZXJzOgBjam1heToARG9jdW1lbnRzOgBQYXBlcnM6AGJlbnRsZXk6ADE5ODAucGRmAAAOABIACAAxADkAOAAwAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgAtVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9iZW50bGV5LzE5ODAucGRmAAATAAEvAAAVAAIADP//AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAKsAsAC4AkgCSgJPAloCYwJxAnUCfAKFAooClwKaAqwCrwK0AAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAArY=},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/355921.355927},
	Bdsk-Url-2 = {http://dx.doi.org/10.1145/355921.355927}}

@article{chung1986,
	Author = {Chen-Hua Chung},
	Comments = {Chung (1986) surveys applications of MCLP, including ``taxpayer reduction,'' cluster analysis, discriminative analysis, and other problems. His analysis of MCLP largely depends on the reduction to p-medians.},
	Copyright = {Copyright {\copyright} 1986 Operational Research Society},
	Date-Modified = {2014-02-07 15:43:34 +0000},
	Issn = {01605682},
	Journal = {The Journal of the Operational Research Society},
	Language = {English},
	Number = {8},
	Pages = {pp. 735-746},
	Publisher = {Palgrave Macmillan Journals on behalf of the Operational Research Society},
	Read = {1},
	Title = {Recent Applications of the Maximal Covering Location Planning (M.C.L.P.) Model},
	Url = {http://www.jstor.org/stable/2581958},
	Volume = {37},
	Year = {1986},
	Bdsk-Url-1 = {http://www.jstor.org/stable/2581958}}

@article{klastorin1979,
	Author = {T. D. Klastorin},
	Comments = {Klastorin (1979) shows that MCLP reduces to the generalized assignment problem (GAP).},
	Copyright = {Copyright {\copyright} 1979 INFORMS},
	Date-Modified = {2014-02-07 15:44:42 +0000},
	Issn = {00251909},
	Journal = {Management Science},
	Keywords = {facility location},
	Language = {English},
	Number = {1},
	Pages = {pp. 107-112},
	Publisher = {INFORMS},
	Read = {1},
	Title = {On the Maximal Covering Location Problem and the Generalized Assignment Problem},
	Url = {http://www.jstor.org/stable/2630534},
	Volume = {25},
	Year = {1979},
	Bdsk-Url-1 = {http://www.jstor.org/stable/2630534}}

@article{galvao1996,
	Author = {Roberto Di{\'e}guez Galv{\~a}o and Charles ReVelle},
	Comments = {Galvao and ReVelle (1996) use Langrangian Relaxation to solve MCLP for larger networks than previously studied. In particular, their method utilizes a lower bound based on subgradient optimization and a greedy upper bound.},
	Date-Modified = {2014-02-07 15:44:23 +0000},
	Doi = {http://dx.doi.org/10.1016/0377-2217(94)00159-6},
	Issn = {0377-2217},
	Journal = {European Journal of Operational Research},
	Keywords = {facility location},
	Number = {1},
	Pages = {114 - 123},
	Read = {1},
	Title = {A Lagrangean heuristic for the maximal covering location problem},
	Url = {http://www.sciencedirect.com/science/article/pii/0377221794001596},
	Volume = {88},
	Year = {1996},
	Bdsk-Url-1 = {http://www.sciencedirect.com/science/article/pii/0377221794001596},
	Bdsk-Url-2 = {http://dx.doi.org/10.1016/0377-2217(94)00159-6}}

@article{current1990,
	Author = {John Current and David Schilling},
	Comments = {Current and Schilling (1990) analyze sources of error due to discretization in MCLP and other problems. These errors arise from the introduction of a discrete metric, the discretization (aggregation) of demand points, and other sources.},
	Date-Modified = {2014-02-07 15:43:49 +0000},
	Issue = {2},
	Journal = {Geographical Analysis},
	Keywords = {facility location},
	Read = {1},
	Title = {Analysis of Errors Due to Demand Data Aggregation in the Set Covering and Maximal Covering Location Problems},
	Volume = {22},
	Year = {1990}}

@unpublished{white1973,
	Author = {J. White and K. Case},
	Keywords = {facility location},
	Note = {Virginia Polytechnic Institute and State University, Blacksburg, Va.},
	Title = {On Covering Problems and the Central Facilities Location Problem},
	Year = {1973}}

@article{megiddo1983,
	Author = {Megiddo, N. and Zemel, E. and Hakimi, S.},
	Comments = {Megiddo et al. (1983) study the maximum coverage location problem on tree-networks and show an exact O(n^2 p) algorithm for that setting. They adapt this result to provide an exact O(n^2 p) algorithm for the p-median problem on tree-networks.},
	Date-Modified = {2014-02-07 15:45:01 +0000},
	Doi = {10.1137/0604028},
	Eprint = {http://epubs.siam.org/doi/pdf/10.1137/0604028},
	Journal = {SIAM Journal on Algebraic Discrete Methods},
	Keywords = {facility location},
	Number = {2},
	Pages = {253-261},
	Read = {1},
	Title = {The Maximum Coverage Location Problem},
	Url = {http://epubs.siam.org/doi/abs/10.1137/0604028},
	Volume = {4},
	Year = {1983},
	Bdsk-Url-1 = {http://epubs.siam.org/doi/abs/10.1137/0604028},
	Bdsk-Url-2 = {http://dx.doi.org/10.1137/0604028}}

@inproceedings{asuncion2009,
	Author = {Arthur Asuncion and Max Welling and Padhraic Smyth and Yee Whye Teh},
	Booktitle = {Proceedings of the 25th Conference on Uncertainty in Artificial Intelligence (UAI)},
	Title = {On Smoothing and Inference for Topic Models},
	Year = {2009},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGy4uL1BhcGVycy9hc3VuY2lvbi8yMDA5LnBkZtIXCxgZV05TLmRhdGFPEQGMAAAAAAGMAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADO7GVcSCsAAAAUMgYIMjAwOS5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABFzqM6fxNQAAAAAAAAAAAABAAMAAAkgAAAAAAAAAAAAAAAAAAAACGFzdW5jaW9uABAACAAAzuyrrAAAABEACAAAzqALJAAAAAEAFAAUMgYAFDHEAAUznwAFM54AAMBHAAIAQE1hY2ludG9zaCBIRDpVc2VyczoAY2ptYXk6AERvY3VtZW50czoAUGFwZXJzOgBhc3VuY2lvbjoAMjAwOS5wZGYADgASAAgAMgAwADAAOQAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIALlVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvYXN1bmNpb24vMjAwOS5wZGYAEwABLwAAFQACAAz//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgCsALEAuQJJAksCUAJbAmQCcgJ2An0ChgKLApgCmwKtArACtQAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAK3}}

@article{church1976,
	Author = {Richard L. Church and Charles S. ReVelle},
	Comments = {Church and ReVelle (1976) show informally that the maximum covering location problem (MCLP) reduces to the p-median problem by describing a transformation of the original metric to a discrete pseudometric. The authors also discuss the Location Set-covering Problem (Toregas (1971)) in relation to these two problems. In order to solve the p-median formulation of the MCLP, the authors use the original metric in the partitioning step of their approximation algorithm and use the descrete pseudometric in the facility location step. They find that using the discrete pseudometric in both steps yields undesirable solutions.},
	Date-Modified = {2014-02-07 15:43:37 +0000},
	Journal = {Geographical Analysis},
	Keywords = {facility location},
	Number = {4},
	Read = {1},
	Title = {Theoretical and Computational Links between the p-Median, Location Set-covering, and the Maximal Covering Location Problem},
	Volume = {8},
	Year = {1976},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGS4uL1BhcGVycy9jaHVyY2gvMTk3Ni5wZGbSFwsYGVdOUy5kYXRhTxEBhgAAAAABhgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAAFDI0CDE5NzYucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAARc8XOn8TUAAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAAZjaHVyY2gAEAAIAADO7KusAAAAEQAIAADOoAskAAAAAQAUABQyNAAUMcQABTOfAAUzngAAwEcAAgA+TWFjaW50b3NoIEhEOlVzZXJzOgBjam1heToARG9jdW1lbnRzOgBQYXBlcnM6AGNodXJjaDoAMTk3Ni5wZGYADgASAAgAMQA5ADcANgAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIALFVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvY2h1cmNoLzE5NzYucGRmABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AqgCvALcCQQJDAkgCUwJcAmoCbgJ1An4CgwKQApMCpQKoAq0AAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACrw==}}

@article{church1974,
	Author = {Richard L. Church and Charles ReVelle},
	Comments = {Church and ReVelle (1974) introduce the Maximal Covering Location Problem (MCLP), the problem of locating a fixed number of facilities to maximize the population covered within a given distance S of the facilities. They also describe a variant of the problem, MCLP with mandatory closeness constraints, in which every point must be within a given distance T > S of a facility. Church and ReVelle state an integer programming formulation of MCLP and describe two greedy approximation algorithms and a linear programming relaxation of the integer program. In their first greedy algorithm, a new facility is chosen at each iteration in order to maximize the number of new points covered in that iteration. The second greedy algorithm is like the first, but previous facility location decisions can be changed if the change in covered population is positive. The authors note that Case and White solved a special case of their problem in which the population is uniform across demand nodes. Church and ReVelle implement the greedy algorithms with a Fortran IV program on an IBM 7094 computer and implement the linear program with a Fortran IV program using the Mathematical Programming System on an IBM 360 Model 91 computer. They ran experiments over two networks, one with 30 nodes and one with 55 nodes. In these experiments, they varied the number of facilities from 1 to 9 and noted that the linear program obtained an optimal integer programming solution in 80\% of the experiments. In cases where a fractional solution was obtained, the authors used inspection or branch-and-bound to obtain an approximate integral solution. The greedy algorithms also yielded near-optimal solutions, and the authors attribute this to nice properties of their networks (data). The MCLP formulation with mandatory closeness constraints is also studied empirically on the example networks, and similar results are achieved. The authors provide a very detailed analysis of the particular solutions identified by the linear program. A common theme in this paper is the study of population covered with respect to the number of facilities. In this sense the MCLP is itself an approximation, or subproblem, of a more difficult problem, and many MCLP instances and their solutions are used to inform a larger decision. Church and ReVelle illustrate the relationship with a ``cost-effectiveness curve'' in their experiments.},
	Date-Modified = {2014-02-07 15:43:36 +0000},
	Journal = {Papers of the Regional Science Association},
	Keywords = {facility location},
	Read = {1},
	Title = {The Maximal Covering Location Problem},
	Volume = {32},
	Year = {1974},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGS4uL1BhcGVycy9jaHVyY2gvMTk3NC5wZGbSFwsYGVdOUy5kYXRhTxEBhgAAAAABhgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAAFDI0CDE5NzQucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAARc8bOn8TUAAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAAZjaHVyY2gAEAAIAADO7KusAAAAEQAIAADOoAskAAAAAQAUABQyNAAUMcQABTOfAAUzngAAwEcAAgA+TWFjaW50b3NoIEhEOlVzZXJzOgBjam1heToARG9jdW1lbnRzOgBQYXBlcnM6AGNodXJjaDoAMTk3NC5wZGYADgASAAgAMQA5ADcANAAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIALFVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvY2h1cmNoLzE5NzQucGRmABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AqgCvALcCQQJDAkgCUwJcAmoCbgJ1An4CgwKQApMCpQKoAq0AAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACrw==}}

@article{revelle2008,
	Author = {Charles ReVelle and Michelle Scholssberg and Justin Williams},
	Comments = {ReVelle et al. (2008) use a method called Heuristic Concentration to approximately solve MCLP. This method has an approximation factor of about 0.5 and exhibits an order-of-magnitude speedup over previous work. The authors give a decent review of MCLP literature before diving into their algorithm. Sadly, ReVelle apparently died during the writing of this paper.},
	Date-Modified = {2014-02-07 15:45:22 +0000},
	Journal = {Computers and Operations Research},
	Keywords = {facility location},
	Pages = {427-435},
	Read = {1},
	Title = {Solving the Maximal Covering Location Problem with Heuristic Concentration},
	Volume = {35},
	Year = {2008},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGi4uL1BhcGVycy9yZXZlbGxlLzIwMDgucGRm0hcLGBlXTlMuZGF0YU8RAYwAAAAAAYwAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM7sZVxIKwAAABQykAgyMDA4LnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEXOVzp/E0wAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAHcmV2ZWxsZQAAEAAIAADO7KusAAAAEQAIAADOoAsjAAAAAQAUABQykAAUMcQABTOfAAUzngAAwEcAAgA/TWFjaW50b3NoIEhEOlVzZXJzOgBjam1heToARG9jdW1lbnRzOgBQYXBlcnM6AHJldmVsbGU6ADIwMDgucGRmAAAOABIACAAyADAAMAA4AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgAtVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9yZXZlbGxlLzIwMDgucGRmAAATAAEvAAAVAAIADP//AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAKsAsAC4AkgCSgJPAloCYwJxAnUCfAKFAooClwKaAqwCrwK0AAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAArY=}}

@article{church1979,
	Author = {Richard L. Church and Michael E. Meadows},
	Comments = {Church and Meadows (1979) study a more general version of MCLP in which demand points are vertices of a network and facilities can be placed on the vertices or along the arcs of the network. They construct the network intersect point set (NIPS) as the set of points that have a distance exactly equal to the coverage radius away from any vertex. They show that at least one optimal solution consists of facility locations that all come from the network intersect point set.},
	Date-Modified = {2014-02-07 15:43:38 +0000},
	Journal = {Geographical Analysis},
	Keywords = {facility location},
	Number = {4},
	Read = {1},
	Title = {Location Modeling Utilizing Maximum Service Distance Criteria},
	Volume = {11},
	Year = {1979},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGS4uL1BhcGVycy9jaHVyY2gvMTk3OS5wZGbSFwsYGVdOUy5kYXRhTxEBhgAAAAABhgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAAFDI0CDE5NzkucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAARc8fOn8TUAAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAAZjaHVyY2gAEAAIAADO7KusAAAAEQAIAADOoAskAAAAAQAUABQyNAAUMcQABTOfAAUzngAAwEcAAgA+TWFjaW50b3NoIEhEOlVzZXJzOgBjam1heToARG9jdW1lbnRzOgBQYXBlcnM6AGNodXJjaDoAMTk3OS5wZGYADgASAAgAMQA5ADcAOQAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIALFVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvY2h1cmNoLzE5NzkucGRmABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AqgCvALcCQQJDAkgCUwJcAmoCbgJ1An4CgwKQApMCpQKoAq0AAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACrw==}}

@book{farahani2009,
	Author = {Reza Zanjirani Farahani and Masoud Hekmatfar},
	Editor = {Reza Zanjirani Farahani and Masoud Hekmatfar},
	Keywords = {facility location},
	Publisher = {Springer-Verlag},
	Title = {Facility Location: Concepts, Models, Algorithms and Case Studies},
	Year = {2009},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGy4uL1BhcGVycy9mYXJhaGFuaS8yMDA5LnBkZtIXCxgZV05TLmRhdGFPEQGMAAAAAAGMAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADO7GVcSCsAAAAUMkMIMjAwOS5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABFz4s6fxNQAAAAAAAAAAAABAAMAAAkgAAAAAAAAAAAAAAAAAAAACGZhcmFoYW5pABAACAAAzuyrrAAAABEACAAAzqALJAAAAAEAFAAUMkMAFDHEAAUznwAFM54AAMBHAAIAQE1hY2ludG9zaCBIRDpVc2VyczoAY2ptYXk6AERvY3VtZW50czoAUGFwZXJzOgBmYXJhaGFuaToAMjAwOS5wZGYADgASAAgAMgAwADAAOQAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIALlVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvZmFyYWhhbmkvMjAwOS5wZGYAEwABLwAAFQACAAz//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgCsALEAuQJJAksCUAJbAmQCcgJ2An0ChgKLApgCmwKtArACtQAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAK3}}

@article{guha2003,
	Author = {Sudipto Guha and Adam Meyerson and Nina Mishra and Rajeev Motwani and Liadan O'Callaghan},
	Journal = {IEEE Transactions on Knowledge and Data Engineering},
	Keywords = {clustering, data streams, approximation algorithms},
	Title = {Clustering Data Streams: Theory and Practice},
	Year = {2003},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QFy4uL1BhcGVycy9ndWhhLzIwMDMucGRm0hcLGBlXTlMuZGF0YU8RAYAAAAAAAYAAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM7sZVxIKwAAABQySQgyMDAzLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEXPLzp/E1AAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAEZ3VoYQAQAAgAAM7sq6wAAAARAAgAAM6gCyQAAAABABQAFDJJABQxxAAFM58ABTOeAADARwACADxNYWNpbnRvc2ggSEQ6VXNlcnM6AGNqbWF5OgBEb2N1bWVudHM6AFBhcGVyczoAZ3VoYToAMjAwMy5wZGYADgASAAgAMgAwADAAMwAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAKlVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvZ3VoYS8yMDAzLnBkZgATAAEvAAAVAAIADP//AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAKgArQC1AjkCOwJAAksCVAJiAmYCbQJ2AnsCiAKLAp0CoAKlAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAqc=}}

@inproceedings{shamos1975,
	Author = {M. I. Shamos and D. Hoey},
	Booktitle = {16th Annual Symposium on Foundations of Computer Science},
	Comments = {Shamos and Hoey (1975) describe several computational geometric problems concerning a set of points in the plane, namely Euclidean minimum spanning tree, smallest enclosing circle, k nearest neighbors, k farthest neighbors, two closest points, and proper straight-line triangulation. They show that a Voronoi diagram can be constructed for n points in the plane in O(n log n) time, describe efficient methods for computing over Voronoi diagrams, and use those results as a foundation to solve the problems under study in O(n log n) time, an improvement from the O(n^2) approaches presented in prior research. Shamos and Hoey also show that a Voronoi diagram cannot be constructed in less than O(n log n) time, hence their approach for the diagram construction is optimal. Part of the authors' foundational results concern generalized Voronoi diagrams, i.e., diagrams in which each polygon is defined by a set of points rather than a single point.},
	Date-Modified = {2014-02-07 15:45:29 +0000},
	Keywords = {approximation algorithms},
	Pages = {151-162},
	Read = {1},
	Title = {Closest Point Problems},
	Year = {1975},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGS4uL1BhcGVycy9zaGFtb3MvMTk3NS5wZGbSFwsYGVdOUy5kYXRhTxEBhgAAAAABhgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAAFDKWCDE5NzUucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAARc4LOn8TUAAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAAZzaGFtb3MAEAAIAADO7KusAAAAEQAIAADOoAskAAAAAQAUABQylgAUMcQABTOfAAUzngAAwEcAAgA+TWFjaW50b3NoIEhEOlVzZXJzOgBjam1heToARG9jdW1lbnRzOgBQYXBlcnM6AHNoYW1vczoAMTk3NS5wZGYADgASAAgAMQA5ADcANQAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIALFVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvc2hhbW9zLzE5NzUucGRmABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AqgCvALcCQQJDAkgCUwJcAmoCbgJ1An4CgwKQApMCpQKoAq0AAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACrw==}}

@article{sylvester1857,
	Author = {J. J. Sylvester},
	Journal = {Quarterly Journal of Pure and Applied Mathematics},
	Keywords = {approximation algorithms},
	Number = {79},
	Title = {A Question in the Geometry of Situation},
	Volume = {1},
	Year = {1857}}

@inbook{eiselt1995,
	Author = {H. A. Eiselt and Gilbert Laporte},
	Chapter = {8},
	Comments = {Overview of objectives (push, pull, balance) in location problems. Among ``pull'' objectives is the objective in the $p$-max cover problem, i.e., the objective that we cover as many points as possible with at most $p$ facilities. The treatment of this problem starts with the history, which dates back to a paper by J. J. Sylvester (1857) on the 1-max cover problem. More recent work includes Church and Meadows' (1979) generalization of the maximal covering location problem (Church and ReVelle, 1974) to a continuous domain and introduction of network intersection point sets (NIPS) for study of this generalization. By Megiddo et al. (1983), max cover on general graphs is NP-hard, but there is an O(n^2 p) algorithm for tree networks. Hakimi et al. (1992) introduce Voroni p-centers on networks; these problems are solvable only for small p. Berman (1994) notes that even if NIPS facility locations are allowed, lower-cost non-NIPS solutions may exist; he introduces the p-partial center problem in response and finds an O(n^2 log n) algorithm.},
	Date-Modified = {2014-02-07 15:44:15 +0000},
	Editor = {Zvi Drezner},
	Keywords = {facility location},
	Publisher = {Springer-Verlag},
	Read = {1},
	Title = {Objectives in Location Problems},
	Year = {1995}}

@book{daskin1995,
	Author = {Mark S. Daskin},
	Keywords = {facility location},
	Publisher = {John Wiley \& Sons},
	Title = {Network and Discrete Location: Models, Algorithms, and Applications},
	Year = {1995}}

@book{drezner1995,
	Author = {Zvi Drezner},
	Keywords = {facility location},
	Publisher = {Springer-Verlag},
	Title = {Facility Location: A Survey of Applications and Methods},
	Year = {1995}}

@inproceedings{jiang2013,
	Author = {Ke Jiang and Brian Kulis and Michael I. Jordan},
	Booktitle = {Advances in Neural Information Processing Systems 26 (NIPS)},
	Month = {Dec},
	Title = {Small-Variance Asymptotics for Exponential Family {D}irichlet Process Mixture Models},
	Year = {2013},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGC4uL1BhcGVycy9qaWFuZy8yMDEzLnBkZtIXCxgZV05TLmRhdGFPEQGGAAAAAAGGAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADO7GVcSCsAAAAUMlQIMjAxMy5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABFzgM6fxNQAAAAAAAAAAAABAAMAAAkgAAAAAAAAAAAAAAAAAAAABWppYW5nAAAQAAgAAM7sq6wAAAARAAgAAM6gCyQAAAABABQAFDJUABQxxAAFM58ABTOeAADARwACAD1NYWNpbnRvc2ggSEQ6VXNlcnM6AGNqbWF5OgBEb2N1bWVudHM6AFBhcGVyczoAamlhbmc6ADIwMTMucGRmAAAOABIACAAyADAAMQAzAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgArVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9qaWFuZy8yMDEzLnBkZgAAEwABLwAAFQACAAz//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgCpAK4AtgJAAkICRwJSAlsCaQJtAnQCfQKCAo8CkgKkAqcCrAAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAKu}}

@inproceedings{hsu2009,
	Author = {Daniel Hsu and Sham M. Kakade and John Langford and Tong Zhang},
	Booktitle = {Advances in Neural Information Processing Systems 22 (NIPS)},
	Title = {Multi-Label Prediction via Compressed Sensing},
	Year = {2009},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QFi4uL1BhcGVycy9oc3UvMjAwOS5wZGbSFwsYGVdOUy5kYXRhTxEBgAAAAAABgAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAAFDJNCDIwMDkucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAARc7/On8TVAAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAANoc3UAABAACAAAzuyrrAAAABEACAAAzqALJQAAAAEAFAAUMk0AFDHEAAUznwAFM54AAMBHAAIAO01hY2ludG9zaCBIRDpVc2VyczoAY2ptYXk6AERvY3VtZW50czoAUGFwZXJzOgBoc3U6ADIwMDkucGRmAAAOABIACAAyADAAMAA5AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgApVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9oc3UvMjAwOS5wZGYAABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4ApwCsALQCOAI6Aj8CSgJTAmECZQJsAnUCegKHAooCnAKfAqQAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACpg==}}

@inproceedings{eisenstein2013,
	Author = {Jacob Eisenstein},
	Booktitle = {Proceedings of the Conference on Empirical Methods on Natural Language Processing (EMNLP)},
	Title = {A Log-Linear Model for Unsupervised Text Normalization},
	Year = {2013},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QHS4uL1BhcGVycy9laXNlbnN0ZWluLzIwMTMucGRm0hcLGBlXTlMuZGF0YU8RAZIAAAAAAZIAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM7sZVxIKwAAABQyQQgyMDEzLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEXOOzp/E1AAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAKZWlzZW5zdGVpbgAQAAgAAM7sq6wAAAARAAgAAM6gCyQAAAABABQAFDJBABQxxAAFM58ABTOeAADARwACAEJNYWNpbnRvc2ggSEQ6VXNlcnM6AGNqbWF5OgBEb2N1bWVudHM6AFBhcGVyczoAZWlzZW5zdGVpbjoAMjAxMy5wZGYADgASAAgAMgAwADEAMwAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAMFVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvZWlzZW5zdGVpbi8yMDEzLnBkZgATAAEvAAAVAAIADP//AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAK4AswC7AlECUwJYAmMCbAJ6An4ChQKOApMCoAKjArUCuAK9AAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAr8=}}

@inproceedings{wallach2009,
	Author = {Hanna M. Wallach and David Mimno and Andrew McCallum},
	Booktitle = {Advances in Neural Information Processing Systems 22 (NIPS)},
	Comments = {Wallach et al. study the effect of the priors alpha and beta over the topic distributions theta and word distributions phi, respectively, in latent Dirichlet allocation. In particular they analyze the case when one or both priors is asymmetric and learned from the data as opposed to symmetric and fixed a priori. In the revised generative story, a draw of topics is performed for each document and the topic assignments for a document come from that draw. Wallach et al. used Gibbs sampling to experimentally evaluate all four combinations of symmetric or asymmetric priors over theta and phi. At first these priors were integrated out, and the authors found that the prior over theta (the prior on topic distributions) dominated held-out likelihood on all three datasets employed. In particular, asymmetric priors on theta generally led to higher held-out log-likelihood. The authors inspected the values of the precisions of the priors sampled during the experiments and found that they encouraged a symmetric or nearly-symmetric prior on the word distributions. They also observed that the asymmetric prior on theta is robust to stop words, that is, stop words become quarantined in a small number of topics and do not greatly effect the performance of the model. For the sake of computational efficiency, the authors also tried optimizing over priors instead of marginalizing over them in the model where the topic distributions have an asymmetric prior and the word distributions have a symmetric prior. They found the results similar to those obtained by marginalization, while the runtime dropped by approximately an order of magnitude. Finally, the authors observed that this model is robust to model misspecification due to an increase in the number of topics chosen a priori (with dataset held constant).},
	Date-Modified = {2014-02-07 15:45:58 +0000},
	Read = {1},
	Title = {Rethinking LDA: Why Priors Matter},
	Year = {2009},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGi4uL1BhcGVycy93YWxsYWNoLzIwMDkucGRm0hcLGBlXTlMuZGF0YU8RAYwAAAAAAYwAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM7sZVxIKwAAABQyqAgyMDA5LnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEXOXzp/E0wAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAHd2FsbGFjaAAAEAAIAADO7KusAAAAEQAIAADOoAsjAAAAAQAUABQyqAAUMcQABTOfAAUzngAAwEcAAgA/TWFjaW50b3NoIEhEOlVzZXJzOgBjam1heToARG9jdW1lbnRzOgBQYXBlcnM6AHdhbGxhY2g6ADIwMDkucGRmAAAOABIACAAyADAAMAA5AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgAtVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy93YWxsYWNoLzIwMDkucGRmAAATAAEvAAAVAAIADP//AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAKsAsAC4AkgCSgJPAloCYwJxAnUCfAKFAooClwKaAqwCrwK0AAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAArY=}}

@inproceedings{yao2009,
	Author = {Limin Yao and David Mimno and Andrew McCallum},
	Booktitle = {Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
	Comments = {Yao et al. (2009) present efficient algorithms for inference in latent Dirichlet allocation. Specifically, they focus on the case where a model has already been learned on a training corpus and we wish to infer topic proportions on a set of unseen documents. As they note, previous papers largely left this task as an exercise to the reader. Yao et al. describe a method for efficiently sampling topic assignments for a document in the Gibbs sampling scheme, exploiting sparsity to obtain significant runtime reduction and even greater memory savings relative to traditional Gibbs sampling. They also introduce a novel approach to topic proportion inference using MaxEnt. They find that MaxEnt compares favorably to the traditional inference methods in terms of runtime, after training, and produces topic proportions similar to those of Gibbs sampling. Auxiliary results suggest that Gibbs sampling does not have to be run to convergence in order to produce useful topic proportions in Gibbs sampling, and that the algorithms produce inferred topic proportions that do not vary significantly, relative to those of full Gibbs inference, with respect to the amount of training data or with respect to the proportion of previously seen vocabulary, beyond a proportion of roughly 0.5.},
	Date-Modified = {2014-02-07 15:46:06 +0000},
	Month = {Jun},
	Pages = {937--946},
	Read = {1},
	Title = {Efficient Methods for Topic Model Inference on Streaming Document Collections},
	Year = {2009},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QFi4uL1BhcGVycy95YW8vMjAwOS5wZGbSFwsYGVdOUy5kYXRhTxEBgAAAAAABgAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAAFDK0CDIwMDkucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAARc/nOn8TUAAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAAN5YW8AABAACAAAzuyrrAAAABEACAAAzqALJAAAAAEAFAAUMrQAFDHEAAUznwAFM54AAMBHAAIAO01hY2ludG9zaCBIRDpVc2VyczoAY2ptYXk6AERvY3VtZW50czoAUGFwZXJzOgB5YW86ADIwMDkucGRmAAAOABIACAAyADAAMAA5AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgApVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy95YW8vMjAwOS5wZGYAABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4ApwCsALQCOAI6Aj8CSgJTAmECZQJsAnUCegKHAooCnAKfAqQAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACpg==}}

@book{mackay2003,
	Author = {David J.C. MacKay},
	Publisher = {Cambridge University Press},
	Title = {Information Theory, Inference, and Learning Algorithms},
	Year = {2003},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGS4uL1BhcGVycy9tYWNrYXkvMjAwMy5wZGbSFwsYGVdOUy5kYXRhTxEBhgAAAAABhgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAAFDJYCDIwMDMucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAARc6TOn8TUAAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAAZtYWNrYXkAEAAIAADO7KusAAAAEQAIAADOoAskAAAAAQAUABQyWAAUMcQABTOfAAUzngAAwEcAAgA+TWFjaW50b3NoIEhEOlVzZXJzOgBjam1heToARG9jdW1lbnRzOgBQYXBlcnM6AG1hY2theToAMjAwMy5wZGYADgASAAgAMgAwADAAMwAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIALFVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvbWFja2F5LzIwMDMucGRmABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AqgCvALcCQQJDAkgCUwJcAmoCbgJ1An4CgwKQApMCpQKoAq0AAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACrw==}}

@book{vazirani2001,
	Author = {Vijay V. Vazirani},
	Publisher = {Springer},
	Title = {Approximation Algorithms},
	Year = {2001},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGy4uL1BhcGVycy92YXppcmFuaS8yMDAxLnBkZtIXCxgZV05TLmRhdGFPEQGMAAAAAAGMAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADO7GVcSCsAAAAUMqIIMjAwMS5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABFz4M6fxNMAAAAAAAAAAAABAAMAAAkgAAAAAAAAAAAAAAAAAAAACHZhemlyYW5pABAACAAAzuyrrAAAABEACAAAzqALIwAAAAEAFAAUMqIAFDHEAAUznwAFM54AAMBHAAIAQE1hY2ludG9zaCBIRDpVc2VyczoAY2ptYXk6AERvY3VtZW50czoAUGFwZXJzOgB2YXppcmFuaToAMjAwMS5wZGYADgASAAgAMgAwADAAMQAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIALlVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvdmF6aXJhbmkvMjAwMS5wZGYAEwABLwAAFQACAAz//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgCsALEAuQJJAksCUAJbAmQCcgJ2An0ChgKLApgCmwKtArACtQAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAK3}}

@book{williamson2010,
	Author = {David P. Williamson and David B. Shmoys},
	Publisher = {Cambridge University Press},
	Title = {The Design of Approximation Algorithms},
	Year = {2010},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QHS4uL1BhcGVycy93aWxsaWFtc29uLzIwMTAucGRm0hcLGBlXTlMuZGF0YU8RAZIAAAAAAZIAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM7sZVxIKwAAABQysAgyMDEwLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEXPBzp/E1QAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAKd2lsbGlhbXNvbgAQAAgAAM7sq6wAAAARAAgAAM6gCyUAAAABABQAFDKwABQxxAAFM58ABTOeAADARwACAEJNYWNpbnRvc2ggSEQ6VXNlcnM6AGNqbWF5OgBEb2N1bWVudHM6AFBhcGVyczoAd2lsbGlhbXNvbjoAMjAxMC5wZGYADgASAAgAMgAwADEAMAAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAMFVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvd2lsbGlhbXNvbi8yMDEwLnBkZgATAAEvAAAVAAIADP//AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAK4AswC7AlECUwJYAmMCbAJ6An4ChQKOApMCoAKjArUCuAK9AAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAr8=}}

@inbook{shakhnarovich2006,
	Author = {Gregory Shakhnarovich and Piotr Indyk and Trevor Darrell},
	Chapter = {1},
	Editor = {Gregory Shakhnarovich and Trevor Darrell and Piotr Indyk},
	Publisher = {MIT Press},
	Title = {Nearest-Neighbor Methods in Learning and Vision},
	Year = {2006},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QIC4uL1BhcGVycy9zaGFraG5hcm92aWNoLzIwMDYucGRm0hcLGBlXTlMuZGF0YU8RAZ4AAAAAAZ4AAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM7sZVxIKwAAABQxxQgyMDA2LnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEXP/zp/E1AAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAANc2hha2huYXJvdmljaAAAEAAIAADO7KusAAAAEQAIAADOoAskAAAAAQAUABQxxQAUMcQABTOfAAUzngAAwEcAAgBFTWFjaW50b3NoIEhEOlVzZXJzOgBjam1heToARG9jdW1lbnRzOgBQYXBlcnM6AHNoYWtobmFyb3ZpY2g6ADIwMDYucGRmAAAOABIACAAyADAAMAA2AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgAzVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9zaGFraG5hcm92aWNoLzIwMDYucGRmAAATAAEvAAAVAAIADP//AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOALEAtgC+AmACYgJnAnICewKJAo0ClAKdAqICrwKyAsQCxwLMAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAs4=}}

@inproceedings{indyk1998,
	Author = {Piotr Indyk and Rajeev Motwani},
	Booktitle = {STOC},
	Title = {Approximate Nearest Neighbors: Towards Removing the Curse of Dimensionality},
	Year = {1998},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGC4uL1BhcGVycy9pbmR5ay8xOTk4LnBkZtIXCxgZV05TLmRhdGFPEQGGAAAAAAGGAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADO7GVcSCsAAAAUMlEIMTk5OC5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABFzr86fxNMAAAAAAAAAAAABAAMAAAkgAAAAAAAAAAAAAAAAAAAABWluZHlrAAAQAAgAAM7sq6wAAAARAAgAAM6gCyMAAAABABQAFDJRABQxxAAFM58ABTOeAADARwACAD1NYWNpbnRvc2ggSEQ6VXNlcnM6AGNqbWF5OgBEb2N1bWVudHM6AFBhcGVyczoAaW5keWs6ADE5OTgucGRmAAAOABIACAAxADkAOQA4AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgArVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9pbmR5ay8xOTk4LnBkZgAAEwABLwAAFQACAAz//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgCpAK4AtgJAAkICRwJSAlsCaQJtAnQCfQKCAo8CkgKkAqcCrAAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAKu}}

@inbook{indyk2004,
	Author = {Piotr Indyk},
	Chapter = {39},
	Editor = {J. E. Goodman and J. O'Rourke},
	Publisher = {CRC Press},
	Title = {Nearest Neighbors in High-Dimensional Spaces},
	Year = {2004},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGC4uL1BhcGVycy9pbmR5ay8yMDA0LnBkZtIXCxgZV05TLmRhdGFPEQGGAAAAAAGGAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADO7GVcSCsAAAAUMlEIMjAwNC5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABFzsM6fxNMAAAAAAAAAAAABAAMAAAkgAAAAAAAAAAAAAAAAAAAABWluZHlrAAAQAAgAAM7sq6wAAAARAAgAAM6gCyMAAAABABQAFDJRABQxxAAFM58ABTOeAADARwACAD1NYWNpbnRvc2ggSEQ6VXNlcnM6AGNqbWF5OgBEb2N1bWVudHM6AFBhcGVyczoAaW5keWs6ADIwMDQucGRmAAAOABIACAAyADAAMAA0AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgArVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9pbmR5ay8yMDA0LnBkZgAAEwABLwAAFQACAAz//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgCpAK4AtgJAAkICRwJSAlsCaQJtAnQCfQKCAo8CkgKkAqcCrAAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAKu}}

@book{hastie2009,
	Author = {Trevor Hastie and Robert Tibshirani and Jerome Friedman},
	Edition = {2},
	Publisher = {Springer-Verlag},
	Title = {Elements of Statistical Learning},
	Year = {2009},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGS4uL1BhcGVycy9oYXN0aWUvMjAwOS5wZGbSFwsYGVdOUy5kYXRhTxEBhgAAAAABhgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAAFDJLCDIwMDkucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAARc/3On8TTAAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAAZoYXN0aWUAEAAIAADO7KusAAAAEQAIAADOoAsjAAAAAQAUABQySwAUMcQABTOfAAUzngAAwEcAAgA+TWFjaW50b3NoIEhEOlVzZXJzOgBjam1heToARG9jdW1lbnRzOgBQYXBlcnM6AGhhc3RpZToAMjAwOS5wZGYADgASAAgAMgAwADAAOQAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIALFVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvaGFzdGllLzIwMDkucGRmABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AqgCvALcCQQJDAkgCUwJcAmoCbgJ1An4CgwKQApMCpQKoAq0AAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACrw==}}

@article{gershman2012,
	Author = {Samuel J. Gershman and David M. Blei},
	Date-Modified = {2014-02-20 13:28:17 +0000},
	Journal = {Journal of Mathematical Psychology},
	Read = {1},
	Title = {A tutorial on {B}ayesian nonparametric models},
	Year = {2012},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGy4uL1BhcGVycy9nZXJzaG1hbi8yMDEyLnBkZtIXCxgZV05TLmRhdGFPEQGMAAAAAAGMAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADO7GVcSCsAAAAUMkUIMjAxMi5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABFzzc6fxNQAAAAAAAAAAAABAAMAAAkgAAAAAAAAAAAAAAAAAAAACGdlcnNobWFuABAACAAAzuyrrAAAABEACAAAzqALJAAAAAEAFAAUMkUAFDHEAAUznwAFM54AAMBHAAIAQE1hY2ludG9zaCBIRDpVc2VyczoAY2ptYXk6AERvY3VtZW50czoAUGFwZXJzOgBnZXJzaG1hbjoAMjAxMi5wZGYADgASAAgAMgAwADEAMgAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIALlVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvZ2Vyc2htYW4vMjAxMi5wZGYAEwABLwAAFQACAAz//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgCsALEAuQJJAksCUAJbAmQCcgJ2An0ChgKLApgCmwKtArACtQAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAK3}}

@inproceedings{newman2007,
	Author = {David Newman and Arthur Asuncion and Padhraic Smyth and Max Welling},
	Booktitle = {Advances in Neural Information Processing Systems 20 (NIPS)},
	Date-Modified = {2014-02-20 13:27:30 +0000},
	Read = {1},
	Title = {Distributed Inference for Latent {D}irichlet Allocation},
	Year = {2007},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGS4uL1BhcGVycy9uZXdtYW4vMjAwNy5wZGbSFwsYGVdOUy5kYXRhTxEBhgAAAAABhgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAAFDJlCDIwMDcucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAARc5LOn8TUAAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAAZuZXdtYW4AEAAIAADO7KusAAAAEQAIAADOoAskAAAAAQAUABQyZQAUMcQABTOfAAUzngAAwEcAAgA+TWFjaW50b3NoIEhEOlVzZXJzOgBjam1heToARG9jdW1lbnRzOgBQYXBlcnM6AG5ld21hbjoAMjAwNy5wZGYADgASAAgAMgAwADAANwAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIALFVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvbmV3bWFuLzIwMDcucGRmABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AqgCvALcCQQJDAkgCUwJcAmoCbgJ1An4CgwKQApMCpQKoAq0AAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACrw==}}

@article{newman2009,
	Author = {David Newman and Arthur Asuncion and Padhraic Smyth and Max Welling},
	Date-Modified = {2014-02-20 13:27:31 +0000},
	Journal = {Journal of Machine Learning Research},
	Read = {1},
	Title = {Distributed Algorithms for Topic Models},
	Volume = {10},
	Year = {2009},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGS4uL1BhcGVycy9uZXdtYW4vMjAwOS5wZGbSFwsYGVdOUy5kYXRhTxEBhgAAAAABhgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAAFDJlCDIwMDkucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAARc5POn8TUAAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAAZuZXdtYW4AEAAIAADO7KusAAAAEQAIAADOoAskAAAAAQAUABQyZQAUMcQABTOfAAUzngAAwEcAAgA+TWFjaW50b3NoIEhEOlVzZXJzOgBjam1heToARG9jdW1lbnRzOgBQYXBlcnM6AG5ld21hbjoAMjAwOS5wZGYADgASAAgAMgAwADAAOQAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIALFVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvbmV3bWFuLzIwMDkucGRmABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AqgCvALcCQQJDAkgCUwJcAmoCbgJ1An4CgwKQApMCpQKoAq0AAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACrw==}}

@inproceedings{ritter2012,
	Author = {Alan Ritter and Mausam and Oren Etzioni and Sam Clark},
	Booktitle = {Proceedings of the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
	Date-Modified = {2014-02-20 13:27:14 +0000},
	Read = {1},
	Title = {Open Domain Event Extraction from Twitter},
	Year = {2012},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGS4uL1BhcGVycy9yaXR0ZXIvMjAxMi5wZGbSFwsYGVdOUy5kYXRhTxEBhgAAAAABhgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAAFDKSCDIwMTIucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAARc/XOn8TUAAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAAZyaXR0ZXIAEAAIAADO7KusAAAAEQAIAADOoAskAAAAAQAUABQykgAUMcQABTOfAAUzngAAwEcAAgA+TWFjaW50b3NoIEhEOlVzZXJzOgBjam1heToARG9jdW1lbnRzOgBQYXBlcnM6AHJpdHRlcjoAMjAxMi5wZGYADgASAAgAMgAwADEAMgAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIALFVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvcml0dGVyLzIwMTIucGRmABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AqgCvALcCQQJDAkgCUwJcAmoCbgJ1An4CgwKQApMCpQKoAq0AAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACrw==}}

@article{banerjee2005,
	Author = {Arindam Banerjee and Inderjit S. Dhillon and Joydeep Ghosh and Suvrit Sra},
	Date-Modified = {2014-02-07 15:42:48 +0000},
	Journal = {Journal of Machine Learning Research},
	Read = {0},
	Title = {Clustering on the Unit Hypersphere using von Mises-Fisher Distributions},
	Volume = {6},
	Year = {2005},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGy4uL1BhcGVycy9iYW5lcmplZS8yMDA1LnBkZtIXCxgZV05TLmRhdGFPEQGMAAAAAAGMAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADO7GVcSCsAAAAUMgwIMjAwNS5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABFzq86fxNQAAAAAAAAAAAABAAMAAAkgAAAAAAAAAAAAAAAAAAAACGJhbmVyamVlABAACAAAzuyrrAAAABEACAAAzqALJAAAAAEAFAAUMgwAFDHEAAUznwAFM54AAMBHAAIAQE1hY2ludG9zaCBIRDpVc2VyczoAY2ptYXk6AERvY3VtZW50czoAUGFwZXJzOgBiYW5lcmplZToAMjAwNS5wZGYADgASAAgAMgAwADAANQAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIALlVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvYmFuZXJqZWUvMjAwNS5wZGYAEwABLwAAFQACAAz//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgCsALEAuQJJAksCUAJbAmQCcgJ2An0ChgKLApgCmwKtArACtQAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAK3}}

@book{baraniuk2011,
	Address = {Rice University, Houston, Texas},
	Author = {Richard Baraniuk and Mark A. Davenport and Marco F. Duarte and Chinmay Hegde and Jason Laska and Mona Sheikh and Wotao Yin},
	Date-Modified = {2014-02-20 13:29:29 +0000},
	Editor = {Richard Baraniuk and Mark A. Davenport and Marco F. Duarte and Chinmay Hegde},
	Publisher = {Connexions},
	Read = {1},
	Title = {An Introduction to Compressive Sensing},
	Year = {2011},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGy4uL1BhcGVycy9iYXJhbml1ay8yMDExLnBkZtIXCxgZV05TLmRhdGFPEQGMAAAAAAGMAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADO7GVcSCsAAAAUMg8IMjAxMS5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABFz986fxNQAAAAAAAAAAAABAAMAAAkgAAAAAAAAAAAAAAAAAAAACGJhcmFuaXVrABAACAAAzuyrrAAAABEACAAAzqALJAAAAAEAFAAUMg8AFDHEAAUznwAFM54AAMBHAAIAQE1hY2ludG9zaCBIRDpVc2VyczoAY2ptYXk6AERvY3VtZW50czoAUGFwZXJzOgBiYXJhbml1azoAMjAxMS5wZGYADgASAAgAMgAwADEAMQAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIALlVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvYmFyYW5pdWsvMjAxMS5wZGYAEwABLwAAFQACAAz//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgCsALEAuQJJAksCUAJbAmQCcgJ2An0ChgKLApgCmwKtArACtQAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAK3}}

@inproceedings{cormode2012,
	Author = {Graham Cormode and S. Muthukrishnan},
	Booktitle = {IEEE Software},
	Title = {Approximating Data with the Count-Min Data Structure},
	Year = {2012},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGi4uL1BhcGVycy9jb3Jtb2RlLzIwMTIucGRm0hcLGBlXTlMuZGF0YU8RAYwAAAAAAYwAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM7sZVxIKwAAABQyOAgyMDEyLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEXO9zp/E1AAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAHY29ybW9kZQAAEAAIAADO7KusAAAAEQAIAADOoAskAAAAAQAUABQyOAAUMcQABTOfAAUzngAAwEcAAgA/TWFjaW50b3NoIEhEOlVzZXJzOgBjam1heToARG9jdW1lbnRzOgBQYXBlcnM6AGNvcm1vZGU6ADIwMTIucGRmAAAOABIACAAyADAAMQAyAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgAtVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9jb3Jtb2RlLzIwMTIucGRmAAATAAEvAAAVAAIADP//AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAKsAsAC4AkgCSgJPAloCYwJxAnUCfAKFAooClwKaAqwCrwK0AAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAArY=}}

@inproceedings{may2012,
	Author = {Chandler May and Michael Henry and Liam McGrath and Eric Bell and Eric Marshall and Michelle Gregory},
	Booktitle = {Pacific Northwest Regional NLP Workshop (NW-NLP)},
	Date-Modified = {2014-02-07 15:44:56 +0000},
	Read = {1},
	Title = {Semantic Features for Classifying Referring Search Terms},
	Year = {2012},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QFi4uL1BhcGVycy9tYXkvMjAxMi5wZGbSFwsYGVdOUy5kYXRhTxEBgAAAAAABgAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAAFDJcCDIwMTIucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAARc9zOn8TUAAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAANtYXkAABAACAAAzuyrrAAAABEACAAAzqALJAAAAAEAFAAUMlwAFDHEAAUznwAFM54AAMBHAAIAO01hY2ludG9zaCBIRDpVc2VyczoAY2ptYXk6AERvY3VtZW50czoAUGFwZXJzOgBtYXk6ADIwMTIucGRmAAAOABIACAAyADAAMQAyAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgApVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9tYXkvMjAxMi5wZGYAABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4ApwCsALQCOAI6Aj8CSgJTAmECZQJsAnUCegKHAooCnAKfAqQAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACpg==}}

@techreport{may2011,
	Author = {Chandler May},
	Date-Modified = {2014-02-07 15:44:55 +0000},
	Institution = {Harvey Mudd College},
	Read = {1},
	Title = {Verification of Solutions to the Sensor Location Problem},
	Year = {2011},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QFi4uL1BhcGVycy9tYXkvMjAxMS5wZGbSFwsYGVdOUy5kYXRhTxEBgAAAAAABgAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAAFDJcCDIwMTEucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAARc9vOn8TUAAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAANtYXkAABAACAAAzuyrrAAAABEACAAAzqALJAAAAAEAFAAUMlwAFDHEAAUznwAFM54AAMBHAAIAO01hY2ludG9zaCBIRDpVc2VyczoAY2ptYXk6AERvY3VtZW50czoAUGFwZXJzOgBtYXk6ADIwMTEucGRmAAAOABIACAAyADAAMQAxAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgApVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9tYXkvMjAxMS5wZGYAABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4ApwCsALQCOAI6Aj8CSgJTAmECZQJsAnUCegKHAooCnAKfAqQAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACpg==}}

@inproceedings{bergsma2013,
	Author = {Shane Bergsma and Benjamin {Van Durme}},
	Booktitle = {Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL)},
	Title = {Using Conceptual Class Attributes to Characterize Social Media Users},
	Year = {2013},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGi4uL1BhcGVycy9iZXJnc21hLzIwMTMucGRm0hcLGBlXTlMuZGF0YU8RAYwAAAAAAYwAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM7sZVxIKwAAABQyGwgyMDEzLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEXOGzp/E1AAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAHYmVyZ3NtYQAAEAAIAADO7KusAAAAEQAIAADOoAskAAAAAQAUABQyGwAUMcQABTOfAAUzngAAwEcAAgA/TWFjaW50b3NoIEhEOlVzZXJzOgBjam1heToARG9jdW1lbnRzOgBQYXBlcnM6AGJlcmdzbWE6ADIwMTMucGRmAAAOABIACAAyADAAMQAzAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgAtVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9iZXJnc21hLzIwMTMucGRmAAATAAEvAAAVAAIADP//AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAKsAsAC4AkgCSgJPAloCYwJxAnUCfAKFAooClwKaAqwCrwK0AAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAArY=}}

@inproceedings{vandurme2012,
	Author = {Benjamin {Van Durme}},
	Booktitle = {Proceedings of the Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL)},
	Title = {Streaming Analysis of Discourse Participants},
	Year = {2012},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QHC4uL1BhcGVycy92YW4gZHVybWUvMjAxMi5wZGbSFwsYGVdOUy5kYXRhTxEBkgAAAAABkgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAAFDKaCDIwMTIucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAARc+7On8TUAAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAAl2YW4gZHVybWUAABAACAAAzuyrrAAAABEACAAAzqALJAAAAAEAFAAUMpoAFDHEAAUznwAFM54AAMBHAAIAQU1hY2ludG9zaCBIRDpVc2VyczoAY2ptYXk6AERvY3VtZW50czoAUGFwZXJzOgB2YW4gZHVybWU6ADIwMTIucGRmAAAOABIACAAyADAAMQAyAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgAvVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy92YW4gZHVybWUvMjAxMi5wZGYAABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4ArQCyALoCUAJSAlcCYgJrAnkCfQKEAo0CkgKfAqICtAK3ArwAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACvg==}}

@inproceedings{yang2009,
	Author = {Xin-She Yang},
	Booktitle = {SAGA},
	Date-Modified = {2014-02-20 13:26:21 +0000},
	Read = {1},
	Title = {Firefly Algorithms for Multimodal Optimization},
	Year = {2009},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QFy4uL1BhcGVycy95YW5nLzIwMDkucGRm0hcLGBlXTlMuZGF0YU8RAYAAAAAAAYAAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM7sZVxIKwAAABQysQgyMDA5LnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEXPTzp/E0wAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAEeWFuZwAQAAgAAM7sq6wAAAARAAgAAM6gCyMAAAABABQAFDKxABQxxAAFM58ABTOeAADARwACADxNYWNpbnRvc2ggSEQ6VXNlcnM6AGNqbWF5OgBEb2N1bWVudHM6AFBhcGVyczoAeWFuZzoAMjAwOS5wZGYADgASAAgAMgAwADAAOQAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAKlVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMveWFuZy8yMDA5LnBkZgATAAEvAAAVAAIADP//AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAKgArQC1AjkCOwJAAksCVAJiAmYCbQJ2AnsCiAKLAp0CoAKlAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAqc=}}

@inproceedings{wang2009,
	Author = {Yi Wang and Hongjie Bai and Matt Stanton and Wen-Yen Chen and Edward Y. Chang},
	Booktitle = {AAIM},
	Date-Modified = {2014-02-20 13:26:27 +0000},
	Read = {1},
	Title = {PLDA: Parallel Latent {D}irichlet Allocation for Large-scale Applications},
	Year = {2009},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QFy4uL1BhcGVycy93YW5nLzIwMDkucGRm0hcLGBlXTlMuZGF0YU8RAYAAAAAAAYAAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM7sZVxIKwAAABQyrAgyMDA5LnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEXOEzp/E1AAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAEd2FuZwAQAAgAAM7sq6wAAAARAAgAAM6gCyQAAAABABQAFDKsABQxxAAFM58ABTOeAADARwACADxNYWNpbnRvc2ggSEQ6VXNlcnM6AGNqbWF5OgBEb2N1bWVudHM6AFBhcGVyczoAd2FuZzoAMjAwOS5wZGYADgASAAgAMgAwADAAOQAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAKlVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvd2FuZy8yMDA5LnBkZgATAAEvAAAVAAIADP//AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAKgArQC1AjkCOwJAAksCVAJiAmYCbQJ2AnsCiAKLAp0CoAKlAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAqc=}}

@inproceedings{ahmed2011a,
	Author = {Amr Ahmed and Qirong Ho and Choon Hui Teo and Jacob Eisenstein and Alex J. Smola and Eric P. Xing},
	Booktitle = {Proceedings of the 14th International Conference on Artificial Intelligence and Statistics (AISTATS)},
	Comments = {Ahmed et al. (2011) present a model and inference algorithm for learning news storylines from text in an online setting. In particular, they augment a Recurrent Chinese Restaurant Process clustering with a Latent Dirichlet Allocation topic model, modeling named entities separately from other words and providing per-storyline priors on the named entity and word distributions to facilitate specification in each storyline. The model and the core inference algorithm were introduced in the same year by the same group of authors. There are two essential improvements in the current work: topic assignments are sampled more efficiently using the approach of Yao et al. (2009), and the extra computational time afforded by that improvement is used to optimize over the model hyperparameters as in Wallach et al. (2009). Ahmed et al. show that these modifications result in a three-percentage-point improvement in clustering accuracy on the Yahoo! news dataset.},
	Date-Modified = {2014-02-07 15:42:24 +0000},
	Read = {1},
	Title = {Online Inference for the Infinite Topic-Cluster Model: Storylines from Streaming Text},
	Year = {2011},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGS4uL1BhcGVycy9haG1lZC8yMDExYS5wZGbSFwsYGVdOUy5kYXRhTxEBiAAAAAABiAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAAFDH9CTIwMTFhLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAARc5vOn8TUAAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAAVhaG1lZAAAEAAIAADO7KusAAAAEQAIAADOoAskAAAAAQAUABQx/QAUMcQABTOfAAUzngAAwEcAAgA+TWFjaW50b3NoIEhEOlVzZXJzOgBjam1heToARG9jdW1lbnRzOgBQYXBlcnM6AGFobWVkOgAyMDExYS5wZGYADgAUAAkAMgAwADEAMQBhAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgAsVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9haG1lZC8yMDExYS5wZGYAEwABLwAAFQACAAz//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgCqAK8AtwJDAkUCSgJVAl4CbAJwAncCgAKFApIClQKnAqoCrwAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAKx}}

@inproceedings{kulis2012,
	Author = {Brian Kulis and Michael I. Jordan},
	Booktitle = {Proceedings of the 29th International Conference on Machine Learning (ICML)},
	Month = {Jun},
	Title = {Revisiting k-means: New Algorithms via {B}ayesian Nonparametrics},
	Year = {2012},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGC4uL1BhcGVycy9rdWxpcy8yMDEyLnBkZtIXCxgZV05TLmRhdGFPEQGGAAAAAAGGAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADO7GVcSCsAAAAUMlYIMjAxMi5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABFzos6fxNMAAAAAAAAAAAABAAMAAAkgAAAAAAAAAAAAAAAAAAAABWt1bGlzAAAQAAgAAM7sq6wAAAARAAgAAM6gCyMAAAABABQAFDJWABQxxAAFM58ABTOeAADARwACAD1NYWNpbnRvc2ggSEQ6VXNlcnM6AGNqbWF5OgBEb2N1bWVudHM6AFBhcGVyczoAa3VsaXM6ADIwMTIucGRmAAAOABIACAAyADAAMQAyAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgArVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9rdWxpcy8yMDEyLnBkZgAAEwABLwAAFQACAAz//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgCpAK4AtgJAAkICRwJSAlsCaQJtAnQCfQKCAo8CkgKkAqcCrAAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAKu}}

@article{andoni2008,
	Author = {Alexandr Andoni and Piotr Indyk},
	Comments = {Andoni and Indyk provide a brief overview of locality sensitive hashing (LSH) in the context of approximate nearest neighbor problems. In the LSH framework, several hash functions are randomly sampled from a given family and the data is projected onto a lower-dimensional space by these hash functions. Given a metric in the original feature space, we wish to design a family of hash functions is constructed so that the probability of collision is high when two data points are close and low when two data points are far apart. Andoni and Indyk formalize this notion, drawing on prior work, and present LSH families with desirable properties for Hamming distance, L-1 distance, L-2 distance, the distance defined by the Jaccard coefficient, and the distance defined by the arc cosine function. They then present a new LSH family, a non-trivial extension of a previously-studied family to multiple dimensions, exhibiting superior asymptotic performance to previous families.},
	Date-Modified = {2014-02-07 15:42:38 +0000},
	Journal = {Communications of the ACM},
	Month = {Jan},
	Number = {1},
	Read = {1},
	Title = {Near-Optimal Hashing Algorithms for Approximate Nearest Neighbor in High Dimensions},
	Volume = {51},
	Year = {2008},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGS4uL1BhcGVycy9hbmRvbmkvMjAwOC5wZGbSFwsYGVdOUy5kYXRhTxEBhgAAAAABhgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAAFDIDCDIwMDgucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAARc7nOn8TUAAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAAZhbmRvbmkAEAAIAADO7KusAAAAEQAIAADOoAskAAAAAQAUABQyAwAUMcQABTOfAAUzngAAwEcAAgA+TWFjaW50b3NoIEhEOlVzZXJzOgBjam1heToARG9jdW1lbnRzOgBQYXBlcnM6AGFuZG9uaToAMjAwOC5wZGYADgASAAgAMgAwADAAOAAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIALFVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvYW5kb25pLzIwMDgucGRmABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AqgCvALcCQQJDAkgCUwJcAmoCbgJ1An4CgwKQApMCpQKoAq0AAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACrw==}}

@article{cormode2009,
	Author = {Graham Cormode and Marios Hadjieleftheriou},
	Journal = {Communications of the ACM},
	Number = {10},
	Title = {Finding the Frequent Items in Streams of Data},
	Volume = {52},
	Year = {2009},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGi4uL1BhcGVycy9jb3Jtb2RlLzIwMDkucGRm0hcLGBlXTlMuZGF0YU8RAYwAAAAAAYwAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM7sZVxIKwAAABQyOAgyMDA5LnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEXO8zp/E1AAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAHY29ybW9kZQAAEAAIAADO7KusAAAAEQAIAADOoAskAAAAAQAUABQyOAAUMcQABTOfAAUzngAAwEcAAgA/TWFjaW50b3NoIEhEOlVzZXJzOgBjam1heToARG9jdW1lbnRzOgBQYXBlcnM6AGNvcm1vZGU6ADIwMDkucGRmAAAOABIACAAyADAAMAA5AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgAtVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9jb3Jtb2RlLzIwMDkucGRmAAATAAEvAAAVAAIADP//AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAKsAsAC4AkgCSgJPAloCYwJxAnUCfAKFAooClwKaAqwCrwK0AAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAArY=}}

@inproceedings{berinde2009,
	Author = {Radu Berinde and Piotr Indyk and Graham Cormode and Martin J. Strauss},
	Booktitle = {PODS},
	Title = {Space-optimal Heavy Hitters with Strong Error Bounds},
	Year = {2009},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGi4uL1BhcGVycy9iZXJpbmRlLzIwMDkucGRm0hcLGBlXTlMuZGF0YU8RAYwAAAAAAYwAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM7sZVxIKwAAABQyHQgyMDA5LnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEXO3zp/E1AAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAHYmVyaW5kZQAAEAAIAADO7KusAAAAEQAIAADOoAskAAAAAQAUABQyHQAUMcQABTOfAAUzngAAwEcAAgA/TWFjaW50b3NoIEhEOlVzZXJzOgBjam1heToARG9jdW1lbnRzOgBQYXBlcnM6AGJlcmluZGU6ADIwMDkucGRmAAAOABIACAAyADAAMAA5AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgAtVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9iZXJpbmRlLzIwMDkucGRmAAATAAEvAAAVAAIADP//AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAKsAsAC4AkgCSgJPAloCYwJxAnUCfAKFAooClwKaAqwCrwK0AAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAArY=}}

@inproceedings{vandurme2009a,
	Author = {Benjamin {Van Durme} and Ashwin Lall},
	Booktitle = {IJCAI},
	Title = {Probabilistic Counting with Randomized Storage},
	Year = {2009},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QHS4uL1BhcGVycy92YW4gZHVybWUvMjAwOWEucGRm0hcLGBlXTlMuZGF0YU8RAZQAAAAAAZQAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM7sZVxIKwAAABQymgkyMDA5YS5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEXPszp/E1QAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAJdmFuIGR1cm1lAAAQAAgAAM7sq6wAAAARAAgAAM6gCyUAAAABABQAFDKaABQxxAAFM58ABTOeAADARwACAEJNYWNpbnRvc2ggSEQ6VXNlcnM6AGNqbWF5OgBEb2N1bWVudHM6AFBhcGVyczoAdmFuIGR1cm1lOgAyMDA5YS5wZGYADgAUAAkAMgAwADAAOQBhAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgAwVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy92YW4gZHVybWUvMjAwOWEucGRmABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4ArgCzALsCUwJVAloCZQJuAnwCgAKHApAClQKiAqUCtwK6Ar8AAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACwQ==}}

@inproceedings{vandurme2009,
	Author = {Benjamin {Van Durme} and Ashwin Lall},
	Booktitle = {Advances in Neural Information Processing Systems 22 (NIPS)},
	Title = {Streaming Pointwise Mutual Information},
	Year = {2009},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QHC4uL1BhcGVycy92YW4gZHVybWUvMjAwOS5wZGbSFwsYGVdOUy5kYXRhTxEBkgAAAAABkgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAAFDKaCDIwMDkucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAARc+vOn8TVAAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAAl2YW4gZHVybWUAABAACAAAzuyrrAAAABEACAAAzqALJQAAAAEAFAAUMpoAFDHEAAUznwAFM54AAMBHAAIAQU1hY2ludG9zaCBIRDpVc2VyczoAY2ptYXk6AERvY3VtZW50czoAUGFwZXJzOgB2YW4gZHVybWU6ADIwMDkucGRmAAAOABIACAAyADAAMAA5AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgAvVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy92YW4gZHVybWUvMjAwOS5wZGYAABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4ArQCyALoCUAJSAlcCYgJrAnkCfQKEAo0CkgKfAqICtAK3ArwAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACvg==}}

@article{vitter1985,
	Author = {Jeffrey S. Vitter},
	Journal = {ACM Transactions on Mathematical Software},
	Month = {Mar},
	Number = {1},
	Pages = {37--57},
	Title = {Random Sampling with a Reservoir},
	Volume = {11},
	Year = {1985},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGS4uL1BhcGVycy92aXR0ZXIvMTk4NS5wZGbSFwsYGVdOUy5kYXRhTxEBhgAAAAABhgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAAFDKmCDE5ODUucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAARc9fOn8TVAAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAAZ2aXR0ZXIAEAAIAADO7KusAAAAEQAIAADOoAslAAAAAQAUABQypgAUMcQABTOfAAUzngAAwEcAAgA+TWFjaW50b3NoIEhEOlVzZXJzOgBjam1heToARG9jdW1lbnRzOgBQYXBlcnM6AHZpdHRlcjoAMTk4NS5wZGYADgASAAgAMQA5ADgANQAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIALFVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvdml0dGVyLzE5ODUucGRmABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AqgCvALcCQQJDAkgCUwJcAmoCbgJ1An4CgwKQApMCpQKoAq0AAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACrw==}}

@inproceedings{vandurme2011,
	Author = {Benjamin {Van Durme} and Ashwin Lall},
	Booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics (ACL)},
	Date-Modified = {2014-02-20 13:26:57 +0000},
	Read = {1},
	Title = {Efficient Online Locality Sensitive Hashing via Reservoir Counting},
	Year = {2011},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QHC4uL1BhcGVycy92YW4gZHVybWUvMjAxMS5wZGbSFwsYGVdOUy5kYXRhTxEBkgAAAAABkgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAAFDKaCDIwMTEucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAARc+3On8TVAAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAAl2YW4gZHVybWUAABAACAAAzuyrrAAAABEACAAAzqALJQAAAAEAFAAUMpoAFDHEAAUznwAFM54AAMBHAAIAQU1hY2ludG9zaCBIRDpVc2VyczoAY2ptYXk6AERvY3VtZW50czoAUGFwZXJzOgB2YW4gZHVybWU6ADIwMTEucGRmAAAOABIACAAyADAAMQAxAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgAvVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy92YW4gZHVybWUvMjAxMS5wZGYAABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4ArQCyALoCUAJSAlcCYgJrAnkCfQKEAo0CkgKfAqICtAK3ArwAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACvg==}}

@inproceedings{vandurme2010,
	Author = {Benjamin {Van Durme} and Ashwin Lall},
	Booktitle = {Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics (ACL)},
	Title = {Online Generation of Locality Sensitive Hash Signatures},
	Year = {2010},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QHC4uL1BhcGVycy92YW4gZHVybWUvMjAxMC5wZGbSFwsYGVdOUy5kYXRhTxEBkgAAAAABkgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAAFDKaCDIwMTAucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAARc+rOn8TVAAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAAl2YW4gZHVybWUAABAACAAAzuyrrAAAABEACAAAzqALJQAAAAEAFAAUMpoAFDHEAAUznwAFM54AAMBHAAIAQU1hY2ludG9zaCBIRDpVc2VyczoAY2ptYXk6AERvY3VtZW50czoAUGFwZXJzOgB2YW4gZHVybWU6ADIwMTAucGRmAAAOABIACAAyADAAMQAwAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgAvVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy92YW4gZHVybWUvMjAxMC5wZGYAABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4ArQCyALoCUAJSAlcCYgJrAnkCfQKEAo0CkgKfAqICtAK3ArwAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACvg==}}

@inproceedings{ahmed2012,
	Author = {Amr Ahmed and Mohamed Aly and Joseph Gonzalez and Shravan Narayanamurthy and Alexander Smola},
	Booktitle = {WSDM},
	Comments = {Ahmed et al. (2012) lay out a framework for scalably learning parameters of latent variable models, covering issues from the dependency structure of the latent variables to the minimization of network protocol overhead. In particular, they suggest utilizing the disk to iterate over local observations and latent variables in constant space, parallelizing collapsed sampling of global variables by allowing slightly stale state on each compute node, synchronizing global variables between nodes using an efficient client-server model in which updates are tracked on the client to guarantee correctness at the end of synchronization, scheduling synchronizations to avoid network protocol overhead, using sequential monte carlo with a single particle to sample latent variables when the data arrives in an ordered stream, and finally, employing a simple and quick fault tolerance scheme in which checkpointing is accomplished by waiting for all network communication to halt and uploading all client and server state to the cloud. Ahmed et al. (2012) perform their analysis on a general latent variable model whose global parameters belong to an algebraic ring; they also perform experiments on the latent dirichlet allocation topic model and a ``temporal user profiling'' model. They find faster sampler convergence on global variables with their synchronization approach as opposed to a memcached approach from prior work, resulting from fewer iterations as well as less wallclock time per iteration. The proposed synchronization schedule also requires less wallclock time than a random schedule. The inference framework achieves a better ROC score on the temporal user profiling task than an approach from prior work while maintaining nearly linear scaling with the number of compute nodes. Finally, the proposed fault tolerance scheme is much more efficient in wallclock time than a previously studied scheme. In conclusion the authors mention that their approach to scalable inference is ``orthogonal'' to that of the GraphLab team and suggest reconciling the two approaches in future work.},
	Date-Modified = {2014-02-07 15:42:26 +0000},
	Keywords = {inference, graphical models, large-scale systems, latent models},
	Read = {1},
	Title = {Scalable Inference in Latent Variable Models},
	Year = {2012},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGC4uL1BhcGVycy9haG1lZC8yMDEyLnBkZtIXCxgZV05TLmRhdGFPEQGGAAAAAAGGAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADO7GVcSCsAAAAUMf0IMjAxMi5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABFznc6fxNQAAAAAAAAAAAABAAMAAAkgAAAAAAAAAAAAAAAAAAAABWFobWVkAAAQAAgAAM7sq6wAAAARAAgAAM6gCyQAAAABABQAFDH9ABQxxAAFM58ABTOeAADARwACAD1NYWNpbnRvc2ggSEQ6VXNlcnM6AGNqbWF5OgBEb2N1bWVudHM6AFBhcGVyczoAYWhtZWQ6ADIwMTIucGRmAAAOABIACAAyADAAMQAyAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgArVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9haG1lZC8yMDEyLnBkZgAAEwABLwAAFQACAAz//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgCpAK4AtgJAAkICRwJSAlsCaQJtAnQCfQKCAo8CkgKkAqcCrAAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAKu}}

@inproceedings{weinberger2009,
	Author = {Kilian Weinberger and Anirban Dasgupta and Josh Attenberg and John Langford and Alex Smola},
	Booktitle = {Proceedings of the 26th International Conference on Machine Learning (ICML)},
	Comments = {Weinberger et al. (2009) augment a hash kernel proposed by Shi et al. (2009), defining their hash functions as signed rather than unsigned sums in the original feature space. They show that this augmentation makes the kernel unbiased, prove probabilistic bounds on the error in the norm and distance defined by the kernel, and prove a probabilistic bound on the distance between the hashed feature variable of an observation and another parameter vector in the hashed feature space. Weinberger et al. (2009) apply this approach to personalized spam detection on a large dataset, exploiting the limited interaction between parameter vectors and assigning a unique hashed feature mapping per user in addition to a global hashed feature mapping. They compare their model to a model built on a purely global hashed feature mapping into a higher-dimensional space, which they consider a proxy for a baseline unhashed classifier. They find the hashed, personalized model outperforms the baseline classifier in recall even when it is given four bits lower dimensionality, and for all users---not just those who provided labeled training examples.},
	Date-Modified = {2014-02-07 15:46:02 +0000},
	Read = {1},
	Title = {Feature Hashing for Large Scale Multitask Learning},
	Year = {2009},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QHS4uL1BhcGVycy93ZWluYmVyZ2VyLzIwMDkucGRm0hcLGBlXTlMuZGF0YU8RAZIAAAAAAZIAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM7sZVxIKwAAABQyrggyMDA5LnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEXOMzp/E1AAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAKd2VpbmJlcmdlcgAQAAgAAM7sq6wAAAARAAgAAM6gCyQAAAABABQAFDKuABQxxAAFM58ABTOeAADARwACAEJNYWNpbnRvc2ggSEQ6VXNlcnM6AGNqbWF5OgBEb2N1bWVudHM6AFBhcGVyczoAd2VpbmJlcmdlcjoAMjAwOS5wZGYADgASAAgAMgAwADAAOQAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAMFVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvd2VpbmJlcmdlci8yMDA5LnBkZgATAAEvAAAVAAIADP//AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAK4AswC7AlECUwJYAmMCbAJ6An4ChQKOApMCoAKjArUCuAK9AAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAr8=}}

@inproceedings{rao2011,
	Author = {Delip Rao and Michael Paul and Clay Fink and David Yarowsky and Timothy Oates and Glen Coppersmith},
	Booktitle = {Proceedings of the International AAAI Conference on Weblogs and Social Media},
	Date-Modified = {2014-02-20 13:27:22 +0000},
	Read = {1},
	Title = {Hierarchical {B}ayesian Models for Latent Attribute Detection in Social Media},
	Year = {2011},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QFi4uL1BhcGVycy9yYW8vMjAxMS5wZGbSFwsYGVdOUy5kYXRhTxEBgAAAAAABgAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAAFDKNCDIwMTEucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAARc/HOn8TVAAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAANyYW8AABAACAAAzuyrrAAAABEACAAAzqALJQAAAAEAFAAUMo0AFDHEAAUznwAFM54AAMBHAAIAO01hY2ludG9zaCBIRDpVc2VyczoAY2ptYXk6AERvY3VtZW50czoAUGFwZXJzOgByYW86ADIwMTEucGRmAAAOABIACAAyADAAMQAxAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgApVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9yYW8vMjAxMS5wZGYAABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4ApwCsALQCOAI6Aj8CSgJTAmECZQJsAnUCegKHAooCnAKfAqQAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACpg==}}

@inproceedings{rao2010,
	Address = {Toronto, Ontario, Canada},
	Author = {Delip Rao and David Yarowsky and Abhishek Shreevats and Manaswi Gupta},
	Booktitle = {SMUC},
	Date-Modified = {2014-02-20 13:27:21 +0000},
	Month = {Oct},
	Read = {1},
	Title = {Classifying Latent User Attributes in Twitter},
	Year = {2010},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QFi4uL1BhcGVycy9yYW8vMjAxMC5wZGbSFwsYGVdOUy5kYXRhTxEBgAAAAAABgAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAAFDKNCDIwMTAucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAARc/DOn8TUAAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAANyYW8AABAACAAAzuyrrAAAABEACAAAzqALJAAAAAEAFAAUMo0AFDHEAAUznwAFM54AAMBHAAIAO01hY2ludG9zaCBIRDpVc2VyczoAY2ptYXk6AERvY3VtZW50czoAUGFwZXJzOgByYW86ADIwMTAucGRmAAAOABIACAAyADAAMQAwAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgApVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9yYW8vMjAxMC5wZGYAABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4ApwCsALQCOAI6Aj8CSgJTAmECZQJsAnUCegKHAooCnAKfAqQAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACpg==}}

@article{mairal2012,
	Author = {Julien Mairal and Francis Bach and Jean Ponce},
	Date-Modified = {2014-02-20 13:27:46 +0000},
	Journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	Month = {Apr},
	Number = {4},
	Read = {1},
	Title = {Task-Driven Dictionary Learning},
	Volume = {34},
	Year = {2012},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGS4uL1BhcGVycy9tYWlyYWwvMjAxMi5wZGbSFwsYGVdOUy5kYXRhTxEBhgAAAAABhgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAAFDJZCDIwMTIucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAARc/vOn8TUAAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAAZtYWlyYWwAEAAIAADO7KusAAAAEQAIAADOoAskAAAAAQAUABQyWQAUMcQABTOfAAUzngAAwEcAAgA+TWFjaW50b3NoIEhEOlVzZXJzOgBjam1heToARG9jdW1lbnRzOgBQYXBlcnM6AG1haXJhbDoAMjAxMi5wZGYADgASAAgAMgAwADEAMgAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIALFVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvbWFpcmFsLzIwMTIucGRmABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AqgCvALcCQQJDAkgCUwJcAmoCbgJ1An4CgwKQApMCpQKoAq0AAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACrw==}}

@article{domingos2012,
	Author = {Pedro Domingos},
	Date-Modified = {2014-02-20 13:29:00 +0000},
	Journal = {Communications of the ACM},
	Month = {Oct},
	Number = {10},
	Read = {1},
	Title = {A Few Useful Things to Know About Machine Learning},
	Volume = {55},
	Year = {2012},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGy4uL1BhcGVycy9kb21pbmdvcy8yMDEyLnBkZtIXCxgZV05TLmRhdGFPEQGMAAAAAAGMAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADO7GVcSCsAAAAUMj0IMjAxMi5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABFz1c6fxNQAAAAAAAAAAAABAAMAAAkgAAAAAAAAAAAAAAAAAAAACGRvbWluZ29zABAACAAAzuyrrAAAABEACAAAzqALJAAAAAEAFAAUMj0AFDHEAAUznwAFM54AAMBHAAIAQE1hY2ludG9zaCBIRDpVc2VyczoAY2ptYXk6AERvY3VtZW50czoAUGFwZXJzOgBkb21pbmdvczoAMjAxMi5wZGYADgASAAgAMgAwADEAMgAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIALlVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvZG9taW5nb3MvMjAxMi5wZGYAEwABLwAAFQACAAz//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgCsALEAuQJJAksCUAJbAmQCcgJ2An0ChgKLApgCmwKtArACtQAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAK3}}

@article{blei2003,
	Author = {David M. Blei and Andrew Y. Ng and Michael I. Jordan},
	Date-Modified = {2014-02-20 13:29:24 +0000},
	Journal = {Journal of Machine Learning Research},
	Month = {Jan},
	Pages = {993--1022},
	Read = {1},
	Title = {Latent {D}irichlet Allocation},
	Volume = {3},
	Year = {2003},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QFy4uL1BhcGVycy9ibGVpLzIwMDMucGRm0hcLGBlXTlMuZGF0YU8RAYAAAAAAAYAAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM7sZVxIKwAAABQyLggyMDAzLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEXPJzp/E1AAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAEYmxlaQAQAAgAAM7sq6wAAAARAAgAAM6gCyQAAAABABQAFDIuABQxxAAFM58ABTOeAADARwACADxNYWNpbnRvc2ggSEQ6VXNlcnM6AGNqbWF5OgBEb2N1bWVudHM6AFBhcGVyczoAYmxlaToAMjAwMy5wZGYADgASAAgAMgAwADAAMwAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAKlVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvYmxlaS8yMDAzLnBkZgATAAEvAAAVAAIADP//AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAKgArQC1AjkCOwJAAksCVAJiAmYCbQJ2AnsCiAKLAp0CoAKlAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAqc=}}

@article{vidal2005,
	Author = {Enrique Vidal and Franck Thollard and Colin de la Higuera and Francisco Casacuberta and Rafael C. Carrasco},
	Journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	Number = {7},
	Title = {Probabilistic Finite-State Machines--Part I},
	Volume = {27},
	Year = {2005},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGC4uL1BhcGVycy92aWRhbC8yMDA1LnBkZtIXCxgZV05TLmRhdGFPEQGGAAAAAAGGAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADO7GVcSCsAAAAUMqQIMjAwNS5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABFzs86fxNQAAAAAAAAAAAABAAMAAAkgAAAAAAAAAAAAAAAAAAAABXZpZGFsAAAQAAgAAM7sq6wAAAARAAgAAM6gCyQAAAABABQAFDKkABQxxAAFM58ABTOeAADARwACAD1NYWNpbnRvc2ggSEQ6VXNlcnM6AGNqbWF5OgBEb2N1bWVudHM6AFBhcGVyczoAdmlkYWw6ADIwMDUucGRmAAAOABIACAAyADAAMAA1AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgArVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy92aWRhbC8yMDA1LnBkZgAAEwABLwAAFQACAAz//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgCpAK4AtgJAAkICRwJSAlsCaQJtAnQCfQKCAo8CkgKkAqcCrAAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAKu}}

@article{griffiths2004,
	Author = {Thomas L. Griffiths and Mark Steyvers},
	Comments = {Griffiths and Steyvers introduce collapsed Gibbs sampling for inference in LDA. They apply the algorithm first to a toy dataset, comparing against variational Bayes and expectation propagation and finding that the Gibbs sampling algorithm achieves lower perplexity in fewer FLOPs. The log likelihood of the model found by Gibbs sampling stabilizes within two hundred iterations and is consistent across multiple runs. Griffiths and Steyvers also apply their algorithm to modeling scientific research areas from 1991 to 2001 in PNAS abstracts in the physical, biological, and social sciences, presenting several different views of the results. They empirically determined that 300 topics best fit the data and learned a model accordingly; the computed topics, compared against a gold standard classification of the abstracts, tended to place their probability mass on content words associated with the appropriate classes. A linear trend analysis revealed statistically significant trends in topics corresponding to Nobel prize awards at the beginning and end of the time span of the dataset. Finally, the authors introduce a visualization of an abstract in which words are tagged with their topics and highlighted if they belong to the abstract's most salient topic.},
	Date-Modified = {2014-02-07 15:44:27 +0000},
	Journal = {Proceedings of the National Academy of Sciences},
	Month = {Apr},
	Number = {suppl 1},
	Pages = {5228--5235},
	Read = {1},
	Title = {Finding Scientific Topics},
	Volume = {101},
	Year = {2004},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QHC4uL1BhcGVycy9ncmlmZml0aHMvMjAwNC5wZGbSFwsYGVdOUy5kYXRhTxEBkgAAAAABkgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAAFDJHCDIwMDQucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAARc63On8TUAAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAAlncmlmZml0aHMAABAACAAAzuyrrAAAABEACAAAzqALJAAAAAEAFAAUMkcAFDHEAAUznwAFM54AAMBHAAIAQU1hY2ludG9zaCBIRDpVc2VyczoAY2ptYXk6AERvY3VtZW50czoAUGFwZXJzOgBncmlmZml0aHM6ADIwMDQucGRmAAAOABIACAAyADAAMAA0AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgAvVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9ncmlmZml0aHMvMjAwNC5wZGYAABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4ArQCyALoCUAJSAlcCYgJrAnkCfQKEAo0CkgKfAqICtAK3ArwAAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACvg==}}

@inproceedings{banerjee2007,
	Author = {Arindam Banerjee and Sugato Basu},
	Booktitle = {Proceedings of the 7th SIAM International Conference on Data Mining (SDM)},
	Comments = {Banerjee and Basu compare three different topic models and evaluate online algorithms for each. They also describe a ``hybrid'' approach that interleaves online processing with offline processing, a scheme that could effect load balancing. The three algorithms compared are movMF, a mixture of von Mises-Fisher distributions which model data distributed on the unit hypersphere (e.g., $L_2$-normalized TF-IDF vectors); DCM, a mixture of multinomials over which Dirichlet priors are placed to facilitate modeling word ``burstiness;'' and LDA, in which multinomials with Dirichlet priors are used to model the topic distribution of each document as well as the word distribution of each topic. Banerjee and Basu describe online updates to each of these models and then evaluate the runtime and clustering performance of the online and offline algorithms for each model. Performance is measured as normalized mutual information between the computed clusters and a gold standard clustering, and movMF is found to achieve the best performance by this metric on most data subsets. The movMF algorithms also achieves lower runtime in most configurations, although the online LDA algorithm is similar to the online movMF algorithm in runtime.},
	Date-Modified = {2014-02-07 15:42:50 +0000},
	Month = {Apr},
	Pages = {431--436},
	Read = {1},
	Title = {Topic Models over Text Streams: A Study of Batch and Online Unsupervised Learning},
	Year = {2007},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGy4uL1BhcGVycy9iYW5lcmplZS8yMDA3LnBkZtIXCxgZV05TLmRhdGFPEQGMAAAAAAGMAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADO7GVcSCsAAAAUMgwIMjAwNy5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABFzqs6fxNQAAAAAAAAAAAABAAMAAAkgAAAAAAAAAAAAAAAAAAAACGJhbmVyamVlABAACAAAzuyrrAAAABEACAAAzqALJAAAAAEAFAAUMgwAFDHEAAUznwAFM54AAMBHAAIAQE1hY2ludG9zaCBIRDpVc2VyczoAY2ptYXk6AERvY3VtZW50czoAUGFwZXJzOgBiYW5lcmplZToAMjAwNy5wZGYADgASAAgAMgAwADAANwAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIALlVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvYmFuZXJqZWUvMjAwNy5wZGYAEwABLwAAFQACAAz//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgCsALEAuQJJAksCUAJbAmQCcgJ2An0ChgKLApgCmwKtArACtQAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAK3}}

@inproceedings{canini2009,
	Author = {Kevin R. Canini and Lei Shi and Thomas L. Griffiths},
	Booktitle = {Proceedings of the 12th International Conference on Artificial Intelligence and Statistics (AISTATS)},
	Comments = {Canini, et al. compare the online Gibbs sampler for LDA introduced by Banerjee and Basu (2007) against two novel online LDA algorithms, an ``incremental'' version of the online Gibbs sampler and a particle filter. In both online algorithms, past topic assignments are rejuvenated using the current model. In the particle filter, the total number of topic assignments grows with each observation, so the state space is represented as a tree of hash tables in order to reduce the time complexity of resampling a particle. The authors evaluated the three algorithms using normalized mutual information on the same dataset as Banerjee and Basu. The particle filter consistently achieved the highest normalized mutual information of the three online algorithms, followed by incremental Gibbs sampling and then the online Gibbs sampling algorithm proposed by Banerjee and Basu. Performance of all three online approaches was lower than that of offline Gibbs sampling for LDA.},
	Date-Modified = {2014-02-07 15:43:28 +0000},
	Month = {Apr},
	Read = {1},
	Title = {Online Inference of Topics with Latent {D}irichlet Allocation},
	Year = {2009},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGS4uL1BhcGVycy9jYW5pbmkvMjAwOS5wZGbSFwsYGVdOUy5kYXRhTxEBhgAAAAABhgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAAzuxlXEgrAAAAFDIwCDIwMDkucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAARc97On8TUAAAAAAAAAAAAAQADAAAJIAAAAAAAAAAAAAAAAAAAAAZjYW5pbmkAEAAIAADO7KusAAAAEQAIAADOoAskAAAAAQAUABQyMAAUMcQABTOfAAUzngAAwEcAAgA+TWFjaW50b3NoIEhEOlVzZXJzOgBjam1heToARG9jdW1lbnRzOgBQYXBlcnM6AGNhbmluaToAMjAwOS5wZGYADgASAAgAMgAwADAAOQAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIALFVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvY2FuaW5pLzIwMDkucGRmABMAAS8AABUAAgAM//8AAIAG0hscHR5aJGNsYXNzbmFtZVgkY2xhc3Nlc11OU011dGFibGVEYXRhox0fIFZOU0RhdGFYTlNPYmplY3TSGxwiI1xOU0RpY3Rpb25hcnmiIiBfEA9OU0tleWVkQXJjaGl2ZXLRJidUcm9vdIABAAgAEQAaACMALQAyADcAQABGAE0AVQBgAGcAagBsAG4AcQBzAHUAdwCEAI4AqgCvALcCQQJDAkgCUwJcAmoCbgJ1An4CgwKQApMCpQKoAq0AAAAAAAACAQAAAAAAAAAoAAAAAAAAAAAAAAAAAAACrw==}}

@inproceedings{ahmed2011,
	Author = {Amr Ahmed and Qirong Ho and Jacob Eisenstein and Eric P. Xing and Alexander J. Smola and Choon Hui Teo},
	Booktitle = {Proceedings of the 20th International World Wide Web Conference (WWW)},
	Comments = {Ahmed et al. merge latent Dirichlet allocation into a Recurrent Chinese Restaurant Process to arrive at a dynamic model of streaming news that accounts for persistent topics as well as transient stories spanning those topics. Specifically, in the paradigm of Ahmed et al. the story of a document in a given position in the stream is drawn from an augmented Chinese restaurant process in which the probability mass for each story varies with the number of documents assigned to that story in a specified window of history. For that document, entities are drawn from an inferred per-story entity distribution. For non-entities, first topic proportions for the document are drawn from an inferred per-story topic distribution, then each topic assignment is drawn from those proportions. In extension to latent Dirichlet allocation, a special topic is designated such that whenever that topic is drawn, a word is drawn not from the global word distribution (for that topic) but from a word distribution inferred specifically for the corresponding story. Ahmed et al. present an online algorithm based on a particle filter for inference of this model. They implement resampling of particles and rejuvenation of sampled documents from a specified window of history in order to avoid local optima and promote diversity in the particles; they also use a proposal distribution that does not depend on the topic assignments for the sake of tractability. The inheritance tree data structure introduced by Canini et al. (2009) is incorporated and augmented to support parallel operations by the particles. The described online system outperforms an offline baseline of single-link clustering (on top of locality sensitive hashing) with respect to accuracy over editorially judged document pairs in the Yahoo! news dataset. Ahmed et al. also perform an ablation test, demonstrating that each component of their model contributes positively to accuracy over detecting the first document in each storyline from the TDT5-May dataset.},
	Date-Modified = {2014-02-07 15:42:21 +0000},
	Keywords = {topic models, dirichlet processes, online inference},
	Month = {Mar},
	Pages = {267--276},
	Read = {1},
	Title = {Unified Analysis of Streaming News},
	Year = {2011},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGC4uL1BhcGVycy9haG1lZC8yMDExLnBkZtIXCxgZV05TLmRhdGFPEQGGAAAAAAGGAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADO7GVcSCsAAAAUMf0IMjAxMS5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABFznM6fxNQAAAAAAAAAAAABAAMAAAkgAAAAAAAAAAAAAAAAAAAABWFobWVkAAAQAAgAAM7sq6wAAAARAAgAAM6gCyQAAAABABQAFDH9ABQxxAAFM58ABTOeAADARwACAD1NYWNpbnRvc2ggSEQ6VXNlcnM6AGNqbWF5OgBEb2N1bWVudHM6AFBhcGVyczoAYWhtZWQ6ADIwMTEucGRmAAAOABIACAAyADAAMQAxAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgArVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9haG1lZC8yMDExLnBkZgAAEwABLwAAFQACAAz//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgCpAK4AtgJAAkICRwJSAlsCaQJtAnQCfQKCAo8CkgKkAqcCrAAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAKu}}

@inproceedings{mimno2012,
	Author = {David Mimno and Matthew D. Hoffman and David M. Blei},
	Booktitle = {Proceedings of the 29th International Conference on Machine Learning (ICML)},
	Comments = {Mimno et al. introduce a new algorithm for latent Dirichlet allocation that augments the stochastic gradient descent algorithm of Hoffman et al. (2010) with Gibbs sampling on the topic assignment variables in order to achieve better scalability with respect to the number of topics. More precisely, the improved scalability arises from two implementation details that are facilitated by the Gibbs sampling approach. The authors compared augmented stochastic gradient descent algorithm against online variational Bayes and sequential monte carlo algorithms for LDA and found that their algorithm generally outperformed the other two in runtime, topic coherence, and held-out document probability on a dataset of articles from the Proceedings of the National Academy of Sciences. They also studied the influence of model and algorithm parameters including the number of Gibbs sweeps, the prior on word distributions, and the learning rate.},
	Date-Modified = {2014-02-07 15:45:06 +0000},
	Month = {Jun},
	Read = {1},
	Title = {Sparse Stochastic Inference for Latent {D}irichlet Allocation},
	Year = {2012},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGC4uL1BhcGVycy9taW1uby8yMDEyLnBkZtIXCxgZV05TLmRhdGFPEQGGAAAAAAGGAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADO7GVcSCsAAAAUMl8IMjAxMi5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABFztc6fxNMAAAAAAAAAAAABAAMAAAkgAAAAAAAAAAAAAAAAAAAABW1pbW5vAAAQAAgAAM7sq6wAAAARAAgAAM6gCyMAAAABABQAFDJfABQxxAAFM58ABTOeAADARwACAD1NYWNpbnRvc2ggSEQ6VXNlcnM6AGNqbWF5OgBEb2N1bWVudHM6AFBhcGVyczoAbWltbm86ADIwMTIucGRmAAAOABIACAAyADAAMQAyAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgArVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9taW1uby8yMDEyLnBkZgAAEwABLwAAFQACAAz//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgCpAK4AtgJAAkICRwJSAlsCaQJtAnQCfQKCAo8CkgKkAqcCrAAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAKu}}

@inproceedings{hoffman2010,
	Author = {Matthew D. Hoffman and David M. Blei and Francis Bach},
	Booktitle = {Advances in Neural Information Processing Systems 23 (NIPS)},
	Comments = {Hoffman et al. take the expectation maximization (EM)/variational Bayes (VB) algorithm for smoothed latent Dirichlet allocation introduced in Blei et al. (2003) and incorporate stochastic gradient descent in order to arrive at an online inference algorithm. In batch VB we perform EM iterations on a variational model until a stopping condition is met. Inside each iteration, the E step is an optimization over the local variational parameters for each document and the M step corresponds to a maximum likelihood estimate of the global variational parameters. In online VB, as proposed by Hoffman et al. (2010), we use the same basic EM framework. However, inside the E step we sample a single document or a mini-batch of documents, instead of iterating over the entire corpus, and optimize only over the local variational parameters for the selected document. In the M step we make a modified update to the global variational parameters in which we take a convex combination of the previous settings of those parameters and the maximum likelihood estimates based on the document (or mini-batch) we considered in this iteration of EM. The time complexity of the proposed online algorithm is linear and the space complexity is constant, as desired. The authors compare the proposed online algorithm against batch VB and find that online VB has much better runtime and even performs better, in terms of perplexity on a held-out test set, in many settings. They suggest this may be because stochastic gradient descent is robust to local optima. They include in their experiments a true online setting in which they download and process Wikipedia articles on the fly.},
	Date-Modified = {2014-02-07 15:44:31 +0000},
	Month = {Dec},
	Read = {1},
	Title = {Online Learning for Latent {D}irichlet Allocation},
	Year = {2010},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGi4uL1BhcGVycy9ob2ZmbWFuLzIwMTAucGRm0hcLGBlXTlMuZGF0YU8RAYwAAAAAAYwAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM7sZVxIKwAAABQyTAgyMDEwLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEXPDzp/E0wAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAHaG9mZm1hbgAAEAAIAADO7KusAAAAEQAIAADOoAsjAAAAAQAUABQyTAAUMcQABTOfAAUzngAAwEcAAgA/TWFjaW50b3NoIEhEOlVzZXJzOgBjam1heToARG9jdW1lbnRzOgBQYXBlcnM6AGhvZmZtYW46ADIwMTAucGRmAAAOABIACAAyADAAMQAwAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgAtVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9ob2ZmbWFuLzIwMTAucGRmAAATAAEvAAAVAAIADP//AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAKsAsAC4AkgCSgJPAloCYwJxAnUCfAKFAooClwKaAqwCrwK0AAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAArY=}}

@inproceedings{zhai2013,
	Author = {Ke Zhai and Jordan Boyd-Graber},
	Booktitle = {Proceedings of the 30th International Conference on Machine Learning (ICML)},
	Comments = {Zhai and Boyd-Graber extend the online Latent Dirichlet Allocation algorithm of Mimno et al. (2012), in which stochastic gradient descent over a variational approximation of the model is sped up with sparse Gibbs sampling on the local parameters, by allowing it an infinite vocabulary. They do so by drawing the word distribution of each topic from a Dirichlet process, a Bayesian nonparametric model, instead of a fixed-dimension Dirichlet prior. The base distribution used in that Dirichlet process is an n-gram model where the word length n is drawn from a multinomial distribution to eliminate bias. To keep the nonparametric approach tractable, a truncation ordered set is used to approximate the vocabulary. Words are scored and ranked so that higher-frequency and higher-probability (under the modified n-gram model) words receive higher score and lower rank. The vocabulary (set) is allowed to grow each iteration, but every few iterations the set is reordered according to the scoring function and truncated. Zhai and Boyd-Graber compare their model against the stochastic gradient descent approach of Mimno et al. (2012), the online algorithm of Hoffman et al. (2010), and an offline dynamic model proposed by Blei and Lafferty (2006). These models are all handicapped so that they start with a vocabulary built from the first minibatch or from a comprehensive dictionary and disregard out-of-vocabulary words. In pointwise mutual information on Wikipedia articles, the infinite-vocabulary model matches the other models for about one thousand documents and then pulls away with a marked acceleration in pointwise mutual informationi later. If the topics from each model are used as features for support vector machine classification, the infinite-vocabulary model outperforms all other models in accuracy except for the dynamic topic model.},
	Date-Modified = {2014-02-07 15:46:09 +0000},
	Read = {1},
	Title = {Online Latent {D}irichlet Allocation with Infinite Vocabulary},
	Year = {2013},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QFy4uL1BhcGVycy96aGFpLzIwMTMucGRm0hcLGBlXTlMuZGF0YU8RAYAAAAAAAYAAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM7sZVxIKwAAABQytggyMDEzLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEXPRzp/E0wAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAEemhhaQAQAAgAAM7sq6wAAAARAAgAAM6gCyMAAAABABQAFDK2ABQxxAAFM58ABTOeAADARwACADxNYWNpbnRvc2ggSEQ6VXNlcnM6AGNqbWF5OgBEb2N1bWVudHM6AFBhcGVyczoAemhhaToAMjAxMy5wZGYADgASAAgAMgAwADEAMwAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAKlVzZXJzL2NqbWF5L0RvY3VtZW50cy9QYXBlcnMvemhhaS8yMDEzLnBkZgATAAEvAAAVAAIADP//AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAKgArQC1AjkCOwJAAksCVAJiAmYCbQJ2AnsCiAKLAp0CoAKlAAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAAqc=}}

@inproceedings{wallach2009a,
	Author = {Hanna M. Wallach and Iain Murray and Ruslan Salakhutdinov and David Mimno},
	Booktitle = {Proceedings of the 26th International Conference on Machine Learning (ICML)},
	Comments = {Wallach et al. (2009) assess several model evaluation techniques for latent Dirichlet allocation. This vein of investigation is similar to that of Yao et al. (2009) but the assessment and model evaluation techniques appear to be complementary. Concretely, Wallach et al. (2009) study methods for inferring a likelihood distribution for a held-out dataset given a model learned from a training dataset. The held-out models are then compared according to held-out likelihood. Specifically, Annealed Importance Sampling (AIS) is taken to be a gold standard and other approaches are judged in how closely their produced likelihoods resemble those of AIS. AIS has produced good estimates in prior work but is computationally expensive. The other approaches include simple importance sampling, harmonic mean, Chib-style estimation, and the ``left-to-right'' algorithm. Counter-intuitively, the evaluation method yielding the highest likelihood is not the best; the harmonic mean method (which has received criticism in prior work) produces likelihood estimates significantly greater than those of the other methods but this difference is only an artifact of under-sampling. Overall, the results suggest the left-to-right algorithm should be used for evaluating different models under latent Dirichlet allocation, assuming emulation of AIS is our goal. The authors also study a different class of evaluation methods, under the name of document completion, that estimate likelihood on the second half of each document in the held-out data using a model fit to the first half. Again, left-to-right evaluation proves effective. Finally, Wallach et al. briefly study the effect of model perturbation on select evaluation methods; the limited results here seem inconclusive.},
	Date-Modified = {2014-02-07 15:45:59 +0000},
	Month = {Jun},
	Read = {1},
	Title = {Evaluation Methods for Topic Models},
	Year = {2009},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGy4uL1BhcGVycy93YWxsYWNoLzIwMDlhLnBkZtIXCxgZV05TLmRhdGFPEQGOAAAAAAGOAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADO7GVcSCsAAAAUMqgJMjAwOWEucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABFzmM6faG0AAAAAAAAAAAABAAMAAAkgAAAAAAAAAAAAAAAAAAAAB3dhbGxhY2gAABAACAAAzuyrrAAAABEACAAAzp+uvQAAAAEAFAAUMqgAFDHEAAUznwAFM54AAMBHAAIAQE1hY2ludG9zaCBIRDpVc2VyczoAY2ptYXk6AERvY3VtZW50czoAUGFwZXJzOgB3YWxsYWNoOgAyMDA5YS5wZGYADgAUAAkAMgAwADAAOQBhAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgAuVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy93YWxsYWNoLzIwMDlhLnBkZgATAAEvAAAVAAIADP//AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAKwAsQC5AksCTQJSAl0CZgJ0AngCfwKIAo0CmgKdAq8CsgK3AAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAArk=}}

@techreport{wallach2004,
	Author = {Hanna M. Wallach},
	Institution = {University of Pennsylvania},
	Month = {Feb},
	Number = {MS-CIS-04-21},
	Title = {Conditional Random Fields: An Introduction},
	Year = {2004},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGi4uL1BhcGVycy93YWxsYWNoLzIwMDQucGRm0hcLGBlXTlMuZGF0YU8RAYwAAAAAAYwAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAM7sZVxIKwAAABQyqAgyMDA0LnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAEXOZzp9obQAAAAAAAAAAAAEAAwAACSAAAAAAAAAAAAAAAAAAAAAHd2FsbGFjaAAAEAAIAADO7KusAAAAEQAIAADOn669AAAAAQAUABQyqAAUMcQABTOfAAUzngAAwEcAAgA/TWFjaW50b3NoIEhEOlVzZXJzOgBjam1heToARG9jdW1lbnRzOgBQYXBlcnM6AHdhbGxhY2g6ADIwMDQucGRmAAAOABIACAAyADAAMAA0AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgAtVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy93YWxsYWNoLzIwMDQucGRmAAATAAEvAAAVAAIADP//AACABtIbHB0eWiRjbGFzc25hbWVYJGNsYXNzZXNdTlNNdXRhYmxlRGF0YaMdHyBWTlNEYXRhWE5TT2JqZWN00hscIiNcTlNEaWN0aW9uYXJ5oiIgXxAPTlNLZXllZEFyY2hpdmVy0SYnVHJvb3SAAQAIABEAGgAjAC0AMgA3AEAARgBNAFUAYABnAGoAbABuAHEAcwB1AHcAhACOAKsAsAC4AkgCSgJPAloCYwJxAnUCfAKFAooClwKaAqwCrwK0AAAAAAAAAgEAAAAAAAAAKAAAAAAAAAAAAAAAAAAAArY=}}

@unpublished{smith2004,
	Author = {Noah A. Smith},
	Date-Modified = {2014-02-20 13:27:04 +0000},
	Institution = {Johns Hopkins University},
	Month = {Dec},
	Read = {1},
	Title = {Log-Linear Models},
	Year = {2004},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGC4uL1BhcGVycy9zbWl0aC8yMDA0LnBkZtIXCxgZV05TLmRhdGFPEQGGAAAAAAGGAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADO7GVcSCsAAAAUMpgIMjAwNC5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABFz5s6faG0AAAAAAAAAAAABAAMAAAkgAAAAAAAAAAAAAAAAAAAABXNtaXRoAAAQAAgAAM7sq6wAAAARAAgAAM6frr0AAAABABQAFDKYABQxxAAFM58ABTOeAADARwACAD1NYWNpbnRvc2ggSEQ6VXNlcnM6AGNqbWF5OgBEb2N1bWVudHM6AFBhcGVyczoAc21pdGg6ADIwMDQucGRmAAAOABIACAAyADAAMAA0AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgArVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9zbWl0aC8yMDA0LnBkZgAAEwABLwAAFQACAAz//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgCpAK4AtgJAAkICRwJSAlsCaQJtAnQCfQKCAo8CkgKkAqcCrAAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAKu}}

@unpublished{minka2012,
	Author = {Thomas P. Minka},
	Title = {Estimating a {D}irichlet Distribution},
	Year = {2012},
	Bdsk-File-1 = {YnBsaXN0MDDUAQIDBAUGJCVYJHZlcnNpb25YJG9iamVjdHNZJGFyY2hpdmVyVCR0b3ASAAGGoKgHCBMUFRYaIVUkbnVsbNMJCgsMDxJXTlMua2V5c1pOUy5vYmplY3RzViRjbGFzc6INDoACgAOiEBGABIAFgAdccmVsYXRpdmVQYXRoWWFsaWFzRGF0YV8QGC4uL1BhcGVycy9taW5rYS8yMDEyLnBkZtIXCxgZV05TLmRhdGFPEQGGAAAAAAGGAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADO7GVcSCsAAAAUMmEIMjAxMi5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABFz5M6faCcAAAAAAAAAAAABAAMAAAkgAAAAAAAAAAAAAAAAAAAABW1pbmthAAAQAAgAAM7sq6wAAAARAAgAAM6frncAAAABABQAFDJhABQxxAAFM58ABTOeAADARwACAD1NYWNpbnRvc2ggSEQ6VXNlcnM6AGNqbWF5OgBEb2N1bWVudHM6AFBhcGVyczoAbWlua2E6ADIwMTIucGRmAAAOABIACAAyADAAMQAyAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgArVXNlcnMvY2ptYXkvRG9jdW1lbnRzL1BhcGVycy9taW5rYS8yMDEyLnBkZgAAEwABLwAAFQACAAz//wAAgAbSGxwdHlokY2xhc3NuYW1lWCRjbGFzc2VzXU5TTXV0YWJsZURhdGGjHR8gVk5TRGF0YVhOU09iamVjdNIbHCIjXE5TRGljdGlvbmFyeaIiIF8QD05TS2V5ZWRBcmNoaXZlctEmJ1Ryb290gAEACAARABoAIwAtADIANwBAAEYATQBVAGAAZwBqAGwAbgBxAHMAdQB3AIQAjgCpAK4AtgJAAkICRwJSAlsCaQJtAnQCfQKCAo8CkgKkAqcCrAAAAAAAAAIBAAAAAAAAACgAAAAAAAAAAAAAAAAAAAKu}}
